[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Cuadernos de Estadística Espacial",
    "section": "",
    "text": "Introducción\nEn los siguientes cuadernos encontrará ejemplos con código sobre estadística espacial escalar y funcional. Para poder correr todos los ejemplos clone el repositorio de la siguiente forma. Debe tener instalado previamente git en su computador.\ngit clone --branch gh-pages  https://github.com/mpbohorquezc/SpatFD-Functional-Geostatistics.git\nSi esta corriendo sobre Ubuntu o Mint es importante tener algunos compiladores previamente instalados para poder instanciar algunas de las librerías. En general con los siguientes comandos podría correr cualquiera de los cuadernos sin problema\nsudo apt-get install r-base-dev\nsudo apt install liblapack-dev libopenblas-dev\nSi alguna dependencia hace falta algunos repositorios los puede descargar e instalar a manera de archivo .tar.gz o se encuentran simplemente en los repositorios del CRAN.",
    "crumbs": [
      "[Introducción]{style=\"color: #FF8000;\"}"
    ]
  },
  {
    "objectID": "1.html",
    "href": "1.html",
    "title": "Geoestadística con sgeostat",
    "section": "",
    "text": "Geoestadística con sgeostat",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Análisis Exploratorio de Datos</span>",
      "<span style='color: #728387 !important;'>Estadística descriptiva y Exploratoria</span>"
    ]
  },
  {
    "objectID": "1.html#carga-de-los-datos",
    "href": "1.html#carga-de-los-datos",
    "title": "Geoestadística con sgeostat",
    "section": "Carga de los datos",
    "text": "Carga de los datos\n\nrm(list=ls())\naquifer=read.table(\"data/aquifer.txt\",head=T,dec=\",\")\nhead(aquifer)\n\n       Este     Norte Profundidad\n1  42.78275 127.62282        1464\n2 -27.39691  90.78732        2553\n3  -1.16289  84.89600        2158\n4 -18.61823  76.45199        2455\n5  96.46549  64.58058        1756\n6 108.56243  82.92325        1702",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Análisis Exploratorio de Datos</span>",
      "<span style='color: #728387 !important;'>Estadística descriptiva y Exploratoria</span>"
    ]
  },
  {
    "objectID": "1.html#librerias",
    "href": "1.html#librerias",
    "title": "Geoestadística con sgeostat",
    "section": "Librerias",
    "text": "Librerias\n\nlibrary(scatterplot3d)\nlibrary(ggplot2)\nlibrary(cowplot)\nlibrary(sgeostat)",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Análisis Exploratorio de Datos</span>",
      "<span style='color: #728387 !important;'>Estadística descriptiva y Exploratoria</span>"
    ]
  },
  {
    "objectID": "1.html#gráficos",
    "href": "1.html#gráficos",
    "title": "Geoestadística con sgeostat",
    "section": "Gráficos",
    "text": "Gráficos\n\ng1 &lt;- ggplot(aquifer, aes(x = Este, y = Profundidad)) +\n  geom_point() +\n  geom_line() +\n  xlab(\"Este\") +\n  ylab(\"Profundidad\")\n\ng2 &lt;- ggplot(aquifer, aes(x = Norte, y = Profundidad)) +\n  geom_point() +\n  geom_line() +\n  xlab(\"Norte\") +\n  ylab(\"Profundidad\")\n\ng3 &lt;- ggplot(aquifer, aes(x = Este * Norte, y = Profundidad)) +\n  geom_point() +\n  geom_line() +\n  xlab(\"Interacción este, norte\") +\n  ylab(\"Profundidad\")\n\nplot_grid(g1,g2,g3)\n\n\n\n\n\n\n\n\n\ncor(aquifer)\n\n                  Este      Norte Profundidad\nEste         1.0000000  0.1147565  -0.7788885\nNorte        0.1147565  1.0000000  -0.6200923\nProfundidad -0.7788885 -0.6200923   1.0000000\n\n\n\nscatterplot3d(aquifer, highlight.3d=TRUE, col.axis=\"blue\",\ncol.grid=\"lightblue\", main=\"Tendencia de Profundidad\", pch=20)\n\n\n\n\n\n\n\n\n\nreg1 &lt;- lm(Profundidad ~ Este + Norte, data = aquifer)\nresiduales1  &lt;-  residuals(reg1)\nsummary(reg1)\n\n\nCall:\nlm(formula = Profundidad ~ Este + Norte, data = aquifer)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-366.96 -161.53  -30.71  148.15  651.20 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 2591.4302    38.9599   66.52   &lt;2e-16 ***\nEste          -6.7514     0.3438  -19.64   &lt;2e-16 ***\nNorte         -5.9872     0.4066  -14.73   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 203.3 on 82 degrees of freedom\nMultiple R-squared:  0.8921,    Adjusted R-squared:  0.8894 \nF-statistic: 338.9 on 2 and 82 DF,  p-value: &lt; 2.2e-16\n\n\n\nanova(reg1)\n\nAnalysis of Variance Table\n\nResponse: Profundidad\n          Df   Sum Sq  Mean Sq F value    Pr(&gt;F)    \nEste       1 19045642 19045642  460.95 &lt; 2.2e-16 ***\nNorte      1  8960172  8960172  216.86 &lt; 2.2e-16 ***\nResiduals 82  3388069    41318                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nreg2 &lt;- lm(Profundidad ~ Este*Norte, data = aquifer)\nresiduales2  &lt;-  residuals(reg2)\nsummary(reg2)\n\n\nCall:\nlm(formula = Profundidad ~ Este * Norte, data = aquifer)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-406.30 -138.88  -13.04  129.36  722.48 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  2.627e+03  3.833e+01  68.546  &lt; 2e-16 ***\nEste        -8.287e+00  5.658e-01 -14.646  &lt; 2e-16 ***\nNorte       -6.649e+00  4.327e-01 -15.366  &lt; 2e-16 ***\nEste:Norte   2.452e-02  7.401e-03   3.314  0.00138 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 191.9 on 81 degrees of freedom\nMultiple R-squared:  0.905, Adjusted R-squared:  0.9014 \nF-statistic: 257.1 on 3 and 81 DF,  p-value: &lt; 2.2e-16\n\n\n\nanova(reg2)\n\nAnalysis of Variance Table\n\nResponse: Profundidad\n           Df   Sum Sq  Mean Sq F value    Pr(&gt;F)    \nEste        1 19045642 19045642  517.06 &lt; 2.2e-16 ***\nNorte       1  8960172  8960172  243.25 &lt; 2.2e-16 ***\nEste:Norte  1   404448   404448   10.98  0.001379 ** \nResiduals  81  2983621    36835                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nreg3 &lt;- lm(Profundidad ~ Este*Norte+I(Este^2)*I(Norte^2), data = aquifer)\nresiduales3  &lt;-  residuals(reg3)\nsummary(reg3)\n\n\nCall:\nlm(formula = Profundidad ~ Este * Norte + I(Este^2) * I(Norte^2), \n    data = aquifer)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-372.7 -133.6  -20.3  129.9  505.1 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           2.538e+03  7.038e+01  36.055   &lt;2e-16 ***\nEste                 -7.728e+00  6.028e-01 -12.822   &lt;2e-16 ***\nNorte                -3.075e+00  1.770e+00  -1.737   0.0863 .  \nI(Este^2)            -6.792e-03  5.967e-03  -1.138   0.2585    \nI(Norte^2)           -2.372e-02  9.049e-03  -2.622   0.0105 *  \nEste:Norte            1.155e-02  9.680e-03   1.193   0.2365    \nI(Este^2):I(Norte^2)  2.251e-06  9.541e-07   2.360   0.0208 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 180.7 on 78 degrees of freedom\nMultiple R-squared:  0.9189,    Adjusted R-squared:  0.9126 \nF-statistic: 147.2 on 6 and 78 DF,  p-value: &lt; 2.2e-16\n\n\n\nanova(reg3)\n\nAnalysis of Variance Table\n\nResponse: Profundidad\n                     Df   Sum Sq  Mean Sq  F value    Pr(&gt;F)    \nEste                  1 19045642 19045642 583.2335 &lt; 2.2e-16 ***\nNorte                 1  8960172  8960172 274.3868 &lt; 2.2e-16 ***\nI(Este^2)             1    55368    55368   1.6955 0.1967061    \nI(Norte^2)            1   152170   152170   4.6599 0.0339500 *  \nEste:Norte            1   451567   451567  13.8283 0.0003755 ***\nI(Este^2):I(Norte^2)  1   181854   181854   5.5689 0.0207829 *  \nResiduals            78  2547110    32655                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\naquifer=data.frame(aquifer,resi=residuales2)\naquifer_points=point(aquifer, x=\"Este\", y=\"Norte\")\naquifer_pair=pair(aquifer_points,num.lags=10)\n\n....................................................................................\n\n\n\nstr(aquifer_pair)\n\nList of 5\n $ from: num [1:3570] 1 1 1 1 1 1 1 1 1 1 ...\n $ to  : num [1:3570] 2 3 4 5 6 7 8 9 10 11 ...\n $ lags: Factor w/ 10 levels \"1\",\"2\",\"3\",\"4\",..: 3 3 3 4 3 4 4 4 4 4 ...\n $ dist: num [1:3570] 79.3 61.3 79.9 82.8 79.5 ...\n $ bins: num [1:10] 13.6 40.7 67.8 94.9 122 ...\n - attr(*, \"type\")= chr \"isotropic\"\n - attr(*, \"class\")= chr \"pair\"\n\n\n\naquifer.v&lt;-est.variogram(aquifer_points,aquifer_pair,'resi')\n\n\ng4 &lt;- ggplot(aquifer, aes(x = Este, y = resi)) + \n  geom_point() + \n  geom_line() +\n  xlab(\"Este\") + \n  ylab(\"residuales2\")\n\ng5 &lt;- ggplot(aquifer, aes(x = Norte, y = resi)) + \n  geom_point() + \n  geom_line() +\n  xlab(\"Norte\") + \n  ylab(\"residuales2\")\n\n\nplot_grid(g4, g5)\n\n\n\n\n\n\n\n\n\naquifer_points=point(aquifer, x=\"Este\", y=\"Norte\")\nfit.trend(aquifer_points,at=\"Profundidad\", np=2, plot.it=TRUE)\n\n\n\n\n\n\n\n\n$beta\n      x^0 y^0       x^1 y^0       x^2 y^0       x^0 y^1       x^1 y^1 \n 2.481430e+03 -8.373708e+00  1.416675e-03 -2.043419e+00  2.680056e-02 \n      x^0 y^2 \n-2.464371e-02 \n\n$R\n       x^0 y^0   x^1 y^0    x^2 y^0    x^0 y^1    x^1 y^1   x^0 y^2\n[1,] -9.219544 -155.6739 -41051.636 -731.67314 -16082.944 -85540.31\n[2,]  0.000000  595.1832   3500.219   57.75539  38829.771  12491.66\n[3,]  0.000000    0.0000  39397.313 -117.36878   1909.315 -23722.80\n[4,]  0.000000    0.0000      0.000  485.98967  14332.040  91118.22\n[5,]  0.000000    0.0000      0.000    0.00000  25401.055   3240.90\n[6,]  0.000000    0.0000      0.000    0.00000      0.000  19989.20\n\n$np\n[1] 2\n\n$x\n [1]   42.78275  -27.39691   -1.16289  -18.61823   96.46549  108.56243\n [7]   88.36356   90.04213   93.17269   97.61099   90.62946   92.55262\n[13]   99.48996  -24.06744  -26.06285   56.27842   73.03881   80.26679\n[19]   80.23009   68.83845   76.39921   64.46148   43.39657   39.07769\n[25]  112.80450   54.25899    6.13202   -3.80469   -2.23054   -2.36177\n[31]   -2.18890   63.22428  -10.77860  -18.98889  -38.57884   83.14496\n[37]  -21.80248  -23.56457  -20.11299  -16.62654   29.90748  100.91568\n[43]  101.29544  103.26625  -14.31073  -18.13447  -18.12151   -9.88796\n[49]  -12.16336   11.65754   61.69122   69.57896   66.72205  -36.65446\n[55]  -19.55102  -21.29791  -22.36166   21.14719    7.68461   -8.33227\n[61]   56.70724   59.00052   68.96893   70.90225   73.00243   59.66237\n[67]   61.87249   63.70810    5.62706   18.24739   85.68824  105.07646\n[73] -101.64278 -145.23654  -73.99313  -94.48182  -88.84983 -120.25898\n[79]  -86.02454  -72.79097 -100.17372  -78.83539  -83.69063  -95.61661\n[85]  -87.55480\n\n$y\n [1] 127.62282  90.78732  84.89600  76.45199  64.58058  82.92325  56.45348\n [8]  39.25820  33.05852  56.27887  35.08169  41.75238  59.15785 184.76636\n[15] 114.07479  26.84826  18.88140  12.61593  14.61795 107.77423  95.99380\n[22] 110.39641  53.61499  61.99805  45.54766 147.81987  48.32772  40.40450\n[29]  29.91113  33.82002  33.68207  79.49924 175.11346 171.91695 158.52742\n[36] 159.11559  15.02551   9.41441  22.09269  17.25621 175.12875  22.97808\n[43]  22.96385  20.34239  31.26545  30.18118  29.53241  38.14483  39.11081\n[50]  18.73347  32.94906  33.80841  33.93264 150.91457 137.78404 131.82542\n[57] 137.13680 139.26199 126.83751 107.77691 171.26443 164.54863 177.24820\n[64] 161.38136 162.98959 170.10544 174.30177 173.91454  79.08730  77.39191\n[71] 139.81702 132.03181  10.65106  28.02333  87.97270  86.62606  76.70991\n[78]  80.76485  54.36334  43.09215  42.89881  40.82141  46.50482  35.82183\n[85]  29.39267\n\n$z\n [1] 1464 2553 2158 2455 1756 1702 1805 1797 1714 1466 1729 1638 1736 1476 2200\n[16] 1999 1680 1806 1682 1306 1722 1437 1828 2118 1725 1606 2648 2560 2544 2386\n[31] 2400 1757 1402 1364 1735 1376 2729 2766 2736 2432 1024 1611 1548 1591 2540\n[46] 2352 2528 2575 2468 2646 1739 1674 1868 1865 1777 1579 1771 1408 1527 2003\n[61] 1386 1089 1384 1030 1092 1161 1415 1231 2300 2238 1038 1332 3510 3490 2594\n[76] 2650 2533 3571 2811 2728 3136 2553 2798 2691 2946\n\n$residuals\n [1] -145.932017  296.391955   20.569629  155.586776  136.944207  210.578982\n [7]  112.643763   81.535500   12.407325 -165.733666   11.643984  -55.843867\n[13]  123.038140  130.250727  132.838620   16.473072 -186.973641   -9.864104\n[19] -133.020821 -298.072286   98.737035 -175.328351 -174.667016  118.113364\n[25]  176.632628  200.333264  366.232978  173.604750  128.842139  -15.778284\n[31]   -1.005758  -17.176812   -5.743382 -109.803640   35.578021  175.509274\n[37]  109.375693  113.827801  154.658230 -138.758151 -234.947039  -41.999962\n[43] -102.169175  -45.349545   38.415648 -182.959426   -9.456222  134.544149\n[49]   14.873572  303.070200 -191.631118 -197.446346  -23.989926   92.632496\n[55]  -47.092725 -308.538280  -72.511843 -213.402614 -260.643390  -17.741523\n[61]  187.380986 -159.999448  282.152142 -199.908135 -116.838018  -37.190026\n[67]  262.093246   81.109636  169.467368  176.796541 -289.932780   42.387375\n[73]  216.381585  -51.786437   30.159248  -53.946573 -219.188525  648.160187\n[79]  -92.004756 -152.583829   49.711612 -386.649271 -141.519561 -407.429504\n[85] -129.126052\n\nattr(,\"class\")\n[1] \"trend.surface\"\n\n\n\ng_resi &lt;- ggplot(aquifer.v, aes(x = Norte, y = resi)) +  \n  geom_point() +  \n  geom_line() +\n  xlab(\"Norte\") +  \n  ylab(\"residuales2\")\n\ng6 &lt;- ggplot(aquifer.v, aes(x = bins, y = classic)) +  \n  geom_point() +  \n  geom_line() +\n  xlab(\"Rezago espacial, h\") +  \n  ylab(\"Estimador clásico del variograma\")\n\ng7 &lt;- ggplot(aquifer.v, aes(x = bins, y = robust)) +  \n  geom_point() +  \n  geom_line() +\n  xlab(\"Rezago espacial, h\") +  \n  ylab(\"Estimador robusto 1 del variograma\")\n\ng8 &lt;- ggplot(aquifer.v, aes(x = bins, y = med)) +  \n  geom_point() +  \n  geom_line() +\n  xlab(\"Rezago espacial, h\") +  \n  ylab(\"Estimador robusto 2 del variograma\")\n\n\nplot_grid(g6, g7, g8, nrow = 1, ncol = 3)\n\n\n\n\n\n\n\n\n\n#par(mfrow=c(1,3))\nprint(aquifer.v)\n\n   lags      bins   classic    robust       med   n\n1     1  13.55308  43779.20  44355.34  47948.45 285\n2     2  40.65923  71039.50  71176.29  73188.30 350\n3     3  67.76539  80041.91  85367.59  93223.52 492\n4     4  94.87154  67197.27  68067.40  73056.46 719\n5     5 121.97770  73572.25  68052.99  66133.91 612\n6     6 149.08385  57650.90  58608.95  58819.91 521\n7     7 176.19001  65498.82  62167.57  68112.31 356\n8     8 203.29616 130414.72 107613.55  77805.71 173\n9     9 230.40231 161738.13 134102.60 123952.77  43\n10   10 257.50847  35525.99  45217.14  58333.98  19\n\n\n\nplot(aquifer.v$robust)\n\n\n\n\n\n\n\n\n\nplot(aquifer.v$med,col='blue')\npoints(aquifer.v$robust,col=\"red\")\n\n\n\n\n\n\n\n\n\naquifer.vmodExp&lt;-fit.exponential(aquifer.v,c0=0,ce=40000,ae=20,plot.it=TRUE,iterations=30)\n\nInitial parameter estimates:  0 40000 20 \n\n\n\n\n\n\n\n\n\nIteration: 1 \nGradient vector:  -4432.441 977.0988 -8.943538 \nNew parameter estimates:  1e-06 40977.1 11.05646 \n\nrse.dif =  3232643827 (rse = 3232643827 )  ;  parm.dist =  977.1397 \n\n\n\n\n\n\n\n\n\nIteration: 2 \nGradient vector:  -26700.7 22493.46 -2.800242 \nNew parameter estimates:  1e-06 63470.56 8.256219 \n\nrse.dif =  -17644208 (rse = 3.215e+09 )  ;  parm.dist =  22493.46 \n\n\n\n\n\n\n\n\n\nIteration: 3 \nGradient vector:  -11057.27 -15597.73 2.315183 \nNew parameter estimates:  1e-06 47872.83 10.5714 \n\nrse.dif =  -3772568 (rse = 3211227051 )  ;  parm.dist =  15597.73 \n\n\n\n\n\n\n\n\n\nIteration: 4 \nGradient vector:  -27525.12 16431.58 -1.824505 \nNew parameter estimates:  1e-06 64304.41 8.746897 \n\nrse.dif =  3032851 (rse = 3214259902 )  ;  parm.dist =  16431.58 \n\n\n\n\n\n\n\n\n\nIteration: 5 \nGradient vector:  -20442.22 -7053.019 1.144197 \nNew parameter estimates:  1e-06 57251.39 9.891094 \n\nrse.dif =  -2468665 (rse = 3211791237 )  ;  parm.dist =  7053.019 \n\n\n\n\n\n\n\n\n\nIteration: 6 \nGradient vector:  -27557.41 7097.539 -0.7122805 \nNew parameter estimates:  1e-06 64348.93 9.178813 \n\nrse.dif =  1486180 (rse = 3213277417 )  ;  parm.dist =  7097.539 \n\n\n\n\n\n\n\n\n\nIteration: 7 \nGradient vector:  -24787.06 -2758.919 0.3605893 \nNew parameter estimates:  1e-06 61590.01 9.539403 \n\nrse.dif =  -951749.7 (rse = 3212325667 )  ;  parm.dist =  2758.919 \n\n\n\n\n\n\n\n\n\nIteration: 8 \nGradient vector:  -26691.4 1898.737 -0.1885371 \nNew parameter estimates:  1e-06 63488.75 9.350866 \n\nrse.dif =  471370.4 (rse = 3212797038 )  ;  parm.dist =  1898.737 \n\n\n\n\n\n\n\n\n\nIteration: 9 \nGradient vector:  -25850.35 -838.0686 0.09276125 \nNew parameter estimates:  1e-06 62650.68 9.443627 \n\nrse.dif =  -249219.6 (rse = 3212547818 )  ;  parm.dist =  838.0686 \n\n\n\n\n\n\n\n\n\nIteration: 10 \nGradient vector:  -26302.53 450.7265 -0.04631475 \nNew parameter estimates:  1e-06 63101.41 9.397312 \n\nrse.dif =  121873.4 (rse = 3212669692 )  ;  parm.dist =  450.7265 \n\n\n\n\n\n\n\n\n\nIteration: 11 \nGradient vector:  -26086.54 -215.2624 0.02285916 \nNew parameter estimates:  1e-06 62886.14 9.420171 \n\nrse.dif =  -61031.79 (rse = 3212608660 )  ;  parm.dist =  215.2624 \n\n\n\n\n\n\n\n\n\nIteration: 12 \nGradient vector:  -26195.52 108.6221 -0.01133309 \nNew parameter estimates:  1e-06 62994.77 9.408838 \n\nrse.dif =  30077.83 (rse = 3212638738 )  ;  parm.dist =  108.6221 \n\n\n\n\n\n\n\n\n\nIteration: 13 \nGradient vector:  -26142.08 -53.26613 0.005604603 \nNew parameter estimates:  1e-06 62941.5 9.414443 \n\nrse.dif =  -14922.96 (rse = 3212623815 )  ;  parm.dist =  53.26613 \n\n\n\n\n\n\n\n\n\nIteration: 14 \nGradient vector:  -26168.65 26.48517 -0.002774911 \nNew parameter estimates:  1e-06 62967.99 9.411668 \n\nrse.dif =  7377.216 (rse = 3212631192 )  ;  parm.dist =  26.48517 \n\n\n\n\n\n\n\n\n\nIteration: 15 \nGradient vector:  -26155.53 -13.07801 0.001373075 \nNew parameter estimates:  1e-06 62954.91 9.413041 \n\nrse.dif =  -3653.216 (rse = 3212627539 )  ;  parm.dist =  13.07801 \n\n\n\n\n\n\n\n\n\nIteration: 16 \nGradient vector:  -26162.03 6.479831 -0.0006796194 \nNew parameter estimates:  1e-06 62961.39 9.412361 \n\nrse.dif =  1807.514 (rse = 3212629346 )  ;  parm.dist =  6.479831 \n\n\n\n\n\n\n\n\n\nIteration: 17 \nGradient vector:  -26158.82 -3.20516 0.0003363367 \nNew parameter estimates:  1e-06 62958.18 9.412698 \n\nrse.dif =  -894.6895 (rse = 3212628451 )  ;  parm.dist =  3.20516 \n\n\n\n\n\n\n\n\n\nIteration: 18 \nGradient vector:  -26160.41 1.586717 -0.0001664615 \nNew parameter estimates:  1e-06 62959.77 9.412531 \n\nrse.dif =  442.763 (rse = 3212628894 )  ;  parm.dist =  1.586717 \n\n\n\n\n\n\n\n\n\nIteration: 19 \nGradient vector:  -26159.62 -0.7851797 8.238305e-05 \nNew parameter estimates:  1e-06 62958.98 9.412613 \n\nrse.dif =  -219.1369 (rse = 3212628675 )  ;  parm.dist =  0.7851797 \n\n\n\n\n\n\n\n\n\nIteration: 20 \nGradient vector:  -26160.01 0.3886224 -4.077271e-05 \nNew parameter estimates:  1e-06 62959.37 9.412573 \n\nrse.dif =  108.4519 (rse = 3212628784 )  ;  parm.dist =  0.3886224 \n\n\n\n\n\n\n\n\n\nIteration: 21 \nGradient vector:  -26159.82 -0.192328 2.01789e-05 \nNew parameter estimates:  1e-06 62959.18 9.412593 \n\nrse.dif =  -53.67477 (rse = 3212628730 )  ;  parm.dist =  0.192328 \n\n\n\n\n\n\n\n\n\nIteration: 22 \nGradient vector:  -26159.91 0.09518727 -9.986825e-06 \nNew parameter estimates:  1e-06 62959.28 9.412583 \n\nrse.dif =  26.56425 (rse = 3212628756 )  ;  parm.dist =  0.09518727 \n\n\n\n\n\n\n\n\n\nIteration: 23 \nGradient vector:  -26159.86 -0.04710907 4.94261e-06 \nNew parameter estimates:  1e-06 62959.23 9.412588 \n\nrse.dif =  -13.14703 (rse = 3212628743 )  ;  parm.dist =  0.04710907 \n\n\n\n\n\n\n\n\n\nIteration: 24 \nGradient vector:  -26159.89 0.023315 -2.446165e-06 \nNew parameter estimates:  1e-06 62959.25 9.412585 \n\nrse.dif =  6.506634 (rse = 3212628750 )  ;  parm.dist =  0.023315 \n\n\n\n\n\n\n\n\n\nIteration: 25 \nGradient vector:  -26159.88 -0.01153889 1.21064e-06 \nNew parameter estimates:  1e-06 62959.24 9.412587 \n\nrse.dif =  -3.220222 (rse = 3212628747 )  ;  parm.dist =  0.01153889 \n\n\n\n\n\n\n\n\n\nIteration: 26 \nGradient vector:  -26159.88 0.005710764 -5.991627e-07 \nNew parameter estimates:  1e-06 62959.25 9.412586 \n\nrse.dif =  1.593734 (rse = 3212628748 )  ;  parm.dist =  0.005710764 \n\n\n\n\n\n\n\n\n\nIteration: 27 \nGradient vector:  -26159.88 -0.002826342 2.965346e-07 \nNew parameter estimates:  1e-06 62959.24 9.412586 \n\nrse.dif =  -0.7887611 (rse = 3212628747 )  ;  parm.dist =  0.002826342 \n\n\n\n\n\n\n\n\n\nIteration: 28 \nGradient vector:  -26159.88 0.001398795 -1.467591e-07 \nNew parameter estimates:  1e-06 62959.24 9.412586 \n\nrse.dif =  0.3903689 (rse = 3212628748 )  ;  parm.dist =  0.001398795 \n\n\n\n\n\n\n\n\n\nIteration: 29 \nGradient vector:  -26159.88 -0.0006922812 7.263288e-08 \nNew parameter estimates:  1e-06 62959.24 9.412586 \n\nrse.dif =  -0.1932006 (rse = 3212628748 )  ;  parm.dist =  0.0006922812 \n\n\n\n\n\n\n\n\n\nIteration: 30 \nGradient vector:  -26159.88 0.000342624 -3.594748e-08 \nNew parameter estimates:  1e-06 62959.24 9.412586 \n\nrse.dif =  0.09561825 (rse = 3212628748 )  ;  parm.dist =  0.000342624 \n\n\n\n\n\n\n\n\n\nConvergence not achieved!\n\n\n\naquifer.vmodGau&lt;-fit.gaussian(aquifer.v,c0=0,cg=50000,ag=50,plot.it=TRUE,iterations=30)\n\nInitial parameter estimates:  0 50000 50 \n\n\n\n\n\n\n\n\n\nIteration: 1 \nGradient vector:  19162.34 -33401.14 -11.41191 \nNew parameter estimates:  19162.34 16598.86 38.58809 \n\nrse.dif =  3299750048 (rse = 3299750048 )  ;  parm.dist =  38507.55 \n\n\n\n\n\n\n\n\n\nIteration: 2 \nGradient vector:  -1294.927 2010.017 -18.77473 \nNew parameter estimates:  17867.41 18608.87 19.81336 \n\nrse.dif =  -66430135 (rse = 3233319913 )  ;  parm.dist =  2391.1 \n\n\n\n\n\n\n\n\n\nIteration: 3 \nGradient vector:  3201.043 -2835.169 9.216254 \nNew parameter estimates:  21068.46 15773.71 29.02961 \n\nrse.dif =  -24694350 (rse = 3208625564 )  ;  parm.dist =  4276.09 \n\n\n\n\n\n\n\n\n\nIteration: 4 \nGradient vector:  -4345.272 4292.413 -6.361973 \nNew parameter estimates:  16723.18 20066.12 22.66764 \n\nrse.dif =  4004881 (rse = 3212630445 )  ;  parm.dist =  6107.884 \n\n\n\n\n\n\n\n\n\nIteration: 5 \nGradient vector:  53.88685 -4.270081 2.074271 \nNew parameter estimates:  16777.07 20061.85 24.74191 \n\nrse.dif =  -3703977 (rse = 3208926468 )  ;  parm.dist =  54.09555 \n\n\n\n\n\n\n\n\n\nIteration: 6 \nGradient vector:  -391.4471 384.4526 -0.5571294 \nNew parameter estimates:  16385.62 20446.3 24.18478 \n\nrse.dif =  588163 (rse = 3209514631 )  ;  parm.dist =  548.6666 \n\n\n\n\n\n\n\n\n\nIteration: 7 \nGradient vector:  29.55911 -27.0943 0.07968918 \nNew parameter estimates:  16415.18 20419.21 24.26447 \n\nrse.dif =  -201438.9 (rse = 3209313192 )  ;  parm.dist =  40.09799 \n\n\n\n\n\n\n\n\n\nIteration: 8 \nGradient vector:  -6.581211 6.259206 -0.01207028 \nNew parameter estimates:  16408.6 20425.47 24.2524 \n\nrse.dif =  26607.8 (rse = 3209339800 )  ;  parm.dist =  9.082408 \n\n\n\n\n\n\n\n\n\nIteration: 9 \nGradient vector:  0.9423146 -0.8928955 0.001794561 \nNew parameter estimates:  16409.54 20424.57 24.25419 \n\nrse.dif =  -4077.43 (rse = 3209335722 )  ;  parm.dist =  1.298161 \n\n\n\n\n\n\n\n\n\nIteration: 10 \nGradient vector:  -0.1413215 0.1339887 -0.0002673761 \nNew parameter estimates:  16409.4 20424.71 24.25393 \n\nrse.dif =  605.1536 (rse = 3209336327 )  ;  parm.dist =  0.194743 \n\n\n\n\n\n\n\n\n\nIteration: 11 \nGradient vector:  0.02102884 -0.01993597 3.982407e-05 \nNew parameter estimates:  16409.42 20424.69 24.25397 \n\nrse.dif =  -90.18701 (rse = 3209336237 )  ;  parm.dist =  0.02897682 \n\n\n\n\n\n\n\n\n\nIteration: 12 \nGradient vector:  -0.003132718 0.00296995 -5.931842e-06 \nNew parameter estimates:  16409.42 20424.69 24.25396 \n\nrse.dif =  13.43229 (rse = 3209336251 )  ;  parm.dist =  0.004316777 \n\n\n\n\n\n\n\n\n\nIteration: 13 \nGradient vector:  0.0004666088 -0.0004423641 8.835486e-07 \nNew parameter estimates:  16409.42 20424.69 24.25396 \n\nrse.dif =  -2.000767 (rse = 3209336249 )  ;  parm.dist =  0.0006429701 \n\n\n\n\n\n\n\n\n\nIteration: 14 \nGradient vector:  -6.950171e-05 6.589045e-05 -1.316048e-07 \nNew parameter estimates:  16409.42 20424.69 24.25396 \n\nrse.dif =  0.2980142 (rse = 3209336249 )  ;  parm.dist =  9.577086e-05 \n\n\n\n\n\n\n\n\n\nIteration: 15 \nGradient vector:  1.035229e-05 -9.814388e-06 1.960254e-08 \nNew parameter estimates:  16409.42 20424.69 24.25396 \n\nrse.dif =  -0.04438925 (rse = 3209336249 )  ;  parm.dist =  1.426508e-05 \n\n\n\n\n\n\n\n\n\nIteration: 16 \nGradient vector:  -1.542e-06 1.46188e-06 -2.919839e-09 \nNew parameter estimates:  16409.42 20424.69 24.25396 \n\nrse.dif =  0.006612301 (rse = 3209336249 )  ;  parm.dist =  2.124821e-06 \n\n\n\n\n\n\n\n\n\nIteration: 17 \nGradient vector:  2.296994e-07 -2.177628e-07 4.349363e-10 \nNew parameter estimates:  16409.42 20424.69 24.25396 \n\nrse.dif =  -0.0009851456 (rse = 3209336249 )  ;  parm.dist =  3.165152e-07 \n\n\n\n\n\n\n\n\n\nIteration: 18 \nGradient vector:  -3.420782e-08 3.242781e-08 -6.477718e-11 \nNew parameter estimates:  16409.42 20424.69 24.25396 \n\nrse.dif =  0.0001473427 (rse = 3209336249 )  ;  parm.dist =  4.713621e-08 \n\n\n\n\n\n\n\n\n\nIteration: 19 \nGradient vector:  5.086605e-09 -4.821087e-09 9.637383e-12 \nNew parameter estimates:  16409.42 20424.69 24.25396 \n\nrse.dif =  -2.193451e-05 (rse = 3209336249 )  ;  parm.dist =  7.007276e-09 \n\n\n\n\n\n\n\n\n\nIteration: 20 \nGradient vector:  -7.583935e-10 7.161523e-10 -1.439258e-12 \nNew parameter estimates:  16409.42 20424.69 24.25396 \n\nrse.dif =  2.861023e-06 (rse = 3209336249 )  ;  parm.dist =  1.042223e-09 \n\n\n\n\n\n\n\n\n\nIteration: 21 \nGradient vector:  1.019258e-10 -9.775917e-11 1.99309e-13 \nNew parameter estimates:  16409.42 20424.69 24.25396 \n\nrse.dif =  -4.768372e-07 (rse = 3209336249 )  ;  parm.dist =  1.415077e-10 \n\nConvergence achieved by sums of squares.\n\n\n\n\n\n\n\n\n\nFinal parameter estimates:  16409.42 20424.69 24.25396 \n\n\n\naquifer.vmodWave&lt;-fit.wave(aquifer.v,c0=0,cw=40000,aw=10,plot.it=TRUE,iterations=30,weighted=T)\n\nInitial parameter estimates:  0 40000 10 \n\n\n\n\n\n\n\n\n\nIteration: 1 \nGradient vector:  18650.32 -21981.27 -0.7942028 \nNew parameter estimates:  18650.32 18018.73 9.205797 \n\nrse.dif =  3409704989 (rse = 3409704989 )  ;  parm.dist =  28827.26 \n\n\n\n\n\n\n\n\n\nIteration: 2 \nGradient vector:  812.9227 -1109.399 -1.187299 \nNew parameter estimates:  19463.25 16909.33 8.018498 \n\nrse.dif =  -289093760 (rse = 3120611230 )  ;  parm.dist =  1375.358 \n\n\n\n\n\n\n\n\n\nIteration: 3 \nGradient vector:  -6990.158 6973.566 0.9858099 \nNew parameter estimates:  12473.09 23882.9 9.004308 \n\nrse.dif =  24044562 (rse = 3144655792 )  ;  parm.dist =  9873.851 \n\n\n\n\n\n\n\n\n\nIteration: 4 \nGradient vector:  7025.438 -6960.473 -1.260353 \nNew parameter estimates:  19498.53 16922.43 7.743955 \n\nrse.dif =  -56767551 (rse = 3087888241 )  ;  parm.dist =  9889.639 \n\n\n\n\n\n\n\n\n\nIteration: 5 \nGradient vector:  -9210.154 9213.61 1.066674 \nNew parameter estimates:  10288.37 26136.04 8.810629 \n\nrse.dif =  175986924 (rse = 3263875165 )  ;  parm.dist =  13027.57 \n\n\n\n\n\n\n\n\n\nIteration: 6 \nGradient vector:  11994.7 -11983.26 -2.255679 \nNew parameter estimates:  22283.07 14152.77 6.55495 \n\nrse.dif =  -196728543 (rse = 3067146622 )  ;  parm.dist =  16954.98 \n\n\n\n\n\n\n\n\n\nIteration: 7 \nGradient vector:  -14060.45 14195.04 -1.578095 \nNew parameter estimates:  8222.625 28347.81 4.976855 \n\nrse.dif =  147278852 (rse = 3214425474 )  ;  parm.dist =  19979.87 \n\n\n\n\n\n\n\n\n\nIteration: 8 \nGradient vector:  -15826.64 16212.91 0.3854677 \nNew parameter estimates:  1e-06 44560.72 5.362323 \n\nrse.dif =  -46983778 (rse = 3167441696 )  ;  parm.dist =  18178.84 \n\n\n\n\n\n\n\n\n\nIteration: 9 \nGradient vector:  13145.08 -21444.98 -0.8756698 \nNew parameter estimates:  13145.08 23115.75 4.486653 \n\nrse.dif =  -757940879 (rse = 2409500817 )  ;  parm.dist =  25153.13 \n\n\n\n\n\n\n\n\n\nIteration: 10 \nGradient vector:  -9434763 9682459 25.73116 \nNew parameter estimates:  1e-06 9705575 30.21781 \n\nrse.dif =  1636307005 (rse = 4045807822 )  ;  parm.dist =  9682468 \n\n\n\n\n\n\n\n\n\nIteration: 11 \nGradient vector:  20962.2 -9688482 0.02156687 \nNew parameter estimates:  20962.2 17093.21 30.23938 \n\nrse.dif =  83628062 (rse = 4129435883 )  ;  parm.dist =  9688504 \n\n\n\n\n\n\n\n\n\nIteration: 12 \nGradient vector:  7173.136 -8587.116 1.22582 \nNew parameter estimates:  28135.34 8506.099 31.4652 \n\nrse.dif =  -628497356 (rse = 3500938527 )  ;  parm.dist =  11188.94 \n\n\n\n\n\n\n\n\n\nIteration: 13 \nGradient vector:  2974.651 -2890.861 -4.19572 \nNew parameter estimates:  31109.99 5615.237 27.26947 \n\nrse.dif =  -192443200 (rse = 3308495327 )  ;  parm.dist =  4147.969 \n\n\n\n\n\n\n\n\n\nIteration: 14 \nGradient vector:  -2399.351 1443.698 15.69929 \nNew parameter estimates:  28710.64 7058.936 42.96876 \n\nrse.dif =  147479203 (rse = 3455974530 )  ;  parm.dist =  2800.25 \n\n\n\n\n\n\n\n\n\nIteration: 15 \nGradient vector:  4786.661 2165.107 -43.14322 \nNew parameter estimates:  33497.3 9224.042 1e-06 \n\nrse.dif =  -686128323 (rse = 2769846206 )  ;  parm.dist =  5253.728 \n\n\n\n\n\n\n\n\n\nIteration: 16 \n\n\nWarning in lsfit(xmat, y, wt = w, intercept = FALSE): 'X' matrix was collinear\n\n\nGradient vector:  -7188.309 -5.926894e-07 0 \nNew parameter estimates:  26308.99 9224.042 1e-06 \n\nrse.dif =  686457465 (rse = 3456303671 )  ;  parm.dist =  7188.309 \n\n\n\n\n\n\n\n\n\nIteration: 17 \n\n\nWarning in lsfit(xmat, y, wt = w, intercept = FALSE): 'X' matrix was collinear\n\n\nGradient vector:  -5.339328e-06 -5.926894e-07 0 \nNew parameter estimates:  26308.99 9224.042 1e-06 \n\nrse.dif =  0.4889331 (rse = 3456303672 )  ;  parm.dist =  5.372122e-06 \n\n\n\n\n\n\n\n\n\nIteration: 18 \n\n\nWarning in lsfit(xmat, y, wt = w, intercept = FALSE): 'X' matrix was collinear\n\n\nGradient vector:  5.926852e-07 -5.926894e-07 0 \nNew parameter estimates:  26308.99 9224.042 1e-06 \n\nrse.dif =  1.907349e-06 (rse = 3456303672 )  ;  parm.dist =  8.381857e-07 \n\n\n\n\n\n\n\n\n\nIteration: 19 \n\n\nWarning in lsfit(xmat, y, wt = w, intercept = FALSE): 'X' matrix was collinear\n\n\nGradient vector:  5.926931e-07 -5.926894e-07 0 \nNew parameter estimates:  26308.99 9224.042 1e-06 \n\nrse.dif =  -9.536743e-07 (rse = 3456303672 )  ;  parm.dist =  8.381908e-07 \n\nConvergence achieved by sums of squares.\n\n\n\n\n\n\n\n\n\nFinal parameter estimates:  26308.99 9224.042 1e-06 \n\n\n\ncurve(65000*(1-(14/x)*sin(x/14)),0,300,ylim=c(0,200000))\npoints(aquifer.v$bins,aquifer.v$classic,col=3)\ntext(aquifer.v$bins,aquifer.v$classic,aquifer.v$n,col=2)\n\n\n\n\n\n\n\n\n\ncurve(200000*(1-exp(-x/170)),0,300)\npoints(aquifer.v$bins,aquifer.v$classic,col=2)\n\n\n\n\n\n\n\n\n\ncurve(65000*(1-(14/x)*sin(x/14)),0,300,ylim=c(0,200000))\npoints(aquifer.v$bins,aquifer.v$classic,col=3)\ntext(aquifer.v$bins,aquifer.v$classic,aquifer.v$n,col=2)\n\n\n\n\n\n\n\n\n\naquifer.vmodExp&lt;-fit.exponential(aquifer.v,c0=0,ce=200000,ae=170,plot.it=TRUE,iterations=30,weighted=T)\n\nInitial parameter estimates:  0 2e+05 170 \n\n\n\n\n\n\n\n\n\nIteration: 1 \nGradient vector:  16365.66 -238859.4 -103.7436 \nNew parameter estimates:  16365.66 1e-06 66.25643 \n\nrse.dif =  3826411368 (rse = 3826411368 )  ;  parm.dist =  200668.5 \n\n\n\n\n\n\n\n\n\nIteration: 2 \nGradient vector:  7737.246 16547.95 166070861252 \nNew parameter estimates:  24102.91 16547.95 166070861318 \n\nrse.dif =  -767474321 (rse = 3058937047 )  ;  parm.dist =  166070861252 \n\n\n\n\n\n\n\n\n\nIteration: 3 \n\n\nWarning in lsfit(xmat, y, wt = w, intercept = FALSE): 'X' matrix was collinear\n\n\nGradient vector:  3355.03 1.242479e+13 0 \nNew parameter estimates:  27457.94 1.242479e+13 166070861318 \n\nrse.dif =  -120011141 (rse = 2938925906 )  ;  parm.dist =  1.242479e+13 \n\n\n\n\n\n\n\n\n\nIteration: 4 \n\n\nWarning in lsfit(xmat, y, wt = w, intercept = FALSE): 'X' matrix was collinear\n\n\nGradient vector:  423.3165 -663474885968 0 \nNew parameter estimates:  27881.25 1.176131e+13 166070861318 \n\nrse.dif =  11801483 (rse = 2950727388 )  ;  parm.dist =  663474885968 \n\n\n\n\n\n\n\n\n\nIteration: 5 \n\n\nWarning in lsfit(xmat, y, wt = w, intercept = FALSE): 'X' matrix was collinear\n\n\nGradient vector:  3.873181 -6320523090 0 \nNew parameter estimates:  27885.12 1.175499e+13 166070861318 \n\nrse.dif =  128956.4 (rse = 2950856345 )  ;  parm.dist =  6320523090 \n\n\n\n\n\n\n\n\n\nIteration: 6 \n\n\nWarning in lsfit(xmat, y, wt = w, intercept = FALSE): 'X' matrix was collinear\n\n\nGradient vector:  0.02266712 -36921321 0 \nNew parameter estimates:  27885.15 1.175495e+13 166070861318 \n\nrse.dif =  752.3639 (rse = 2950857097 )  ;  parm.dist =  36921321 \n\n\n\n\n\n\n\n\n\nIteration: 7 \n\n\nWarning in lsfit(xmat, y, wt = w, intercept = FALSE): 'X' matrix was collinear\n\n\nGradient vector:  0.0001316946 -214507.3 0 \nNew parameter estimates:  27885.15 1.175495e+13 166070861318 \n\nrse.dif =  4.371067 (rse = 2950857102 )  ;  parm.dist =  214507.3 \n\n\n\n\n\n\n\n\n\nIteration: 8 \n\n\nWarning in lsfit(xmat, y, wt = w, intercept = FALSE): 'X' matrix was collinear\n\n\nGradient vector:  7.650992e-07 -1246.212 0 \nNew parameter estimates:  27885.15 1.175495e+13 166070861318 \n\nrse.dif =  0.02539396 (rse = 2950857102 )  ;  parm.dist =  1246.213 \n\n\n\n\n\n\n\n\n\nIteration: 9 \n\n\nWarning in lsfit(xmat, y, wt = w, intercept = FALSE): 'X' matrix was collinear\n\n\nGradient vector:  4.447233e-09 -7.24441 0 \nNew parameter estimates:  27885.15 1.175495e+13 166070861318 \n\nrse.dif =  0.0001473427 (rse = 2950857102 )  ;  parm.dist =  7.244141 \n\n\n\n\n\n\n\n\n\nIteration: 10 \n\n\nWarning in lsfit(xmat, y, wt = w, intercept = FALSE): 'X' matrix was collinear\n\n\nGradient vector:  2.31966e-11 -0.03646515 0 \nNew parameter estimates:  27885.15 1.175495e+13 166070861318 \n\nrse.dif =  9.536743e-07 (rse = 2950857102 )  ;  parm.dist =  0.03710938 \n\nConvergence achieved by sums of squares.\n\n\n\n\n\n\n\n\n\nFinal parameter estimates:  27885.15 1.175495e+13 166070861318 \n\n\n\naquifer.vmodwave&lt;-fit.wave(aquifer.v,c0=4000,cw=30000,aw=15,plot.it=TRUE,iterations=0,weighted=T)\n\n\n\n\n\n\n\n\nConvergence not achieved!\n\n\n\naquifer.vmodExp_0&lt;-fit.exponential(aquifer.v,c0=0,ce=200000,ae=170,plot.it=TRUE,iterations=0,weighted=T)\n\n\n\n\n\n\n\n\nConvergence not achieved!\n\n\n\naquifer.vmodwave_0&lt;-fit.wave(aquifer.v,c0=4000,cw=30000,aw=15,plot.it=TRUE,iterations=0,weighted=T)\n\n\n\n\n\n\n\n\nConvergence not achieved!\n\n\n\naquifer.spherical&lt;-fit.spherical(aquifer.v,c0=0,cs=35000,as=70,plot.it=TRUE,iterations=0,weighted=T)\n\n\n\n\n\n\n\n\nConvergence not achieved!\n\n\n\nggplot(aquifer.v, aes(bins, classic)) + \n  geom_point() + \n  geom_line() +\n  xlab(\"Rezago espacial, h\") + \n  ylab(\"Estimador clásico del variograma\")+\n  xlim(0, 300) +\n  geom_function(aes(color = \"Exponencial\"),\n    fun =~4000+150000*(1-exp(-.x/100)) \n    ) +\n  geom_function(aes(color = \"Seno cardinal\"),\n    fun =~4000+30000*(1-((15/.x)*sin(.x/15)))             \n    ) + xlab(\"Rezago espacial\") + ylab(\"Modelos teóricos de  semivariogramas\") \n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_function()`).\n\n\n\n\n\n\n\n\n\n\nKriging_aquifer &lt;- point(data.frame(list(x=10,y=80)))\nKriging_aquifer &lt;- krige(Kriging_aquifer, aquifer_points, 'resi', aquifer.vmodExp_0)\n\n\nUsing all points.\n  Preparing the kriging system matrix...\n  Inverting the matrix...\n  Predicting.\n\n\n\nKriging_aquifer\n\n\nPoint object: x \n\n   Locations: 1\n\n   Attributes:\n      x\n      y\n      do\n      zhat\n      sigma2hat\n\n\n\nKriging_aquifer$sigma2hat\n\n[1] 7010.452\n\n\n\nKriging_aquifer &lt;- point(data.frame(list(x=10,y=80)))\nKriging_aquifer &lt;- krige(Kriging_aquifer, aquifer_points, 'resi', aquifer.vmodwave_0)\n\n\nUsing all points.\n  Preparing the kriging system matrix...\n  Inverting the matrix...\n  Predicting.\n\n\n\nKriging_aquifer\n\n\nPoint object: x \n\n   Locations: 1\n\n   Attributes:\n      x\n      y\n      do\n      zhat\n      sigma2hat\n\n\n\nKriging_aquifer$zhat\n\n[1] 196.2781\n\n\n\nKriging_aquifer$sigma2hat\n\n[1] 5169.927\n\n\n\ngrid &lt;- list(x=seq(min(aquifer$Este),max(aquifer$Este),by=20),y=seq(min(aquifer$Norte),max(aquifer$Norte),by=10))\ngrid$xr &lt;- range(grid$x)\ngrid$xs &lt;- grid$xr[2] - grid$xr[1]\ngrid$yr &lt;- range(grid$y)\ngrid$ys &lt;- grid$yr[2] - grid$yr[1]\ngrid$max &lt;- max(grid$xs, grid$ys)\ngrid$xy &lt;- data.frame(cbind(c(matrix(grid$x, length(grid$x), length(grid$y))),\nc(matrix(grid$y, length(grid$x), length(grid$y), byrow=TRUE))))\ncolnames(grid$xy) &lt;- c(\"x\", \"y\")\ngrid$point &lt;- point(grid$xy)\ngrid$krige &lt;- krige(grid$point,aquifer_points,'resi',aquifer.vmodwave_0,maxdist=180,extrap=FALSE)\n\n\nUsing points within 180 units of prediction points.\n  Predicting..........................................................................................................................................................................................................................................\n\n\n\nop &lt;- par(no.readonly = TRUE)\npar(pty=\"s\")\nplot(grid$xy, type=\"n\", xlim=c(grid$xr[1], grid$xr[1]+grid$max),ylim=c(grid$yr[1], grid$yr[1]+grid$max))\nimage(grid$x,grid$y,matrix(grid$krige$zhat,length(grid$x),length(grid$y)),add=TRUE)\ncontour(grid$x,grid$y,matrix(grid$krige$zhat,length(grid$x),length(grid$y)),add=TRUE)\n\n\n\n\n\n\n\n\n\nop &lt;- par(no.readonly = TRUE)\npar(pty=\"s\")\nplot(grid$xy, type=\"n\", xlim=c(grid$xr[1], grid$xr[1]+grid$max),ylim=c(grid$yr[1], grid$yr[1]+grid$max))\nimage(grid$x,grid$y,matrix(grid$krige$sigma2hat,length(grid$x),length(grid$y)), add=TRUE)\ncontour(grid$x,grid$y,matrix(grid$krige$sigma2hat,length(grid$x),length(grid$y)),add=TRUE)",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Análisis Exploratorio de Datos</span>",
      "<span style='color: #728387 !important;'>Estadística descriptiva y Exploratoria</span>"
    ]
  },
  {
    "objectID": "2-Pruebas de Bondad de ajuste.html",
    "href": "2-Pruebas de Bondad de ajuste.html",
    "title": "1  Pruebas de bondad de ajuste",
    "section": "",
    "text": "Pruebas de bondad de ajuste",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Análisis Exploratorio de Datos</span>",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'><span style='color: #728387 !important;'>Pruebas de bondad de ajuste</span></span>"
    ]
  },
  {
    "objectID": "2-Pruebas de Bondad de ajuste.html#cargar-paquetes-y-leer-datos",
    "href": "2-Pruebas de Bondad de ajuste.html#cargar-paquetes-y-leer-datos",
    "title": "1  Pruebas de bondad de ajuste",
    "section": "2.1 Cargar Paquetes y Leer datos",
    "text": "2.1 Cargar Paquetes y Leer datos\n\n#install.packages(\"moments\")\n#install.packages(\"ecostats\")\nlibrary(moments)\nlibrary(ecostats)\n\n\nlibrary(nortest)\nlibrary(vcd)\n\n\n#install.packages(\"Rgof\")\nlibrary(Rgof)\ndatos=read.table(\"Datos1.txt\")",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Análisis Exploratorio de Datos</span>",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'><span style='color: #728387 !important;'>Pruebas de bondad de ajuste</span></span>"
    ]
  },
  {
    "objectID": "2-Pruebas de Bondad de ajuste.html#gráficos-exploratorios-mirar-simetría-apuntamiento-datos-atípicos",
    "href": "2-Pruebas de Bondad de ajuste.html#gráficos-exploratorios-mirar-simetría-apuntamiento-datos-atípicos",
    "title": "1  Pruebas de bondad de ajuste",
    "section": "2.2 Gráficos exploratorios, mirar simetría, apuntamiento, datos atípicos",
    "text": "2.2 Gráficos exploratorios, mirar simetría, apuntamiento, datos atípicos\n\nhist(datos$x)\n\n\nboxplot(datos$x)\n\n\nstem(datos$x)",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Análisis Exploratorio de Datos</span>",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'><span style='color: #728387 !important;'>Pruebas de bondad de ajuste</span></span>"
    ]
  },
  {
    "objectID": "2-Pruebas de Bondad de ajuste.html#medidas-de-resumen",
    "href": "2-Pruebas de Bondad de ajuste.html#medidas-de-resumen",
    "title": "1  Pruebas de bondad de ajuste",
    "section": "2.3 Medidas de resumen",
    "text": "2.3 Medidas de resumen\n\nsummary(datos$x)\n\n\nmean(datos$x)\n\n\nmedian(datos$x)\n\n\n#skewness(datos$x)\n\n\nkurtosis(datos$x)",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Análisis Exploratorio de Datos</span>",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'><span style='color: #728387 !important;'>Pruebas de bondad de ajuste</span></span>"
    ]
  },
  {
    "objectID": "2-Pruebas de Bondad de ajuste.html#histogramas-de-frecuencia-relativa-densidad-ajuste-a-la-distribución-de-probabilidad-teórica",
    "href": "2-Pruebas de Bondad de ajuste.html#histogramas-de-frecuencia-relativa-densidad-ajuste-a-la-distribución-de-probabilidad-teórica",
    "title": "1  Pruebas de bondad de ajuste",
    "section": "2.4 Histogramas de frecuencia relativa, densidad, ajuste a la distribución de probabilidad teórica",
    "text": "2.4 Histogramas de frecuencia relativa, densidad, ajuste a la distribución de probabilidad teórica\n\nhist(datos$x,freq=F,ylab=\"Densidad\",col=\"whitesmoke\",ylim=c(0,0.045),main=\"Distribución de frecuencias de X\",xlab=\"X\")\nlines(density(datos$x),col=\"#BF3EFF\",lwd=3)\ncurve(dnorm(x, mean = 87.80697, sd = 9.780568),60,130,col=\"midnightblue\",add=T,lwd=3)\ncurve(dgamma(x, shape = 71.444, scale=1.212),60,130,col=\"chocolate\",add=T,lwd=3)\nlegend(\"topright\",col=c(\"#BF3EFF\",\"midnightblue\",\"chocolate\"),c(\"Densidad\",\"Normal teórica\",\"Gamma teórica\"),lty=1,lwd=3)\n\n\nhist(datos$x,freq=F,ylab=\"Densidad\",col=\"whitesmoke\",ylim=c(0,0.045))\nlines(density(datos$x),col=\"midnightblue\",lwd=3)\ncurve(dgamma(x, shape = 71.444, scale=1.212),60,130,col=\"chocolate\",add=T,lwd=3)",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Análisis Exploratorio de Datos</span>",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'><span style='color: #728387 !important;'>Pruebas de bondad de ajuste</span></span>"
    ]
  },
  {
    "objectID": "2-Pruebas de Bondad de ajuste.html#verificación-de-porcentajes-a-k-desviaciones-estándar-de-la-media-para-la-distribución-normal",
    "href": "2-Pruebas de Bondad de ajuste.html#verificación-de-porcentajes-a-k-desviaciones-estándar-de-la-media-para-la-distribución-normal",
    "title": "1  Pruebas de bondad de ajuste",
    "section": "2.5 Verificación de porcentajes a k desviaciones estándar de la media para la distribución normal",
    "text": "2.5 Verificación de porcentajes a k desviaciones estándar de la media para la distribución normal\n\nIntervalos=c(mean(datos$x)-4*sd(datos$x),mean(datos$x)-3*sd(datos$x),mean(datos$x)-2*sd(datos$x),mean(datos$x)-sd(datos$x),                 mean(datos$x),mean(datos$x)+sd(datos$x),mean(datos$x)+2*sd(datos$x),mean(datos$x)+3*sd(datos$x),mean(datos$x)+4*sd(datos$x))\nhist(datos$x,freq=F,ylab=\"Densidad\",breaks=Intervalos,col=\"whitesmoke\",ylim=c(0,0.045))\n\n\nhist(datos$x,breaks=Intervalos,plot=F)",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Análisis Exploratorio de Datos</span>",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'><span style='color: #728387 !important;'>Pruebas de bondad de ajuste</span></span>"
    ]
  },
  {
    "objectID": "2-Pruebas de Bondad de ajuste.html#gráfico-de-cuantiles-teóricos-vs-cuantiles-muestrales-envolvente",
    "href": "2-Pruebas de Bondad de ajuste.html#gráfico-de-cuantiles-teóricos-vs-cuantiles-muestrales-envolvente",
    "title": "1  Pruebas de bondad de ajuste",
    "section": "2.6 Gráfico de cuantiles teóricos vs cuantiles muestrales, envolvente",
    "text": "2.6 Gráfico de cuantiles teóricos vs cuantiles muestrales, envolvente\n\nqqnorm(datos$x)\n\n\nqqenvelope(datos$x)",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Análisis Exploratorio de Datos</span>",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'><span style='color: #728387 !important;'>Pruebas de bondad de ajuste</span></span>"
    ]
  },
  {
    "objectID": "2-Pruebas de Bondad de ajuste.html#comparación-de-los-datos-de-la-muestra-con-una-muestra-simulada-de-la-distribución-normal-teórica-propuesta",
    "href": "2-Pruebas de Bondad de ajuste.html#comparación-de-los-datos-de-la-muestra-con-una-muestra-simulada-de-la-distribución-normal-teórica-propuesta",
    "title": "1  Pruebas de bondad de ajuste",
    "section": "2.7 Comparación de los datos de la muestra, con una muestra simulada de la distribución normal teórica propuesta",
    "text": "2.7 Comparación de los datos de la muestra, con una muestra simulada de la distribución normal teórica propuesta\n\nmu=mean(datos$x)\ndesvest=sd(datos$x)\nyy=rnorm(276,mu,desvest)\nqqplot(datos$x,yy)\n\n\n2.7.0.1 Comparación de los datos de la muestra, con una muestra simulada de la distribución teórica Gamma propuesta\n\nyygam=rgamma(276,shape=72,scale=1.2)\nqqplot(datos$x,yygam,col=2)",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Análisis Exploratorio de Datos</span>",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'><span style='color: #728387 !important;'>Pruebas de bondad de ajuste</span></span>"
    ]
  },
  {
    "objectID": "2-Pruebas de Bondad de ajuste.html#prueba-de-hipótesis-de-kolmogorov-smirnov",
    "href": "2-Pruebas de Bondad de ajuste.html#prueba-de-hipótesis-de-kolmogorov-smirnov",
    "title": "1  Pruebas de bondad de ajuste",
    "section": "2.8 Prueba de hipótesis de Kolmogorov Smirnov",
    "text": "2.8 Prueba de hipótesis de Kolmogorov Smirnov\n\nks.test(datos$x, \"pnorm\", mean=86, sd=10)\n\n\nks.test(datos$x, \"pgamma\",shape=71.444, scale=10)",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Análisis Exploratorio de Datos</span>",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'><span style='color: #728387 !important;'>Pruebas de bondad de ajuste</span></span>"
    ]
  },
  {
    "objectID": "2-Pruebas de Bondad de ajuste.html#pruebas-de-hipótesis-de-normalidad-del-paquete-nortest.-ejercicio-consultar-los-estadísticos-de-todas-las-pruebas-ejecutadas-a-continuación",
    "href": "2-Pruebas de Bondad de ajuste.html#pruebas-de-hipótesis-de-normalidad-del-paquete-nortest.-ejercicio-consultar-los-estadísticos-de-todas-las-pruebas-ejecutadas-a-continuación",
    "title": "1  Pruebas de bondad de ajuste",
    "section": "2.9 Pruebas de hipótesis de normalidad del paquete nortest. Ejercicio consultar los estadísticos de todas las pruebas ejecutadas a continuación",
    "text": "2.9 Pruebas de hipótesis de normalidad del paquete nortest. Ejercicio consultar los estadísticos de todas las pruebas ejecutadas a continuación\n\nks.test(datos$x, \"pnorm\", mean=86, sd=10)\n\n\nshapiro.test(datos$x)\n\n\nad.test(datos$x)\n\n\ncvm.test(datos$x)\n\n\nlillie.test(datos$x)\n\n\npearson.test(datos$x)\n\n\nsf.test(datos$x)",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Análisis Exploratorio de Datos</span>",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'><span style='color: #728387 !important;'>Pruebas de bondad de ajuste</span></span>"
    ]
  },
  {
    "objectID": "2.html",
    "href": "2.html",
    "title": "Geoestadística Univariada con geoR",
    "section": "",
    "text": "Geoestadística Univariada con geoR",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Geoestadística </span>",
      "<span style='color: #728387 !important;'>Geoestadística Univariada con GeoR </span>"
    ]
  },
  {
    "objectID": "2.html#parte-descriptiva",
    "href": "2.html#parte-descriptiva",
    "title": "Geoestadística Univariada con geoR",
    "section": "Parte descriptiva",
    "text": "Parte descriptiva\n\nLibrerías\nLista de librerías con link a la documentación.\n\nfields\ngeoR\nakima (Usado para gráficos descriptivos)\n\n\nrm(list=ls())\nlibrary(fields)\n\n\nlibrary(geoR)\n\n\nlibrary(akima)\n\n\n\nLectura de datos\n\naquifer &lt;- read.table(\"data/aquifer.txt\", head = TRUE, dec = \",\")\n\nEncabezado de datos aquifer.txt\n\nhead(aquifer)\n\n       Este     Norte Profundidad\n1  42.78275 127.62282        1464\n2 -27.39691  90.78732        2553\n3  -1.16289  84.89600        2158\n4 -18.61823  76.45199        2455\n5  96.46549  64.58058        1756\n6 108.56243  82.92325        1702\n\n\nSummary de los datos aquifer.txt",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Geoestadística </span>",
      "<span style='color: #728387 !important;'>Geoestadística Univariada con GeoR </span>"
    ]
  },
  {
    "objectID": "2.html#geo_data",
    "href": "2.html#geo_data",
    "title": "Geoestadística Univariada con geoR",
    "section": "GEO_Data",
    "text": "GEO_Data\n\nConvertir aquifer a un objeto geodata (GeoR obj)\n\nDocumentación as.geodata\n\naquiferg &lt;- as.geodata(aquifer)\nsummary(aquiferg)\n\nNumber of data points: 85 \n\nCoordinates summary\n         Este     Norte\nmin -145.2365   9.41441\nmax  112.8045 184.76636\n\nDistance summary\n        min         max \n  0.2211656 271.0615463 \n\nData summary\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n1024.000 1548.000 1797.000 2002.282 2540.000 3571.000",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Geoestadística </span>",
      "<span style='color: #728387 !important;'>Geoestadística Univariada con GeoR </span>"
    ]
  },
  {
    "objectID": "2.html#gráfico-de-objeto-geodata",
    "href": "2.html#gráfico-de-objeto-geodata",
    "title": "Geoestadística Univariada con geoR",
    "section": "Gráfico de objeto geodata",
    "text": "Gráfico de objeto geodata\n\nDocumentación plotgeodata\n\nGráfico del objeto geodata\n\nplot(aquiferg, qt.col = c(\"purple\",\n                         \"pink\",\n                         \"green\",\n                         \"yellow\"))\n\n\n\n\n\n\n\n\nGráfico con el parametro 3d\n\nplot(aquiferg, scatter3d = T)\n\n\n\n\n\n\n\n\nGráfico removiendo la tendencia (trend )\n\nplot(aquiferg, trend = \"1st\")",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Geoestadística </span>",
      "<span style='color: #728387 !important;'>Geoestadística Univariada con GeoR </span>"
    ]
  },
  {
    "objectID": "2.html#gráficos-descriptivos-interpolación",
    "href": "2.html#gráficos-descriptivos-interpolación",
    "title": "Geoestadística Univariada con geoR",
    "section": "Gráficos descriptivos interpolación",
    "text": "Gráficos descriptivos interpolación\n\nDocumentración Interpolación inderp\nDocumentación persp\nDocumentación drape.plot\n\n\npar(mfrow = c(2, 2),\n    mar = c(3, 3, 1, 1),\n    mgp = c(2, 1, 0))\n# Esta función agrupa los siguientes gráficos en\n# una matrix 2x2\n\ngrillas &lt;- interp(aquifer$Este,\n                  aquifer$Norte,\n                  aquifer$Profundidad)\n\npersp(grillas$x,\n      grillas$y,\n      grillas$z,\n      xlab = \"Este\",\n      ylab = \"Norte\",\n      zlab = \"Nivel freatico\",\n      phi = 30,\n      theta = 20,\n      col = \"lightblue\",\n      expand = .5,\n      ticktype = \"detailed\")\n\ndrape.plot(grillas$x,\n           grillas$y,\n           grillas$z,\n           xlab = \"Este\",\n           ylab = \"Norte\",\n           zlab = \"z\",\n           theta = 45,\n           col = topo.colors(64),\n           expand = .5,\n           ticktype = \"detailed\")\n\n\ndrape.plot(grillas$x,\n           grillas$y,\n           grillas$z,\n           xlab = \"Este\",\n           ylab = \"Norte\",\n           zlab = \"z\",\n           theta = -10,\n           col = topo.colors(64),\n           expand = .5,\n           ticktype = \"detailed\")\n\n\ndrape.plot(grillas$x,\n           grillas$y,\n           grillas$z,\n           xlab = \"Este\",\n           ylab = \"Norte\",\n           zlab = \"z\",\n           theta = 60,\n           col = topo.colors(64),\n           expand = .5,\n           ticktype = \"detailed\")",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Geoestadística </span>",
      "<span style='color: #728387 !important;'>Geoestadística Univariada con GeoR </span>"
    ]
  },
  {
    "objectID": "2.html#gráficos-de-contorno",
    "href": "2.html#gráficos-de-contorno",
    "title": "Geoestadística Univariada con geoR",
    "section": "Gráficos de contorno",
    "text": "Gráficos de contorno\n\nDocumentación contour\nDocumentación filled.contour\n\n\npar(mfrow = c(2, 1),\n    mar = c(1,1,1,1))\n\ncontour(grillas, nlevels = 10, main = \"Contorno\")\nimage(grillas$z, main =  \"Grilla\")\n\n\n\n\n\n\n\n\n\nfilled.contour(grillas, levels = seq(1000,\n                                     5000,\n                                     len = 10),\n               col = heat.colors(10),\n                main = \"grilla niveles\")\n\n\n\n\n\n\n\n\n\nFunciones y gráficas a partir de la función outer\n\nh &lt;- seq(0, 1, len = 50)\nu &lt;- seq(0, 1, len = 50)\n\nejemplo1CH  &lt;- function(h, u, sigma, a, b, c, d, delta) {\n    (sigma^2/((a^2*u^2+c)^(d/2)))*exp(-(b^2*h^2)/(a^2*u^2+c))*exp(-delta*u^2)\n    }\nh &lt;- seq(0, 1, len = 20)\nu &lt;- seq(1, 10, len = 20)\nf &lt;- outer(h, u, ejemplo1CH, sigma=3, a=1, b=3, c=1, d=2, delta=0)\n\npar(mfrow = c(2, 2),\n    mar = c(3, 3, 1, 1),\n    mgp = c(2, 1, 0))\n\ndrape.plot(h,\n           u,\n           f,\n           main = \"Cressie-Huang; 1 (25,1,0.6)\",\n           xlab = \"h\",\n           ylab = \"u\",\n           zlab = \"Covarianza\",\n           ltheta = 75,\n           col = terrain.colors(64))\n\ndrape.plot(h,\n           u,\n           f,\n           main = \"Cressie-Huang; 1 (25,1,0.6)\",\n           xlab = \"h\",\n           ylab = \"u\",\n           zlab = \"Covarianza\",\n           theta = -150,\n           col = terrain.colors(64))\npersp(h,\n      u,\n      f,\n      main = \"Cressie-Huang; 1 (25,1,0.6)\",\n      xlab = \"h\",\n      ylab = \"u\",\n      zlab = \"Covarianza\",\n      ltheta = 75)\n\ncontour(h,\n        u,\n        f,\n        col = topo.colors(10),\n        xlim = c(0,0.6))",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Geoestadística </span>",
      "<span style='color: #728387 !important;'>Geoestadística Univariada con GeoR </span>"
    ]
  },
  {
    "objectID": "2.html#modelando-la-media-con-regresión-polinomial",
    "href": "2.html#modelando-la-media-con-regresión-polinomial",
    "title": "Geoestadística Univariada con geoR",
    "section": "Modelando la media con regresión polinomial",
    "text": "Modelando la media con regresión polinomial\n\nPrimer modelo\n\nreg1 &lt;- lm(Profundidad ~ Este + Norte, data = aquifer)\nresiduales1  &lt;-  residuals(reg1)\nsummary(reg1)\n\n\nCall:\nlm(formula = Profundidad ~ Este + Norte, data = aquifer)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-366.96 -161.53  -30.71  148.15  651.20 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 2591.4302    38.9599   66.52   &lt;2e-16 ***\nEste          -6.7514     0.3438  -19.64   &lt;2e-16 ***\nNorte         -5.9872     0.4066  -14.73   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 203.3 on 82 degrees of freedom\nMultiple R-squared:  0.8921,    Adjusted R-squared:  0.8894 \nF-statistic: 338.9 on 2 and 82 DF,  p-value: &lt; 2.2e-16\n\n\n\nanova(reg1)\n\nAnalysis of Variance Table\n\nResponse: Profundidad\n          Df   Sum Sq  Mean Sq F value    Pr(&gt;F)    \nEste       1 19045642 19045642  460.95 &lt; 2.2e-16 ***\nNorte      1  8960172  8960172  216.86 &lt; 2.2e-16 ***\nResiduals 82  3388069    41318                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nSegundo modelo\n\nreg2 &lt;- lm(Profundidad ~ Este + Norte +\n           I(Este^2) + I(Norte^2) +\n           I(Este * Norte),\n           data = aquifer)\nresiduales2  &lt;-  residuals(reg2)\nsummary(reg2)\n\n\nCall:\nlm(formula = Profundidad ~ Este + Norte + I(Este^2) + I(Norte^2) + \n    I(Este * Norte), data = aquifer)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-407.43 -138.76   -5.74  128.84  648.16 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      2.481e+03  6.813e+01  36.424  &lt; 2e-16 ***\nEste            -8.374e+00  5.525e-01 -15.157  &lt; 2e-16 ***\nNorte           -2.043e+00  1.764e+00  -1.159 0.250146    \nI(Este^2)        1.417e-03  4.987e-03   0.284 0.777096    \nI(Norte^2)      -2.464e-02  9.298e-03  -2.650 0.009708 ** \nI(Este * Norte)  2.680e-02  7.413e-03   3.616 0.000526 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 185.9 on 79 degrees of freedom\nMultiple R-squared:  0.9131,    Adjusted R-squared:  0.9076 \nF-statistic:   166 on 5 and 79 DF,  p-value: &lt; 2.2e-16\n\n\n\nanova(reg2)\n\nAnalysis of Variance Table\n\nResponse: Profundidad\n                Df   Sum Sq  Mean Sq  F value    Pr(&gt;F)    \nEste             1 19045642 19045642 551.3469 &lt; 2.2e-16 ***\nNorte            1  8960172  8960172 259.3855 &lt; 2.2e-16 ***\nI(Este^2)        1    55368    55368   1.6028 0.2092235    \nI(Norte^2)       1   152170   152170   4.4051 0.0390253 *  \nI(Este * Norte)  1   451567   451567  13.0723 0.0005259 ***\nResiduals       79  2728964    34544                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nTercer modelo\n\nreg3 &lt;- lm(Profundidad ~ Este * Norte,\n           data = aquifer)\nresiduales3  &lt;-  residuals(reg3)\nsummary(reg3)\n\n\nCall:\nlm(formula = Profundidad ~ Este * Norte, data = aquifer)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-406.30 -138.88  -13.04  129.36  722.48 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  2.627e+03  3.833e+01  68.546  &lt; 2e-16 ***\nEste        -8.287e+00  5.658e-01 -14.646  &lt; 2e-16 ***\nNorte       -6.649e+00  4.327e-01 -15.366  &lt; 2e-16 ***\nEste:Norte   2.452e-02  7.401e-03   3.314  0.00138 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 191.9 on 81 degrees of freedom\nMultiple R-squared:  0.905, Adjusted R-squared:  0.9014 \nF-statistic: 257.1 on 3 and 81 DF,  p-value: &lt; 2.2e-16\n\n\n\nanova(reg3)\n\nAnalysis of Variance Table\n\nResponse: Profundidad\n           Df   Sum Sq  Mean Sq F value    Pr(&gt;F)    \nEste        1 19045642 19045642  517.06 &lt; 2.2e-16 ***\nNorte       1  8960172  8960172  243.25 &lt; 2.2e-16 ***\nEste:Norte  1   404448   404448   10.98  0.001379 ** \nResiduals  81  2983621    36835                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Geoestadística </span>",
      "<span style='color: #728387 !important;'>Geoestadística Univariada con GeoR </span>"
    ]
  },
  {
    "objectID": "2.html#estimación-del-semivariograma-empírico",
    "href": "2.html#estimación-del-semivariograma-empírico",
    "title": "Geoestadística Univariada con geoR",
    "section": "Estimación del semivariograma empírico",
    "text": "Estimación del semivariograma empírico\n\nDocumentación variog\n\nvari2 &lt;- variog(aquiferg, trend = \"1st\")\n\nvariog: computing omnidirectional variogram\n\n\n\nvari2Cloud &lt;- variog(aquiferg, op = \"cloud\", trend = \"1st\")\n\nvariog: computing omnidirectional variogram\n\n\n\nvari2BinCloud &lt;- variog(aquiferg,\n                       max.dist = 200,\n                       op = \"cloud\",\n                       bin.cloud = TRUE)\n\nvariog: computing omnidirectional variogram\n\n\n\nvari2Sm &lt;- variog(aquiferg,\n                  trend = \"1st\",\n                  op = \"sm\",\n                  band=11)\n\nvariog: computing omnidirectional variogram\n\n\n\npar(mfrow = c(2, 2), mar = c(3, 3, 1, 1), mgp = c(2, 1, 0))\n     plot(vari2$u, vari2$v, main = \"binned variogram\") \n     plot(vari2Cloud$u, vari2Cloud$v, main = \"variogram cloud\")\n     plot(vari2BinCloud$u, vari2BinCloud$v, main = \"clouds for binned variogram\")\n     plot(vari2Sm$u, vari2Sm$v, main = \"smoothed variogram\")\n\n\n\n\n\n\n\n\n\n\nExplorando estimación clásica, removiendo tendencia\n\nvari1 &lt;- variog(aquiferg)\n\nvariog: computing omnidirectional variogram\n\n\n\nvari2 &lt;- variog(aquiferg, trend = \"1st\")\n\nvariog: computing omnidirectional variogram\n\n\n\nvari3 &lt;- variog(aquiferg, trend = \"2nd\")\n\nvariog: computing omnidirectional variogram\n\n\n\nplot(vari1$u,vari1$v, main = \"Sin remover tendencia\")\n\n\n\n\n\n\n\n\n\nplot(vari2$u,vari2$v, main  = \"Trend 1 \")\n\n\n\n\n\n\n\n\n\nplot(vari3$u,vari3$v, main  = \"Trend 2 \")\n\n\n\n\n\n\n\n\n\n\nExplorando estimación resistente a datos atípicos y removiendo tendencia\n\nvari1 &lt;- variog(aquiferg, estimator.type = \"modulus\")\n\nvariog: computing omnidirectional variogram\n\n\n\nvari2 &lt;- variog(aquiferg, trend = \"1st\", estimator.type = \"modulus\")\n\nvariog: computing omnidirectional variogram\n\n\n\nvari3 &lt;- variog(aquiferg, trend = \"2nd\", estimator.type = \"modulus\")\n\nvariog: computing omnidirectional variogram\n\n\n\nplot(vari1$u,vari1$v, main = \"Sin remover tendencia\")\n\n\n\n\n\n\n\n\n\nplot(vari2$u,vari2$v, main  = \"Trend 1 \")\n\n\n\n\n\n\n\n\n\nplot(vari3$u,vari3$v, main  = \"Trend 2 \")",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Geoestadística </span>",
      "<span style='color: #728387 !important;'>Geoestadística Univariada con GeoR </span>"
    ]
  },
  {
    "objectID": "2.html#explorando-anisotropía",
    "href": "2.html#explorando-anisotropía",
    "title": "Geoestadística Univariada con geoR",
    "section": "Explorando anisotropía",
    "text": "Explorando anisotropía\n\nvari_0 &lt;- variog(aquiferg,\n                 trend = \"1st\",\n                 max.dist = 200,\n                 dir = 0)\n\nvariog: computing variogram for direction = 0 degrees (0 radians)\n        tolerance angle = 22.5 degrees (0.393 radians)\n\n\n\nvari_45 &lt;- variog(aquiferg,\n                  trend = \"1st\",\n                  max.dist = 200,\n                  dir = pi / 4)\n\nvariog: computing variogram for direction = 45 degrees (0.785 radians)\n        tolerance angle = 22.5 degrees (0.393 radians)\n\n\n\nvari_90 &lt;- variog(aquiferg,\n                  trend = \"1st\",\n                  max.dist = 200,\n                  dir = pi / 2)\n\nvariog: computing variogram for direction = 90 degrees (1.571 radians)\n        tolerance angle = 22.5 degrees (0.393 radians)\n\n\n\nvari_135 &lt;- variog(aquiferg,\n                   trend = \"1st\",\n                   max.dist = 200,\n                   dir = 3 * pi / 4)\n\nvariog: computing variogram for direction = 135 degrees (2.356 radians)\n        tolerance angle = 22.5 degrees (0.393 radians)\n\n\n\npar(mfrow = c(2, 2),\n    mar = c(3, 3, 1, 1),\n    mgp = c(2, 1, 0))\n\nplot(vari_0$u,vari_0$v, main = \"vari 0\")\nplot(vari_45$u,vari_45$v, main = \"vari 45\")\nplot(vari_90$u,vari_90$v, main = \"vari 90\")\nplot(vari_135$u,vari_135$v, main = \"vari 195\")",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Geoestadística </span>",
      "<span style='color: #728387 !important;'>Geoestadística Univariada con GeoR </span>"
    ]
  },
  {
    "objectID": "2.html#estimación-teórica-del-semivariograma",
    "href": "2.html#estimación-teórica-del-semivariograma",
    "title": "Geoestadística Univariada con geoR",
    "section": "Estimación teórica del semivariograma",
    "text": "Estimación teórica del semivariograma\n\nDocumentación eyefit\nDocumentación variofit\nDocumentación likfit\n\n\nvar1 &lt;- variog(aquiferg,trend=\"1st\",max.dist=200)\n\nvariog: computing omnidirectional variogram\n\n\n\n#ini1 &lt;- eyefit(var1)\n#cov.model  sigmasq phi   tausq kappa kappa2   practicalRange\n#1      wave 30805.52  13 8984.94  &lt;NA&gt;   &lt;NA&gt; 38.8889336320589\nini1 &lt;- c(30805.52, 13)\nfitvar1 &lt;- variofit(var1,\n                    cov.model = \"wave\",\n                    ini1,\n                    fix.nugget = TRUE,\n                    nugget = 8984.94,\n                    wei = \"equal\")\n\nvariofit: covariance model used is wave \nvariofit: weights used: equal \nvariofit: minimisation function used: optim \n\n\n\nfitvar2 &lt;- variofit(var1,\n                    cov.model = \"wave\",\n                    ini1,\n                    fix.nugget = TRUE,\n                    nugget = 8984.94,\n                    wei = \"npairs\")\n\nvariofit: covariance model used is wave \nvariofit: weights used: npairs \nvariofit: minimisation function used: optim \n\n\n\nfitvar3 &lt;- variofit(var1,\n                    ini1,\n                    fix.nugget = TRUE,\n                    nugget = 8984.94,\n                    wei = \"cressie\")\n\nvariofit: covariance model used is matern \nvariofit: weights used: cressie \nvariofit: minimisation function used: optim \n\n\n\nfitvar4 &lt;- likfit(aquiferg,\n                  coords = aquiferg$coords,\n                  data = aquiferg$data,\n                  trend = \"1st\",\n                  ini.cov.pars = ini1,\n                  fix.nugget = T,\n                  nugget = 8984.94,\n                  cov.model = \"wave\",\n                  lik.method = \"ML\")\n\nkappa not used for the wave correlation function\n---------------------------------------------------------------\nlikfit: likelihood maximisation using the function optim.\nlikfit: Use control() to pass additional\n         arguments for the maximisation function.\n        For further details see documentation for optim.\nlikfit: It is highly advisable to run this function several\n        times with different initial values for the parameters.\nlikfit: WARNING: This step can be time demanding!\n---------------------------------------------------------------\nlikfit: end of numerical maximisation.\n\n\n\nfitvar5 &lt;- likfit(aquiferg,\n                  coords = aquiferg$coords,\n                  data = aquiferg$data,\n                  trend = \"1st\",\n                  ini.cov.pars = ini1,\n                  fix.nugget = T,\n                  nugget = 8984.94,\n                  cov.model = \"wave\",\n                  lik.method = \"REML\")\n\nkappa not used for the wave correlation function\n---------------------------------------------------------------\nlikfit: likelihood maximisation using the function optim.\nlikfit: Use control() to pass additional\n         arguments for the maximisation function.\n        For further details see documentation for optim.\nlikfit: It is highly advisable to run this function several\n        times with different initial values for the parameters.\nlikfit: WARNING: This step can be time demanding!\n---------------------------------------------------------------\nlikfit: end of numerical maximisation.\n\n\n\nplot(var1$u,var1$v,\n     xlab = \"h\",\n     ylab = \"semivarianza\",\n     cex.lab = 1.3,\n     cex.axis = 1.2,\n     main = \"Estimación teórica del modelo de semivariograma\",\n     col.main = 4, cex.main =1.3)\nlines(fitvar1, col = 1)\nlines(fitvar2, col = 2)\nlines(fitvar3, col = 3)\nlines(fitvar4, col = 4)\nlines(fitvar5, col = 5)\nlegend(130, 18000,\n       c(\"MCO\", \"MCPnpairs\", \"MCPcressie\", \"ML\", \"REML\"),\n       lwd = 2,\n       lty = 2:7,\n       col = 2:7,\n       box.col = 9,\n       text.col = 2:7)",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Geoestadística </span>",
      "<span style='color: #728387 !important;'>Geoestadística Univariada con GeoR </span>"
    ]
  },
  {
    "objectID": "2.html#resultados",
    "href": "2.html#resultados",
    "title": "Geoestadística Univariada con geoR",
    "section": "Resultados",
    "text": "Resultados\n\n#summary(fitvar1)\n#summary(fitvar2)\n#summary(fitvar3)\n#summary(fitvar4)\n#summary(fitvar5)",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Geoestadística </span>",
      "<span style='color: #728387 !important;'>Geoestadística Univariada con GeoR </span>"
    ]
  },
  {
    "objectID": "2.html#pulimiento-de-medianas",
    "href": "2.html#pulimiento-de-medianas",
    "title": "Geoestadística Univariada con geoR",
    "section": "Pulimiento de medianas",
    "text": "Pulimiento de medianas\nEsta es una alternativa al modelamiento de la media cuando los modelos de regresión polinómicos usuales no logran el objetivo de eliminar la tendencia ya sea porque el tipo de tendencia corresponde mas a unas ventanas móviles o porque hay presentes datos atípicos.\n\nCargar librerias\nLista de librerías con link a la documentación.\n\nrm(list=ls())\nlibrary(gstat)\n\nWarning: package 'gstat' was built under R version 4.4.3\n\nlibrary(sp)\n\nWarning: package 'sp' was built under R version 4.4.3\n\nlibrary(mvtnorm)\n\nWarning: package 'mvtnorm' was built under R version 4.4.2\n\n\n\nAdjuntando el paquete: 'mvtnorm'\n\n\nThe following objects are masked from 'package:spam':\n\n    rmvnorm, rmvt\n\n\n\ngstat\nsp\n\n\n\nGrilla de las ubicaciones espaciales.\n\nn_x &lt;- 4\nn_y &lt;- 6\nx &lt;- seq(0, 1, len = n_x)\ny &lt;- seq(0, 1, len = n_y)\ncoordenadas &lt;- as.data.frame(expand.grid(x, y))\nnames(coordenadas) &lt;- c(\"X\", \"Y\")\n\n\n\nDefinición de objeto VGM\nEsto define un objeto vgm que es el tipo de objeto que usa el paquete gstat para los modelos teóricos de variograma. Con este objeto se pueden definir modelos anidados.\n\nvgm\n\n\nvario &lt;- vgm(10, # Punto de silla\n             \"Exp\", # Modelo, ver documentación\n             0.5)  # Rango\nprint(vario)\n\n  model psill range\n1   Exp    10   0.5\n\n\n\n\nMatriz de varianza dadas coordenadas.\n\nvgmArea\ncoordinates\n\ncoordinates(coordenadas) &lt;- ~X + Y\n#class(coordenadas) # Cambio de objedto dataframe a sp\n\n\ncov_mat &lt;- vgmArea(coordenadas, # Matriz de ubiaciones SP\n        vgm = vario) # VGM object\n\nprint(dim(cov_mat))\n\n[1] 24 24\n\n\n\n\n\nSimulación\nSimulación dada la media y la matriz de varianza\n\nmu  &lt;- rep(0, n_x * n_y) # Media del proceso\nsimu &lt;- rmvnorm(1,\n                mean = mu,\n                sigma = cov_mat)\nprint(simu[1:5])\n\n[1] -2.643498 -2.366024  1.743884 -7.470776 -4.988423\n\n\n\n\nPulimiento de medianas\nUnir las coordenadas con la columna de simulación\n\ndata &lt;- as.data.frame(cbind(coordenadas@coords,\n                            Simula = t(simu)))\nnames(data) &lt;- c(\"X\", \"Y\", \"Var\")\nprint(head(data))\n\n          X   Y       Var\n1 0.0000000 0.0 -2.643498\n2 0.3333333 0.0 -2.366024\n3 0.6666667 0.0  1.743884\n4 1.0000000 0.0 -7.470776\n5 0.0000000 0.2 -4.988423\n6 0.3333333 0.2 -6.201843\n\n\nReshape para matriz, esto transforma la tabla de datos en matriz\n\ntabla &lt;- reshape2::dcast(data,\n                         X ~ Y,\n                         value.var = \"Var\")\nrownames(tabla) &lt;- tabla[, 1]\ntabla &lt;- tabla[, c(-1)]\nprint(tabla)\n\n                          0        0.2        0.4        0.6       0.8\n0                 -2.643498 -4.9884231  2.6290265  2.8093060 -3.990201\n0.333333333333333 -2.366024 -6.2018433  0.5502774  0.1913482  3.597712\n0.666666666666667  1.743884  0.4797224 -0.2919147 -2.9442832 -0.927355\n1                 -7.470776 -4.7242224 -0.1812142  0.1333725 -3.129286\n                          1\n0                 -1.045584\n0.333333333333333  1.415650\n0.666666666666667  4.324694\n1                  1.152873\n\n\nPulimiento de medianas de la tabla\n\nmed &lt;- medpolish(tabla)\n\n1: 43.2713\n2: 37.2951\n3: 36.38581\nFinal: 36.25004\n\n\n\ngeo_data &lt;- reshape2::melt(med$residuals)\nprint(med)\n\n\nMedian Polish Results (Dataset: \"tabla\")\n\nOverall: -1.144824\n\nRow Effects:\n                0 0.333333333333333 0.666666666666667                 1 \n       -0.2809354         0.1086863         2.6884341        -0.1086863 \n\nColumn Effects:\n        0       0.2       0.4       0.6       0.8         1 \n-1.273813 -3.516688  1.329356  1.307184 -2.173371  2.429086 \n\nResiduals:\n                          0       0.2      0.4       0.6      0.8         1\n0                  0.056074 -0.045976  2.72543  2.927881 -0.39107 -2.048910\n0.333333333333333 -0.056074 -1.649018  0.25706 -0.079698  6.80722  0.022702\n0.666666666666667  1.474086  2.452800 -3.16488 -5.795078 -0.29759  0.351998\n1                 -4.943453  0.045976 -0.25706  0.079698  0.29759 -0.022702\n\n\nReshape de los datos, con efecto de la fila y la columna\n\ntabla_residuales &lt;- as.data.frame(med$residuals)\nnames(tabla_residuales) &lt;- med$col\nrownames(tabla_residuales) &lt;- med$row\ngeo_data &lt;- reshape2::melt(as.matrix(tabla_residuales))\n\ngeo_data &lt;- cbind(data,\n                  geo_data,\n                  med$overall)\nnames(geo_data) &lt;- c(\"X\",\n                     \"Y\",\n                     \"Var\",\n                     \"Efecto fila\",\n                     \"Efecto columa\",\n                     \"Residual\",\n                     \"Efecto Global\")\nprint(geo_data)\n\n           X   Y        Var Efecto fila Efecto columa    Residual Efecto Global\n1  0.0000000 0.0 -2.6434981  -0.2809354     -1.273813  0.05607397     -1.144824\n2  0.3333333 0.0 -2.3660244   0.1086863     -1.273813 -0.05607397     -1.144824\n3  0.6666667 0.0  1.7438838   2.6884341     -1.273813  1.47408641     -1.144824\n4  1.0000000 0.0 -7.4707763  -0.1086863     -1.273813 -4.94345331     -1.144824\n5  0.0000000 0.2 -4.9884231  -0.2809354     -3.516688 -0.04597581     -1.144824\n6  0.3333333 0.2 -6.2018433   0.1086863     -3.516688 -1.64901769     -1.144824\n7  0.6666667 0.2  0.4797224   2.6884341     -3.516688  2.45280020     -1.144824\n8  1.0000000 0.2 -4.7242224  -0.1086863     -3.516688  0.04597581     -1.144824\n9  0.0000000 0.4  2.6290265  -0.2809354      1.329356  2.72543029     -1.144824\n10 0.3333333 0.4  0.5502774   0.1086863      1.329356  0.25705953     -1.144824\n11 0.6666667 0.4 -0.2919147   2.6884341      1.329356 -3.16488039     -1.144824\n12 1.0000000 0.4 -0.1812142  -0.1086863      1.329356 -0.25705953     -1.144824\n13 0.0000000 0.6  2.8093060  -0.2809354      1.307184  2.92788109     -1.144824\n14 0.3333333 0.6  0.1913482   0.1086863      1.307184 -0.07969840     -1.144824\n15 0.6666667 0.6 -2.9442832   2.6884341      1.307184 -5.79507758     -1.144824\n16 1.0000000 0.6  0.1333725  -0.1086863      1.307184  0.07969840     -1.144824\n17 0.0000000 0.8 -3.9902008  -0.2809354     -2.173371 -0.39107090     -1.144824\n18 0.3333333 0.8  3.5977122   0.1086863     -2.173371  6.80722048     -1.144824\n19 0.6666667 0.8 -0.9273550   2.6884341     -2.173371 -0.29759449     -1.144824\n20 1.0000000 0.8 -3.1292863  -0.1086863     -2.173371  0.29759449     -1.144824\n21 0.0000000 1.0 -1.0455840  -0.2809354      2.429086 -2.04891043     -1.144824\n22 0.3333333 1.0  1.4156504   0.1086863      2.429086  0.02270233     -1.144824\n23 0.6666667 1.0  4.3246937   2.6884341      2.429086  0.35199779     -1.144824\n24 1.0000000 1.0  1.1528733  -0.1086863      2.429086 -0.02270233     -1.144824\n\n\nValidación de la descomposición\n\nvalida &lt;- cbind(geo_data$Var,\n                geo_data[[\"Efecto fila\"]] +\n                geo_data[[\"Efecto columa\"]] +\n                geo_data[[\"Residual\"]] +\n                geo_data[[\"Efecto Global\"]])\nvalida &lt;- as.data.frame(valida)\nnames(valida) &lt;- c(\"datos\", \"suma\")\nprint(valida)\n\n        datos       suma\n1  -2.6434981 -2.6434981\n2  -2.3660244 -2.3660244\n3   1.7438838  1.7438838\n4  -7.4707763 -7.4707763\n5  -4.9884231 -4.9884231\n6  -6.2018433 -6.2018433\n7   0.4797224  0.4797224\n8  -4.7242224 -4.7242224\n9   2.6290265  2.6290265\n10  0.5502774  0.5502774\n11 -0.2919147 -0.2919147\n12 -0.1812142 -0.1812142\n13  2.8093060  2.8093060\n14  0.1913482  0.1913482\n15 -2.9442832 -2.9442832\n16  0.1333725  0.1333725\n17 -3.9902008 -3.9902008\n18  3.5977122  3.5977122\n19 -0.9273550 -0.9273550\n20 -3.1292863 -3.1292863\n21 -1.0455840 -1.0455840\n22  1.4156504  1.4156504\n23  4.3246937  4.3246937\n24  1.1528733  1.1528733",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Geoestadística </span>",
      "<span style='color: #728387 !important;'>Geoestadística Univariada con GeoR </span>"
    ]
  },
  {
    "objectID": "3.html",
    "href": "3.html",
    "title": "Kriging_puntual",
    "section": "",
    "text": "Kriging\nKriging es una técnica de interpolación espacial que permite estimar valores desconocidos en una superficie a partir de los valores conocidos en ubicaciones cercanas. Es especialmente útil para datos de alta densidad y para datos con estructuras espaciales complejas. En este cuaderno, vamos a explorar los diferentes tipos de Kriging y cómo implementarlos en R.\nAntes de comenzar, asegúrate de tener instalados los siguientes paquetes de R: “gstat”, “sp”, “raster” y “ggplot2”. Si no los tienes, puedes instalarlos mediante el siguiente código:\n# Instalar paquetes si es necesario\n\nlibrary(gstat)\nlibrary(sp)\nlibrary(raster)\nlibrary(ggplot2)\nlibrary(phylin)\n# Generación de datos simulados para los ejemplos\nset.seed(1029)\ncoords &lt;- data.frame(x = runif(10, 0, 100), y = runif(10, 0, 100))\nvalues &lt;- data.frame(value = rnorm(10))\n\n# Combinar 'coords' y 'values' en un solo data frame\ndata &lt;- cbind(coords, values)\n\n# Convertir 'data' en un objeto espacial\ncoordinates(data) &lt;- ~ x + y\nproj4string(data) &lt;- CRS(\"+proj=utm +zone=33 +datum=WGS84\")",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Geoestadística </span>",
      "<span style='color: #728387 !important;'>Kriging</span>"
    ]
  },
  {
    "objectID": "3.html#introducción",
    "href": "3.html#introducción",
    "title": "Kriging_puntual",
    "section": "Introducción",
    "text": "Introducción\nKriging es una técnica de interpolación espacial que se basa en la teoría de la estadística espacial. La idea fundamental detrás de Kriging es que la estimación del valor desconocido en una ubicación dada se hace como una combinación lineal ponderada de los valores conocidos en las ubicaciones vecinas. Los pesos de esta combinación se determinan utilizando la información de covarianza entre los puntos en el espacio. Esta técnica se utiliza comúnmente en estadística espacial, geología, minería, geofísica, oceanografía y otros campos que involucran la toma de medidas en lugares dispersos en el espacio.\nEl nombre “Kriging” proviene del geólogo Danie G. Krige, quien fue el primero en aplicar esta técnica para la exploración de minerales en Sudáfrica en la década de 1950",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Geoestadística </span>",
      "<span style='color: #728387 !important;'>Kriging</span>"
    ]
  },
  {
    "objectID": "3.html#kriging-simple",
    "href": "3.html#kriging-simple",
    "title": "Kriging_puntual",
    "section": "Kriging Simple",
    "text": "Kriging Simple\nEn esta sección se explica el método de kriging simple, que es una técnica de interpolación espacial que utiliza una función de tendencia conocida y un modelo de variograma ajustado a los datos. El objetivo es estimar el valor de una variable Z en una ubicación s0 a partir de los valores observados en n ubicaciones si cercanas. El kriging simple asume que la variable Z se puede descomponer como:\n\\[\nZ(s) = \\mu(s) + \\varepsilon(s)\n\\]\ndonde $ \\mu(s)$ es la función de tendencia conocida y \\(\\varepsilon(s)\\) es un proceso espacial aleatorio con media cero y covarianza \\(C(s_i,s_j) = Cov(\\varepsilon(s_i),\\epsilon(s_j))\\). El predictor del kriging simple es na compinación lineal de los valoes observados:\n\\[\np(Z, s_0) = \\mu(s_0) + \\sum_{i=1}^{n} \\lambda_i (Z(s_i) - \\mu(s_i)),\n\\]\ndonde los pesos \\(\\lambda_i\\) se obtienen resolviendo el sistea de ecuaciones:\n\\[\n\\sum_{j=1}^{n} \\lambda_j C(s_i, s_j) - C(s_i, s_0) = 0, \\quad i = 1, \\dots, n.\n\\]\nEl kriging simple minimiza el error cuadrático medio entre el valo estimado y el verdadero, que se denomina varianza kriging y se calcula como:\n\\[\\sigma^{2}KS(s_{0}) = C(s_{0}, s_{0}) - \\sum_{i=1}^{n} \\sum_{j=1}^{n} \\lambda_{i} \\lambda_{j} C(s_{i}, s_{j}).\n\\]\nPara implementar el kriging simple en R se puede utilizar la función krig del paquete phylin, que requiere como argumentos los valores observados, las coordenadas de las ubicaciones muestreadas y las ubicaciones a interpolar, el modelo de variograma ajustado y el valor conocido de la media (o NA para usar kriging ordinario). A continuación se muestra un ejemplo con datos simulados:\n\n# Calcular el variograma experimental\nvgram &lt;- variogram(value ~ 1, data)\n\n# Ajustar un modelo de variograma\nmodel &lt;- vgm(psill = 1, model = \"Sph\", range = 50, nugget = 0)\nvfit &lt;- fit.variogram(vgram, model)\n\n\n# Crear una cuadrícula de predicción\ngrd &lt;- expand.grid(x = seq(0, 100, by = 5), y = seq(0, 100, by = 5))\ncoordinates(grd) &lt;- ~ x + y\ngridded(grd) &lt;- TRUE\nproj4string(grd) &lt;- CRS(\"+proj=utm +zone=33 +datum=WGS84\")\n\n# Kriging Simple\nkriged_values &lt;- krige(value ~ 1, data, grd, model = vfit, nmax = 5)\n\n[using ordinary kriging]\n\n\n\n# Visualización\nspplot(kriged_values[\"var1.pred\"], main = \"Kriging Simple Prediction\")",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Geoestadística </span>",
      "<span style='color: #728387 !important;'>Kriging</span>"
    ]
  },
  {
    "objectID": "3.html#kriging-ordinario",
    "href": "3.html#kriging-ordinario",
    "title": "Kriging_puntual",
    "section": "Kriging Ordinario",
    "text": "Kriging Ordinario\nEl kriging ordinario es el tipo más general y más utilizado de kriging. Presupone que el valor medio constante es desconocido y lo estima a partir de los datos disponibles. Esta es una suposición razonable a menos que haya una razón científica para rechazarla.\nEl kriging ordinario se puede expresar como:\n\\[\nZ^*(x_0) = \\sum_{i=1}^{n} \\lambda_i Z(x_i)\n\\]\nDonde \\(Z^*(x_0)\\) es el valor estimado en el punto \\(x_0\\), \\(Z(x_i)\\) son los valores medidos en los puntos \\(x_i\\) , \\(n\\) es el número de los puntos medidos y \\(\\lambda_i\\) son los pesos óptimos que minimizan la varianza del error de estimación.\nLos pesos óptimos se obtienen resolviendo un sistema de ecuaciones lineales conocido como sistema krigiano:}\n\\[\n\\begin{bmatrix}\n\\gamma_{11} & \\gamma_{12} & \\cdots & \\gamma_{1n} & 1 \\\\\n\\gamma_{21} & \\gamma_{22} & \\cdots & \\gamma_{2n} & 1 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots & 1 \\\\\n\\gamma_{n1} & \\gamma_{n2} & \\cdots & \\gamma_{nn} & 1 \\\\\n1 & 1 & \\cdots & 1 & 0\n\\end{bmatrix}\n\\begin{bmatrix}\n\\lambda_1 \\\\\n\\lambda_2 \\\\\n\\vdots \\\\\n\\lambda_n \\\\\nm\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n\\gamma(x_0, x_1) \\\\\n\\gamma(x_0, x_2) \\\\\n\\vdots \\\\\n\\gamma(x_0, x_n) \\\\\n-1\n\\end{bmatrix}\n\\]\ndonde \\(\\gamma_{ij}\\) son los semivariogramas entre los puntos medidos, \\(\\gamma(x_0,x_i)\\) son los semivariogramas entre el punto a estimar y los puntos medidos y \\(m\\) es un multiplicador lagrengeano que representa la estimación del valor medio constante.\nPara implementar el kriging ordinario en R, se pueden utilizar las librerías “gstat” o “kriging”. A continuación se muestra un ejemplo usando la librería “gstat”\nPar implementar el kriging ordinario en R, se pueden utilizar las librerias “gstat” o “kriging”. A continuación se muestra un ejemplo usando la librería “gstat”.\n\n# Ajustar modelo de variograma para kriging ordinario\nvgram &lt;- variogram(value ~ 1, data)\nvfit &lt;- fit.variogram(vgram, model)\n\n\n# Kriging ordinario\nkriged_values_ordinary &lt;- krige(value ~ 1, data, grd, model = vfit, nmax = 5)\n\n[using ordinary kriging]\n\n\n\n# Visualización\nspplot(kriged_values_ordinary[\"var1.pred\"], main = \"Kriging Ordinario Prediction\")",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Geoestadística </span>",
      "<span style='color: #728387 !important;'>Kriging</span>"
    ]
  },
  {
    "objectID": "3.html#kriging-universal",
    "href": "3.html#kriging-universal",
    "title": "Kriging_puntual",
    "section": "Kriging Universal",
    "text": "Kriging Universal\nEl kriging universal es una variante del kriging que permite incorporar variables auxiliares que influyen en la variable de interés. Por ejemplo, si queremos interpolar la temperatura en una región, podemos usar como variables auxiliares la altitud, la latitud o la distancia al mar. El kriging universal asume que la variable de interés se puede expresar como una combinación lineal de las variables auxiliares más un error espacialmente correlacionado. Es decir:\n\\[\nZ(s) = p \\sum_{j=0} X_j(s)\\beta_j + \\varepsilon(s),\n\\]\ndonde \\(Z(s)\\) es la variable de interés en el punto \\(s\\), \\(X_j(s)\\) son las variables auxiliares (incluyendo una constante), \\(\\beta_j\\) son los coeficientes desconocidos y \\(\\varepsilon(s)\\) es el error espacial con variograma conocido.\nPara estimar \\(Z(s_0)\\) es un punto no observado \\(s_0\\) se usa el predictor del kriging universal:\n\\[\np(Z, s_0) = \\sum_{i=1}^{n} \\lambda_i Z(s_i),\n\\]\ndonde \\(\\lambda_i\\) son los pesos que minimizan el error cuadrático medio de predicción sujeto a las restricciones:\n\\[\n\\lambda^{\\top} X = x^{\\top} 0,\n\\]\ndonde \\(X\\) es una matriz con las variables auxiliares en los puntos observados y \\(x_0\\) es un vector con las variables auxiliares en el punto \\(s_0\\).\nPara implementar el kriging universal en R, podemos usar el paquete gstat y la función krige. Esta función requiere una formula que defina la variable dependiente como un modelo lineal de las variables independientes, un bjeto espacial con las coordenadas y los datos observados, un objeto espacial con las coordenadas de los puntos a predecir y un modelo de variograma para el error espacial.\nA continuación se muestra un ejemplo de cómo usar krige para realizar kriging universal con dos variables auxiliares: \\(x\\) e \\(y\\)\n\n# Añadir variables auxiliares al conjunto de datos\nvalues$x &lt;- coordinates(data)[,1]\nvalues$y &lt;- coordinates(data)[,2]\n\n# Ajustar variograma\nvgram_universal &lt;- variogram(value ~ x + y, data)\nvfit_universal &lt;- fit.variogram(vgram_universal, vgm(model = \"Sph\", psill = 1, range = 50, nugget = 0))\n\n\n# Kriging Universal\nkriged_values_universal &lt;- krige(value ~ x + y, data, grd, model = vfit_universal)\n\n[using universal kriging]\n\n\n\n# Visualización\nspplot(kriged_values_universal[\"var1.pred\"], main = \"Kriging Universal Prediction\")",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Geoestadística </span>",
      "<span style='color: #728387 !important;'>Kriging</span>"
    ]
  },
  {
    "objectID": "8-Introduccion proceso espacial bivariado.html",
    "href": "8-Introduccion proceso espacial bivariado.html",
    "title": "2  Introducción proceso espacial Bivariado",
    "section": "",
    "text": "2.1 Ubicaciones\nEn este caso se supone que ambos procesos están observados en los mismos lugares\nx=seq(0,1,len=3)\ny=seq(0,1,len=4)\ncoordenadas=expand.grid(x,y)\nMat_dist=as.matrix(dist(coordenadas))",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Geoestadística </span>",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'><span style='color: #728387 !important;'>Proceso espacial gaussiano bivariado</span></span>"
    ]
  },
  {
    "objectID": "8-Introduccion proceso espacial bivariado.html#modelo-lineal-de-coregionalización",
    "href": "8-Introduccion proceso espacial bivariado.html#modelo-lineal-de-coregionalización",
    "title": "2  Introducción proceso espacial Bivariado",
    "section": "2.2 Modelo lineal de coregionalización",
    "text": "2.2 Modelo lineal de coregionalización\n\nCova1=function(h,a){exp(-h/a)}\nCova2=function(h,a){ifelse(h &lt;= a, 1-1.5*(h/a)+0.5*(h/a)^3, 0)}\nB1=matrix(c(26.3,0.3,0.3,2.1),nrow=2,byrow=T)\nB2=matrix(c(2.1,1.3,1.3,17.5),nrow=2,byrow=T)\nMat_Cov_bloque11=B1[1,1]*Cova1(Mat_dist,1)+B2[1,1]*Cova2(Mat_dist,0.5)\nMat_Cov_bloque22=B1[2,2]*Cova1(Mat_dist,1)+B2[2,2]*Cova2(Mat_dist,0.5)\nMat_Cov_bloque12=B1[1,2]*Cova1(Mat_dist,1)+B2[1,2]*Cova2(Mat_dist,0.5)\nMat_Cov_bloque21=B1[2,1]*Cova1(Mat_dist,1)+B2[2,1]*Cova2(Mat_dist,0.5)\nMAT_COV=rbind(cbind(Mat_Cov_bloque11,Mat_Cov_bloque12),cbind(Mat_Cov_bloque21,Mat_Cov_bloque22))\ndim(MAT_COV)\n\n[1] 24 24\n\n\n\ndet(MAT_COV)\n\n[1] 3.494166e+29",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Geoestadística </span>",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'><span style='color: #728387 !important;'>Proceso espacial gaussiano bivariado</span></span>"
    ]
  },
  {
    "objectID": "8-Introduccion proceso espacial bivariado.html#simulación-de-un-proceso-gaussiano-bivariado",
    "href": "8-Introduccion proceso espacial bivariado.html#simulación-de-un-proceso-gaussiano-bivariado",
    "title": "2  Introducción proceso espacial Bivariado",
    "section": "2.3 Simulación de un proceso Gaussiano Bivariado",
    "text": "2.3 Simulación de un proceso Gaussiano Bivariado\n\nsim1=rmvnorm(1,mean=rep(0,2*nrow(coordenadas)), sigma=MAT_COV)\ndatos=cbind(coordenadas,z1=sim1[1:12],z2=sim1[13:24])",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Geoestadística </span>",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'><span style='color: #728387 !important;'>Proceso espacial gaussiano bivariado</span></span>"
    ]
  },
  {
    "objectID": "13-Gstats datos de méxico.html",
    "href": "13-Gstats datos de méxico.html",
    "title": "3  Gstats datos de méxico",
    "section": "",
    "text": "4 Ejemplo gstats\nDatos del aire de méxico del O3 del día 2020-02-10 a las 18 horas.",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Geoestadística </span>",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'><span style='color: #728387 !important;'>Ozono México</span></span>"
    ]
  },
  {
    "objectID": "13-Gstats datos de méxico.html#gráficas-descriptivas",
    "href": "13-Gstats datos de méxico.html#gráficas-descriptivas",
    "title": "3  Gstats datos de méxico",
    "section": "4.1 Gráficas descriptivas",
    "text": "4.1 Gráficas descriptivas",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Geoestadística </span>",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'><span style='color: #728387 !important;'>Ozono México</span></span>"
    ]
  },
  {
    "objectID": "4.html",
    "href": "4.html",
    "title": "Aplicación de los modelos",
    "section": "",
    "text": "Aplicación de los modelos",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Modelos de Regresión Espacial</span>",
      "<span style='color: #728387 !important;'>Aplicación de los Modelos </span>"
    ]
  },
  {
    "objectID": "4.html#estudio-de-mercadeo",
    "href": "4.html#estudio-de-mercadeo",
    "title": "Aplicación de los modelos",
    "section": "Estudio de Mercadeo",
    "text": "Estudio de Mercadeo\nEn este apartado se comparan varios tipos de modelos de regresión espacial para ver con cuál se obtiene el mejor ajuste. Se consideran modelos autoregresivos y de medias móviles así como su combinación.",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Modelos de Regresión Espacial</span>",
      "<span style='color: #728387 !important;'>Aplicación de los Modelos </span>"
    ]
  },
  {
    "objectID": "4.html#preparación",
    "href": "4.html#preparación",
    "title": "Aplicación de los modelos",
    "section": "Preparación",
    "text": "Preparación\n\nPaquetes\n\nlibrary(ggplot2)    # Graphics library\nlibrary(sf)         # Spatial data types and handling\n\n\nlibrary(mapview)    # Visualize spatial data\nlibrary(spdep)      # Diagnosing spatial dependence\n\n\nlibrary(spatialreg) # Spatial lag and spatial error model\n\n\nlibrary(readxl)\nlibrary(sp)\nlibrary(openxlsx)\nlibrary(dplyr)\n\n\nlibrary(GISTools)\nlibrary(spdep)\nlibrary(car)\n\n\nlibrary(psych)\n\n\nlibrary(FactoClass)\n\n\nrequire(\"GWmodel\")\n\n\nlibrary(viridis)\n\n\nlibrary(SpatFD)\nlibrary(ggspatial)\n\nEn este paso, se cargan los datos principales desde un archivo Excel (BASE.xlsx) y se leen las fronteras geográficas de Colombia por departamentos usando un archivo shapefile. Los datos espaciales en formato shapefile son cargados con la función st_read de la librería sf.\n\n# Lectura de Datos\nBASE &lt;- read_excel(\"data/BASE.xlsx\")\n# Lectura del Shape de Colombia por Departamentos\nColombia = st_read(dsn = \"data/Geodatabase Colombia\", \n                   layer = \"departamentos\")\n\nReading layer `departamentos' from data source \n  `C:\\Users\\josep_o4goibb\\Documents\\spatfd-book-quarto\\data\\Geodatabase Colombia' \n  using driver `ESRI Shapefile'\nSimple feature collection with 33 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 166883.7 ymin: 23827.08 xmax: 1804084 ymax: 1984107\nCRS:           NA\n\n\n\n\nCruce de información y arreglo de coordenada\nRealizamos un cruce de los datos de los departamentos de Colombia con los datos de mercado. Además, se transforma el sistema de coordenadas geográficas de los datos al sistema UTM (Universal Transverse Mercator) para mejorar la precisión en los cálculos espaciales. Esto es especialmente relevante en análisis de distancias y vecindades.\n\nInsumo = merge(Colombia, BASE, by.x=\"COD_DANE\", by.y=\"Cod\")\nInsumo = subset(Insumo[c(1:31,33),])\n# Conversión a Coordenadas UTM\nCrs.geo &lt;- \"+proj=tmerc +lat_0=4.599047222222222 +lon_0=-74.08091666666667 +k=1 +x_0=1000000 +y_0=1000000 +ellps=intl +towgs84=307,304,-318,0,0,0,0 +units=m +no_defs\"\nst_crs(Insumo) &lt;- Crs.geo\nInsumo.utm &lt;- st_transform(Insumo, crs = 3724)",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Modelos de Regresión Espacial</span>",
      "<span style='color: #728387 !important;'>Aplicación de los Modelos </span>"
    ]
  },
  {
    "objectID": "4.html#mapa-de-valores-observados",
    "href": "4.html#mapa-de-valores-observados",
    "title": "Aplicación de los modelos",
    "section": "Mapa de valores observados",
    "text": "Mapa de valores observados\n\n#  Mapa de Valores Observados\n#dev.new() #windows()\nggplot(Insumo) +\n  geom_sf(aes(fill = CAP_BAC)) +\n  \n  scale_fill_viridis_c(option='viridis') +  # Escala de colores para la variable\n  labs(fill = \"Valores Locales\") +\n  theme_minimal() +\n  ggtitle(\"Valores Observados para las captaciones del banco agrario\\nen Colombia, cuarto trimestre 2020\") +\n  \n  # Añadir la leyenda personalizada\n  theme(legend.position = \"right\") +\n  \n  # Añadir escala\n  annotation_scale(location = \"bl\", width_hint = 0.15) +\n  annotation_north_arrow(location = \"tr\", which_north = \"true\", height = unit(1, \"cm\"), width = unit(1, \"cm\"))",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Modelos de Regresión Espacial</span>",
      "<span style='color: #728387 !important;'>Aplicación de los Modelos </span>"
    ]
  },
  {
    "objectID": "4.html#matriz-de-vecindades",
    "href": "4.html#matriz-de-vecindades",
    "title": "Aplicación de los modelos",
    "section": "Matriz de vecindades",
    "text": "Matriz de vecindades\nEn el análisis espacial, las matrices de vecindad son estructuras que definen las relaciones espaciales entre las unidades de observación. En este caso, cada departamento de Colombia tiene una “vecindad” que se define por su proximidad a otros departamentos.\nCentroides de las Áreas: Primero, calculamos los centroides de cada uno de los polígonos (departamentos) usando st_centroid(). Los centroides son los puntos centrales de los polígonos, lo que nos permite calcular distancias entre ellos.\nMatriz de Distancias: Usamos st_distance() para calcular la matriz de distancias entre los centroides de los departamentos. Esto nos da una medida de la cercanía geográfica entre las unidades.\nMatriz de Vecindades (Insumo.nb): Se utiliza la función poly2nb() del paquete spdep para crear una lista de vecinos basada en la geometría de los departamentos. El parámetro queen = TRUE asegura que un departamento se considere vecino de otro si comparten una frontera común o un vértice.\n\n## Centroides de las Áreas\nCentroids &lt;- st_centroid(Insumo.utm)\n\nWarning: st_centroid assumes attributes are constant over geometries\n\n\n\n# Matriz de Distancias entre los Centroides\nWdist &lt;- st_distance(Centroids)\n\n# Matriz W de vecindades\nInsumo.nb &lt;- poly2nb(Insumo.utm, queen = TRUE)\n\nWarning in poly2nb(Insumo.utm, queen = TRUE): some observations have no neighbours;\nif this seems unexpected, try increasing the snap argument.\n\n\nWarning in poly2nb(Insumo.utm, queen = TRUE): neighbour object has 2 sub-graphs;\nif this sub-graph count seems unexpected, try increasing the snap argument.\n\n\n\nTipos de Matrices de Vecindad\nLas matrices de vecindad pueden definirse de diferentes maneras. Aquí se muestran algunas opciones comunes:\nMatriz binaria de vecindad: Una matriz donde los valores son 1 si los departamentos son vecinos (según la geometría), y 0 si no lo son. Esto es útil para análisis como los modelos de regresión espacial, donde la vecindad puede influir en la variable dependiente.\n\nDepartamentos &lt;- Insumo$Departamento\n\nn &lt;- length(Insumo.nb)\nMatW &lt;- matrix(0, n, n, dimnames = list(Departamentos, Departamentos))\n\nfor (i in 1:n) {\n  vecinos &lt;- Insumo.nb[[i]]\n  MatW[i, vecinos] &lt;- 1\n}\n\n\nMatrices de Vecindad Ponderadas\n Existen varios tipos de ponderación para las matrices de vecindad, que reflejan diferentes grados de proximidad entre los departamentos. Estas ponderaciones pueden basarse en distancias o en relaciones de contigüidad. Los estilos más comunes son:\n\nEstilo “B” (Binary): Simplemente indica si dos departamentos son vecinos o no (como la matriz binaria).\nEstilo “C” (Contiguity): Se utiliza cuando los vecinos comparten una frontera común.\nEstilo “W” (Weights): Utiliza una matriz de pesos basada en distancias, donde los vecinos más cercanos tienen mayor peso\nEstilo “U”(Unweighted): En este estilo, los vecinos se definen de forma binaria (con un valor de 1 si hay vecindad y 0 si no la hay), pero a diferencia de otros estilos, no se toma en cuenta el tipo de vecindad exacta (como si comparten frontera o vértice).\n\n#---\n# MATRIZ DE VECINDADES (W)\n#---\n\n# Opcional: convierte la lista de vecinos en una matriz binaria de vecindades si se necesita\nDepartamentos &lt;- Insumo$Departamento\nn &lt;- length(Insumo.nb)\nMatW &lt;- matrix(0, n, n, dimnames = list(Departamentos, Departamentos))\n\nfor (i in 1:n) {\n  vecinos &lt;- Insumo.nb[[i]]\n  MatW[i, vecinos] &lt;- 1\n}\n\n# Alternativamente, usa diferentes estilos de ponderación\nInsumo.lw &lt;- nb2listw(Insumo.nb, zero.policy = TRUE )\nInsumo.lwb &lt;- nb2listw(Insumo.nb, style = \"B\",zero.policy = TRUE)\nInsumo.lwc &lt;- nb2listw(Insumo.nb, style = \"C\",zero.policy = TRUE)\nInsumo.lwu &lt;- nb2listw(Insumo.nb, style = \"U\",zero.policy = TRUE)\nInsumo.lww &lt;- nb2listw(Insumo.nb, style = \"W\",zero.policy = TRUE)",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Modelos de Regresión Espacial</span>",
      "<span style='color: #728387 !important;'>Aplicación de los Modelos </span>"
    ]
  },
  {
    "objectID": "4.html#pruebas-de-autocorrelación",
    "href": "4.html#pruebas-de-autocorrelación",
    "title": "Aplicación de los modelos",
    "section": "Pruebas de Autocorrelación",
    "text": "Pruebas de Autocorrelación\n\nÍndice de Moran\nEl índice de Moran es una medida global utilizada para cuantificar la autocorrelación espacial en un conjunto de datos geoespaciales. Este índice evalúa si los valores de una variable en una región tienden a estar agrupados en áreas vecinas o, por el contrario, dispersos. Se calcula comparando el valor de la variable en cada unidad espacial con los valores en sus vecinas, ponderados por la distancia o vecindad. El índice varía entre -1 y 1: un valor cercano a 1 indica que los valores de la variable están positivamente autocorrelacionados, es decir, las unidades cercanas tienen valores similares; un valor cercano a -1 sugiere autocorrelación negativa, donde las unidades cercanas tienen valores opuestos; y un valor cercano a 0 implica ausencia de autocorrelación espacial, lo que significa que los valores están distribuidos aleatoriamente.\n\nmoran.test(Insumo$CAP_BAC, Insumo.lw)\n\n\n    Moran I test under randomisation\n\ndata:  Insumo$CAP_BAC  \nweights: Insumo.lw  \nn reduced by no-neighbour observations  \n\nMoran I statistic standard deviate = 1.8248, p-value = 0.03401\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.140449554      -0.033333333       0.009069006 \n\n\nEl resultado del test de Moran que se presenta indica lo siguiente:\n\nMoran I statistic\n\n\nExpectation (Esperanza)\nLa esperanza teórica del índice de Moran bajo la hipótesis nula es -0.0333. Este valor refleja la media esperada del índice de Moran si no existiera autocorrelación espacial (es decir, si los valores de la variable se distribuyeran aleatoriamente).\n\n\nVariance (Varianza)\nLa varianza de la estadística de Moran es 0.0091. La varianza describe la dispersión de los valores observados del índice de Moran respecto a su valor esperado bajo la hipótesis nula.\n\n\nMoran I statistic standard deviate\nLa desviación estándar de la estadística de Moran es 1.8248. p-value: El valor p es 0.03401. Esto indica que la probabilidad de observar una estadística de Moran igual o más extrema que la observada bajo la hipótesis nula (sin autocorrelación espacial) es de aproximadamente 3.4%. Dado que este valor p es menor que el umbral común de 0.05, podemos rechazar la hipótesis nula de que no hay autocorrelación espacial significativa y concluir que hay evidencia estadística de autocorrelación espacial positiva en los datos de la variable CAP_BAC.\n\nmoran.plot(Insumo$CAP_BAC, \n           Insumo.lw, \n           labels=as.character(Insumo$Departamento), \n           xlab=\"Captaciones BAC\", \n           ylab=\"Captaciones BAC rezagado\", \n           las=1, \n           pch=16, \n           cex=0.5)\n\nlegend(\"bottomright\", \n       legend=c(\"I de Moran: 0.1530\", \"Valor P:      0.02262\"), \n       cex=1,\n       bg='lightgreen')\n\ntitle(\"Dispersograma de Moran para las captaciones del banco agrario en \nlos Departamentos de Colombia, cuarto trimestre 2020\", cex.main=1)\n\n\n\n\n\n\n\n\n\n\n\nLocal G\nEl Local G es un índice de autocorrelación espacial que complementa el índice de Moran al permitir la identificación de patrones locales de agrupamiento o dispersión en los datos. Mientras que el índice de Moran proporciona una medida global de la autocorrelación espacial, el Local G permite detectar si ciertas áreas específicas presentan una concentración significativa de valores similares (o diferentes). Este índice se calcula para cada unidad espacial, tomando en cuenta los valores en sus vecinas más cercanas. Los valores de Local G más altos indican áreas de alta concentración de valores similares, mientras que los valores negativos o bajos indican zonas de baja concentración o patrones de dispersión. Es útil para identificar clústeres locales de alta o baja intensidad, lo que permite un análisis más detallado de las estructuras espaciales en los datos.\n\nnearng = dnearneigh(st_coordinates(Insumo.utm)[, 1:2], 0, 550)\nInsumo.lw.g = nb2listw(nearng, style=\"B\", zero.policy = T)\n\n\ndnearneigh:Esta función calcula las vecindades entre los elementos espaciales según una distancia determinada. En este caso, se utiliza st_coordinates(Insumo.utm)[, 1:2] para obtener las coordenadas de los departamentos en el sistema de referencia espacial UTM, y se establecen dos parámetros: 0 (distancia mínima) y 550 (distancia máxima) para definir qué unidades espaciales están cerca entre sí.\nnb2listwConvierte la vecindad obtenida (nearng) en una lista de pesos espaciales, donde style=“B” indica que la matriz de vecindad será binaria (vecinos cercanos reciben un valor de 1, y los demás reciben 0). Además, zero.policy = T indica que se manejan correctamente los casos en los que algunas unidades no tienen vecinos (se asigna un valor de 0).\nlocalG:Esta función calcula el índice Local G para la variable CAP_BAC, utilizando la matriz de vecindad definida anteriormente. El resultado muestra el valor de Local G para cada unidad espacial (departamento), lo que permite identificar los clústeres locales de valores similares en CAP_BAC.\n\n# Local G\nlocalG = localG(Insumo$CAP_BAC, Insumo.lw); localG\n\n [1]  0.155681557 -0.712138366  1.156581529  0.223053281  1.225680585\n [6]  1.780856038 -0.731942275 -0.060298220 -0.295608194  0.657477592\n[11]  2.277561982  0.871102293  2.294286018 -0.656017332 -0.999281109\n[16]  1.681892858  0.023724727  1.074391458 -0.147838109  0.353880133\n[21]  1.377877204 -0.579569282  0.003748916 -0.484612682  0.115533100\n[26]  0.331016021 -0.382174908          NaN -0.691581293 -1.040470926\n[31] -1.026671692 -1.054907095\nattr(,\"internals\")\n               Gi      E(Gi)        V(Gi)        Z(Gi) Pr(z != E(Gi))\n [1,] 0.034341489 0.03225806 0.0001790941  0.155681557     0.87628404\n [2,] 0.013326210 0.03225806 0.0007067366 -0.712138366     0.47637910\n [3,] 0.051335768 0.03225806 0.0002720819  1.156581529     0.24744337\n [4,] 0.035157388 0.03225806 0.0001689570  0.223053281     0.82349404\n [5,] 0.047456292 0.03225806 0.0001537557  1.225680585     0.22031890\n [6,] 0.060877660 0.03225806 0.0002582673  1.780856038     0.07493597\n [7,] 0.021853899 0.03225806 0.0002020509 -0.731942275     0.46420380\n [8,] 0.031367743 0.03225806 0.0002180140 -0.060298220     0.95191812\n [9,] 0.027504594 0.03225806 0.0002585763 -0.295608194     0.76752932\n[10,] 0.046354798 0.03225806 0.0004597006  0.657477592     0.51087387\n[11,] 0.063046196 0.03225806 0.0001827369  2.277561982     0.02275269\n[12,] 0.050790538 0.03225806 0.0004526145  0.871102293     0.38369830\n[13,] 0.065765757 0.03225806 0.0002133015  2.294286018     0.02177408\n[14,] 0.014971771 0.03225806 0.0006943415 -0.656017332     0.51181297\n[15,] 0.014214548 0.03225806 0.0003260371 -0.999281109     0.31765853\n[16,] 0.052551797 0.03225806 0.0001455885  1.681892858     0.09258962\n[17,] 0.032909872 0.03225806 0.0007548078  0.023724727     0.98107218\n[18,] 0.055869899 0.03225806 0.0004829858  1.074391458     0.28264727\n[19,] 0.029120083 0.03225806 0.0004505345 -0.147838109     0.88247053\n[20,] 0.037283549 0.03225806 0.0002016710  0.353880133     0.72342872\n[21,] 0.055190592 0.03225806 0.0002770019  1.377877204     0.16824120\n[22,] 0.016800765 0.03225806 0.0007113061 -0.579569282     0.56220511\n[23,] 0.032308100 0.03225806 0.0001781310  0.003748916     0.99700880\n[24,] 0.024333024 0.03225806 0.0002674320 -0.484612682     0.62795112\n[25,] 0.034715170 0.03225806 0.0004523084  0.115533100     0.90802259\n[26,] 0.037589783 0.03225806 0.0002594396  0.331016021     0.74063238\n[27,] 0.025280301 0.03225806 0.0003333559 -0.382174908     0.70233163\n[28,] 0.000000000 0.00000000 0.0000000000          NaN            NaN\n[29,] 0.014222756 0.03225806 0.0006800810 -0.691581293     0.48920031\n[30,] 0.004592077 0.03225806 0.0007070212 -1.040470926     0.29812117\n[31,] 0.013839331 0.03225806 0.0003218521 -1.026671692     0.30457508\n[32,] 0.015701595 0.03225806 0.0002463242 -1.054907095     0.29146782\nattr(,\"cluster\")\n [1] High Low  High Low  High Low  Low  High Low  Low  High Low  High Low  Low \n[16] Low  High High Low  Low  High Low  High High Low  Low  Low  Low  Low  Low \n[31] Low  Low \nLevels: Low High\nattr(,\"gstari\")\n[1] FALSE\nattr(,\"call\")\nlocalG(x = Insumo$CAP_BAC, listw = Insumo.lw)\nattr(,\"class\")\n[1] \"localG\"\n\n\n\nSimulación Monte Carlo:\nPara evaluar la significancia de los resultados obtenidos con el índice Local G, se realizan 1000 simulaciones donde se barajan aleatoriamente los valores de CAP_BAC y se vuelve a calcular el índice Local G para cada permutación. Esto permite comparar los valores observados de Local G con una distribución aleatoria. sweep(sim.G, 2, localG, “&gt;=”): Compara los valores de localGobservados con los valores simulados. Elsweepcompara cada valor desim.Gcon el valor correspondiente delocalG` para cada unidad espacial. Si el valor simulado es mayor o igual que el valor observado, se cuenta como un 1, lo que indica que el valor simulado es al menos tan grande como el observado. colSums(…)+1: Suma cuántos de los valores simulados son mayores o iguales a los valores observados de Local G, añadiendo 1 para evitar valores p de 0. (nrow(sim.G)+1): Se normaliza por el número total de simulaciones (1000), de manera que se obtiene un valor p para cada unidad espacial, indicando la probabilidad de obtener un valor de Local G tan extremo como el observado bajo la distribución aleatoria.\n\n# Simulaci?n montecarlo\nsim.G = matrix(0,1000,32)\nfor(i in 1:1000) sim.G[i,] = localG(sample(Insumo$CAP_BAC),Insumo.lw)\nmc.pvalor.G = (colSums(sweep(sim.G,2,localG,\"&gt;=\"))+1)/(nrow(sim.G)+1)\nmc.pvalor.G\n\n [1] 0.36863137 0.77122877 0.10689311 0.34165834 0.15584416 0.06893107\n [7] 0.74725275 0.43756244 0.54645355 0.17482517 0.01698302 0.17382617\n[13] 0.02197802 0.71028971 0.88211788 0.06493506 0.33666334 0.11888112\n[19] 0.44955045 0.31268731 0.12687313 0.64335664 0.42957043 0.61438561\n[25] 0.32867133 0.29570430 0.55444555         NA 0.75024975 0.99200799\n[31] 0.90309690 0.90209790\n\n\nLos valores p calculados (mc.pvalor.G) indican la significancia estadística de los patrones espaciales observados. Un valor p bajo (generalmente menor que 0.05) sugiere que la autocorrelación espacial observada en un departamento es significativamente diferente de la aleatoriedad, lo que indica un clúster local de alta o baja concentración de valores. Los departamentos con valores p bajos pueden considerarse como áreas con patrones espaciales significativos, lo cual es útil para identificar zonas con características especiales en la variable de interés.\n\nMapas\n\nlibrary(ggplot2)\nlocalG= as.numeric(localG)\n# Mapa de G\nggplot(Insumo.utm) + \n  geom_sf(aes(fill = localG)) +\n  scale_fill_viridis_c() +\n  ggtitle(\"G Getis Ord Local para las captaciones del banco agrario en Colombia, cuarto trimestre 2020\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n# Mapa de p-valor\nggplot(Insumo.utm) + \n  geom_sf(aes(fill = mc.pvalor.G)) +\n  scale_fill_viridis_c() +\n  ggtitle(\"P-Valor de G Getis Ord Local para las captaciones del banco agrario en Colombia, cuarto trimestre 2020\") +\n  theme_minimal()",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Modelos de Regresión Espacial</span>",
      "<span style='color: #728387 !important;'>Aplicación de los Modelos </span>"
    ]
  },
  {
    "objectID": "4.html#regresión-espacial",
    "href": "4.html#regresión-espacial",
    "title": "Aplicación de los modelos",
    "section": "Regresión Espacial",
    "text": "Regresión Espacial\nLos modelos de regresión espacial son fundamentales para capturar la dependencia espacial entre observaciones, un fenómeno común en datos geoespaciales. \n\nOLS\n\\[\ny = \\mathbf{X}\\beta + \\epsilon\n\\]\nEl modelo OLS es la regresión lineal clásica, donde \\(y\\) es la variable dependiente, \\(\\mathbf{X}\\) es la matriz de covariables, \\(\\beta\\) son los coeficientes a estimar y \\(\\varepsilon\\) es el término del error. Este modelo no captura ninguna dependencia espacial de los errores, lo que puede ser una limitación cuando hay correlación espacial entre las observaciones.\n\nreg.eq1=CAP_BAC ~ PIB + NBI + CAP_BOG+CAP_BC + CAP_OCC + CAP_CS+ Población\nreg1=lm(reg.eq1,data=Insumo)                                     #OLS            y=XB+e,    \nsummary(reg1)\n\n\nCall:\nlm(formula = reg.eq1, data = Insumo)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-285.63  -79.51  -10.25   45.42  402.00 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)  1.313e+02  7.573e+01   1.734   0.0958 .\nPIB          3.930e-03  3.321e-03   1.183   0.2482  \nNBI         -1.278e+00  1.878e+00  -0.680   0.5028  \nCAP_BOG     -6.148e-02  5.542e-02  -1.109   0.2783  \nCAP_BC       2.751e-03  5.994e-03   0.459   0.6504  \nCAP_OCC     -4.705e-02  2.152e-02  -2.186   0.0388 *\nCAP_CS       4.444e-01  3.203e-01   1.388   0.1780  \nPoblación    1.521e-05  6.709e-05   0.227   0.8226  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 142.7 on 24 degrees of freedom\nMultiple R-squared:  0.8798,    Adjusted R-squared:  0.8447 \nF-statistic: 25.09 on 7 and 24 DF,  p-value: 1.43e-09\n\n\n\n\nSLX (Spatial Lag of X)\nEl modelo SLX (Spatial Lag of X) extiende el OLS al incluir el “lag” espacial de las variables explicativas (\\(\\mathbf{WX\\theta}\\)), donde \\(\\mathbf{W}\\) es la matriz de vecindad y \\(\\theta\\) es el vector de coeficientes correspondientes a las variables explicativas laggeadas. Este modelo captura la influencia de los valores de las covariables de los vecinos en la variable dependiente.\n\nreg2=lmSLX(reg.eq1,data=Insumo, Insumo.lw,, zero.policy = TRUE)                       #SLX            y=XB+WxT+e\nsummary(reg2)\n\n\nCall:\nlm(formula = formula(paste(\"y ~ \", paste(colnames(x)[-1], collapse = \"+\"))), \n    data = as.data.frame(x), weights = weights)\n\nCoefficients:\n               Estimate    Std. Error  t value     Pr(&gt;|t|)  \n(Intercept)     1.057e+02   1.456e+02   7.260e-01   4.777e-01\nPIB             3.620e-03   4.007e-03   9.033e-01   3.790e-01\nNBI            -9.757e-02   2.781e+00  -3.508e-02   9.724e-01\nCAP_BOG        -8.925e-03   7.998e-02  -1.116e-01   9.125e-01\nCAP_BC         -4.774e-03   9.727e-03  -4.908e-01   6.298e-01\nCAP_OCC        -6.427e-02   3.416e-02  -1.882e+00   7.711e-02\nCAP_CS          1.336e-01   4.529e-01   2.950e-01   7.716e-01\nPoblación       1.052e-04   1.162e-04   9.057e-01   3.777e-01\nlag.PIB         3.786e-03   9.844e-03   3.847e-01   7.053e-01\nlag.NBI        -1.050e+00   4.323e+00  -2.429e-01   8.110e-01\nlag.CAP_BOG    -1.822e-01   1.654e-01  -1.101e+00   2.861e-01\nlag.CAP_BC      2.917e-03   1.550e-02   1.882e-01   8.529e-01\nlag.CAP_OCC    -1.146e-02   5.798e-02  -1.976e-01   8.457e-01\nlag.CAP_CS      9.438e-01   9.882e-01   9.552e-01   3.529e-01\nlag.Población  -1.448e-04   1.795e-04  -8.065e-01   4.311e-01\n\n\n\n\nModelo Lag (SAR - Spatial Autoregressive)\n\\(y = \\mathbf{X}\\beta + \\rho\\mathbf{Wy} + u\\) y \\(u=\\lambda W u + \\varepsilon\\)\nEl modelo SAR (Spatial Autoregressive) inlcluye un término de “lag” en la variable dependiente (\\(\\mathbf{W}y\\)), donde (\\(\\mathbf{rho}\\)) es el coeficiente asociado al lag espacial. Este modelo captura la dependencia espacial en los valores de la variable dependiente entre vecinos.\nEl término del error (\\(u\\)) también esta modelado como un proceso autoregresivo espacial ,es decir, \\(u = \\lambda W u + \\varepsilon\\) lo que significa que el error de una observación también depende de los errores de sus vecinos.\n\nreg3 = lagsarlm(reg.eq1, data = Insumo, Insumo.lw, zero.policy = TRUE)\n\nWarning in lagsarlm(reg.eq1, data = Insumo, Insumo.lw, zero.policy = TRUE): inversion of asymptotic covariance matrix failed for tol.solve = 2.22044604925031e-16 \n  número de condición recíproco = 5.86692e-18 - using numerical Hessian.\n\n\n\nsummary(reg3)\n\n\nCall:lagsarlm(formula = reg.eq1, data = Insumo, listw = Insumo.lw, \n    zero.policy = TRUE)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-214.497  -61.665  -15.071   34.870  395.222 \n\nType: lag \nRegions with no neighbours included:\n 28 \nCoefficients: (numerical Hessian approximate standard errors) \n               Estimate  Std. Error z value Pr(&gt;|z|)\n(Intercept)  6.8199e+01  7.2159e+01  0.9451  0.34459\nPIB          3.1708e-03  2.7729e-03  1.1435  0.25283\nNBI         -1.0169e+00  1.5539e+00 -0.6544  0.51284\nCAP_BOG     -4.7766e-02  4.6328e-02 -1.0310  0.30253\nCAP_BC       4.7788e-03  5.0817e-03  0.9404  0.34702\nCAP_OCC     -3.5245e-02  1.8997e-02 -1.8553  0.06355\nCAP_CS       3.6931e-01  2.6724e-01  1.3820  0.16699\nPoblación    1.0303e-05  5.5724e-05  0.1849  0.85331\n\nRho: 0.2533, LR test value: 2.8104, p-value: 0.093656\nApproximate (numerical Hessian) standard error: 0.14574\n    z-value: 1.738, p-value: 0.082208\nWald statistic: 3.0207, p-value: 0.082208\n\nLog likelihood: -198.1508 for lag model\nML residual variance (sigma squared): 13793, (sigma: 117.44)\nNumber of observations: 32 \nNumber of parameters estimated: 10 \nAIC: 416.3, (AIC for lm: 417.11)\n\n\n\n\n\n\n\nModelo de Error Espacial (SEM - Spatial Error Model)\n\\(y = X\\beta + \\varepsilon\\) y \\(\\varepsilon = \\lambda \\varepsilon + u\\)\nEl Modelo de Error Espacial (SEM) incluye una corrección para la dependencia espacial en los errores \\((\\varepsilon)\\), donde \\(\\lambda\\) es el coeficiente que mide la fuerza de la correlación espacial en el término de error. El modelo SEM no incorpora un “lag” espacial en la variable dependiente, sino que captura la dependencia espacial únicamente a través del componente del error.\n\nreg4 = errorsarlm(reg.eq1, data = Insumo, Insumo.lw, zero.policy = TRUE)\n\nWarning in errorsarlm(reg.eq1, data = Insumo, Insumo.lw, zero.policy = TRUE): inversion of asymptotic covariance matrix failed for tol.solve = 2.22044604925031e-16 \n  número de condición recíproco = 9.31736e-18 - using numerical Hessian.\n\n\n\nsummary(reg4)\n\n\nCall:errorsarlm(formula = reg.eq1, data = Insumo, listw = Insumo.lw, \n    zero.policy = TRUE)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-218.740  -53.251  -12.473   40.884  430.689 \n\nType: error \nRegions with no neighbours included:\n 28 \nCoefficients: (asymptotic standard errors) \n               Estimate  Std. Error z value Pr(&gt;|z|)\n(Intercept)  8.1541e+01  6.6482e+01  1.2265 0.220010\nPIB          3.4910e-03  2.6338e-03  1.3254 0.185024\nNBI         -5.7398e-01  1.5259e+00 -0.3762 0.706802\nCAP_BOG     -2.2704e-02  4.9984e-02 -0.4542 0.649667\nCAP_BC       1.5961e-05  5.3543e-03  0.0030 0.997622\nCAP_OCC     -5.2267e-02  1.9001e-02 -2.7508 0.005945\nCAP_CS       2.3351e-01  2.8637e-01  0.8154 0.414840\nPoblación    5.7012e-05  6.5438e-05  0.8712 0.383627\n\nLambda: 0.52347, LR test value: 4.2435, p-value: 0.0394\nApproximate (numerical Hessian) standard error: 0.20488\n    z-value: 2.5551, p-value: 0.010617\nWald statistic: 6.5283, p-value: 0.010617\n\nLog likelihood: -197.4342 for error model\nML residual variance (sigma squared): 12472, (sigma: 111.68)\nNumber of observations: 32 \nNumber of parameters estimated: 10 \nAIC: 414.87, (AIC for lm: 417.11)\n\n\n\n\nModelo de Durbin Espacial con Error (SDEM - Spatial Durbin Error Model)\n\\(y = X \\beta + WX \\theta + u\\) y \\(u = \\lambda W u + \\varepsilon\\)\nEl Modelo de Durbin Espacial con Error (SDEM) es una combinación del modelo de error espacial y el modelo de regresión espacial Durbin. En este modelo, no solo se incluye un término de “lag” espacial para la variable dependiente, sino también para las variables explicativas. El término de error (\\(u\\) ) sigue un proceso autoregresivo espacial. Este modelo captura tanto la dependencia espacial en las variables dependientes como en las explicativas.\n\nreg5 = errorsarlm(reg.eq1, data = Insumo, Insumo.lw, etype = \"emixed\", zero.policy = TRUE)\n\nWarning in errorsarlm(reg.eq1, data = Insumo, Insumo.lw, etype = \"emixed\", : inversion of asymptotic covariance matrix failed for tol.solve = 2.22044604925031e-16 \n  número de condición recíproco = 9.13061e-18 - using numerical Hessian.\n\n\n\nsummary(reg5)\n\n\nCall:errorsarlm(formula = reg.eq1, data = Insumo, listw = Insumo.lw, \n    etype = \"emixed\", zero.policy = TRUE)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-211.810  -47.834  -11.501   56.293  377.775 \n\nType: error \nRegions with no neighbours included:\n 28 \nCoefficients: (asymptotic standard errors) \n                 Estimate  Std. Error z value Pr(&gt;|z|)\n(Intercept)    2.8964e+01  1.0590e+02  0.2735   0.7845\nPIB            4.4110e-03  2.8308e-03  1.5582   0.1192\nNBI            3.5633e-01  1.8031e+00  0.1976   0.8433\nCAP_BOG       -3.8107e-02  5.4243e-02 -0.7025   0.4824\nCAP_BC        -1.6123e-03  6.6418e-03 -0.2427   0.8082\nCAP_OCC       -5.3413e-02  2.3321e-02 -2.2903   0.0220\nCAP_CS         2.8575e-01  3.0596e-01  0.9339   0.3503\nPoblación      5.3045e-05  7.7522e-05  0.6843   0.4938\nlag.PIB        4.1782e-03  7.6459e-03  0.5465   0.5847\nlag.NBI       -5.8691e-01  3.1145e+00 -0.1884   0.8505\nlag.CAP_BOG   -1.0933e-01  1.1822e-01 -0.9248   0.3551\nlag.CAP_BC    -5.3450e-03  1.0944e-02 -0.4884   0.6253\nlag.CAP_OCC   -1.7609e-02  4.3079e-02 -0.4088   0.6827\nlag.CAP_CS     5.0040e-01  7.0948e-01  0.7053   0.4806\nlag.Población -5.1562e-05  1.2903e-04 -0.3996   0.6894\n\nLambda: 0.46671, LR test value: 2.1801, p-value: 0.13981\nApproximate (numerical Hessian) standard error: 0.27542\n    z-value: 1.6945, p-value: 0.090164\nWald statistic: 2.8714, p-value: 0.090164\n\nLog likelihood: -196.0596 for error model\nML residual variance (sigma squared): 11631, (sigma: 107.85)\nNumber of observations: 32 \nNumber of parameters estimated: 17 \nAIC: 426.12, (AIC for lm: 426.3)\n\n\n\n\nModelo Durbin Espacial (SDM - Spatial Durbin Model)\n\\[\ny = X \\beta + Wy\\rho + WX\\theta + \\varepsilon\n\\]\nEl Modelo Durbin Espacial (SDM) es una extensión del modelo SAR que incluye tanto un “lag” espacial de la variable dependiente como un “lag” espacial de las variables explicativas. Este modelo permite que las variables explicativas influyan tanto directamente como a través de sus efectos espaciales en la variable dependiente.\n\nreg6 = lagsarlm(reg.eq1, data = Insumo, Insumo.lw, type = \"mixed\", zero.policy = TRUE)\n\nWarning in lagsarlm(reg.eq1, data = Insumo, Insumo.lw, type = \"mixed\", zero.policy = TRUE): inversion of asymptotic covariance matrix failed for tol.solve = 2.22044604925031e-16 \n  número de condición recíproco = 4.58189e-18 - using numerical Hessian.\n\n\n\nsummary(reg6)\n\n\nCall:lagsarlm(formula = reg.eq1, data = Insumo, listw = Insumo.lw, \n    type = \"mixed\", zero.policy = TRUE)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-203.5501  -57.4964   -9.1121   49.0668  377.8941 \n\nType: mixed \nRegions with no neighbours included:\n 28 \nCoefficients: (numerical Hessian approximate standard errors) \n                 Estimate  Std. Error z value Pr(&gt;|z|)\n(Intercept)    5.6710e+01  1.0611e+02  0.5344  0.59304\nPIB            3.8566e-03  2.7986e-03  1.3781  0.16819\nNBI            1.4678e-01  2.1429e+00  0.0685  0.94539\nCAP_BOG       -1.4527e-02  5.7942e-02 -0.2507  0.80203\nCAP_BC        -2.9294e-03  6.8930e-03 -0.4250  0.67085\nCAP_OCC       -5.8433e-02  2.3689e-02 -2.4666  0.01364\nCAP_CS         1.6655e-01  3.2580e-01  0.5112  0.60922\nPoblación      7.9995e-05  8.3984e-05  0.9525  0.34084\nlag.PIB        1.1073e-03  6.6845e-03  0.1657  0.86843\nlag.NBI       -1.1460e+00  3.1540e+00 -0.3634  0.71633\nlag.CAP_BOG   -1.1343e-01  1.1758e-01 -0.9647  0.33469\nlag.CAP_BC    -1.2808e-04  1.0278e-02 -0.0125  0.99006\nlag.CAP_OCC    7.3867e-03  4.4739e-02  0.1651  0.86886\nlag.CAP_CS     5.3185e-01  6.9614e-01  0.7640  0.44487\nlag.Población -9.8368e-05  1.3609e-04 -0.7228  0.46979\n\nRho: 0.38762, LR test value: 2.4703, p-value: 0.11602\nApproximate (numerical Hessian) standard error: 0.22804\n    z-value: 1.6998, p-value: 0.089166\nWald statistic: 2.8894, p-value: 0.089166\n\nLog likelihood: -195.9145 for mixed model\nML residual variance (sigma squared): 11739, (sigma: 108.34)\nNumber of observations: 32 \nNumber of parameters estimated: 17 \nAIC: 425.83, (AIC for lm: 426.3)\n\n\n\n\nModelo Manski (Manski Model)\nEl Modelo Manski es similar al modelo SDM, pero tiene una estructura más compleja en cuanto a la autocorrelación espacial de los errores. Este modelo incluye tanto el “lag” espacial de la variable dependiente, como los “lags” espaciales de las variables explicativas. La diferencia principal con el modelo SDM es el tratamiento más complejo de los términos de error.\n\nreg7 = sacsarlm(reg.eq1, data = Insumo, Insumo.lw, type = \"sacmixed\", zero.policy = TRUE)\n\nWarning in sacsarlm(reg.eq1, data = Insumo, Insumo.lw, type = \"sacmixed\", : inversion of asymptotic covariance matrix failed for tol.solve = 2.22044604925031e-16 \n  número de condición recíproco = 4.61347e-18 - using numerical Hessian.\n\n\n\nsummary(reg7)\n\n\nCall:sacsarlm(formula = reg.eq1, data = Insumo, listw = Insumo.lw, \n    type = \"sacmixed\", zero.policy = TRUE)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-204.541  -53.811  -12.538   51.980  382.238 \n\nType: sacmixed \nCoefficients: (numerical Hessian approximate standard errors) \n                 Estimate  Std. Error z value Pr(&gt;|z|)\n(Intercept)    4.8808e+01  1.1502e+02  0.4243  0.67131\nPIB            4.0090e-03  2.8803e-03  1.3919  0.16396\nNBI            2.1612e-01  1.9200e+00  0.1126  0.91038\nCAP_BOG       -2.2486e-02  6.9157e-02 -0.3251  0.74507\nCAP_BC        -2.3158e-03  7.5058e-03 -0.3085  0.75768\nCAP_OCC       -5.6496e-02  2.5908e-02 -2.1806  0.02921\nCAP_CS         2.0887e-01  3.8203e-01  0.5467  0.58456\nPoblación      6.9346e-05  9.6780e-05  0.7165  0.47366\nlag.PIB        1.5704e-03  7.9396e-03  0.1978  0.84321\nlag.NBI       -9.9232e-01  3.1209e+00 -0.3180  0.75051\nlag.CAP_BOG   -1.1048e-01  1.2387e-01 -0.8919  0.37243\nlag.CAP_BC    -1.5701e-03  1.3233e-02 -0.1187  0.90555\nlag.CAP_OCC    2.5166e-03  5.0022e-02  0.0503  0.95988\nlag.CAP_CS     5.1478e-01  7.4300e-01  0.6928  0.48841\nlag.Población -8.2594e-05  1.4845e-04 -0.5564  0.57796\n\nRho: 0.31266\nApproximate (numerical Hessian) standard error: 0.50048\n    z-value: 0.62472, p-value: 0.53215\nLambda: 0.13054\nApproximate (numerical Hessian) standard error: 0.71242\n    z-value: 0.18324, p-value: 0.85461\n\nLR test value: 7.3157, p-value: 0.60429\n\nLog likelihood: -195.8981 for sacmixed model\nML residual variance (sigma squared): 11840, (sigma: 108.81)\nNumber of observations: 32 \nNumber of parameters estimated: 18 \nAIC: 427.8, (AIC for lm: 417.11)\n\n\n\n\nModelo SARAR (Kelejian-Prucha, Cliff-Ord, SAC)\n\\[\ny = X\\beta + \\rho W y + u\n\\]\ny\n\\[\nu = \\lambda W u + \\varepsilon\n\\]\nEl Modelo SARAR (también conocido como modelo Kelejian-Prucha o Cliff-Ord) es un modelo que combina características del modelo SAR y SEM. Este modelo tiene un término de “lag” espacial en la variable dependiente y un término de error espacial autoregresivo, lo que permite capturar tanto la dependencia espacial en la variable dependiente como en el error.\n\nreg8 = sacsarlm(reg.eq1, data = Insumo, Insumo.lw, type = \"sac\", zero.policy = TRUE)\n\nWarning in sacsarlm(reg.eq1, data = Insumo, Insumo.lw, type = \"sac\", zero.policy = TRUE): inversion of asymptotic covariance matrix failed for tol.solve = 2.22044604925031e-16 \n  número de condición recíproco = 8.70662e-18 - using numerical Hessian.\n\n\n\nsummary(reg8)\n\n\nCall:sacsarlm(formula = reg.eq1, data = Insumo, listw = Insumo.lw, \n    type = \"sac\", zero.policy = TRUE)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-205.1587  -56.7315   -9.4429   31.9574  422.6304 \n\nType: sac \nCoefficients: (numerical Hessian approximate standard errors) \n               Estimate  Std. Error z value Pr(&gt;|z|)\n(Intercept)  6.4572e+01  7.2349e+01  0.8925  0.37212\nPIB          3.2940e-03  2.6769e-03  1.2305  0.21850\nNBI         -6.2802e-01  1.5495e+00 -0.4053  0.68526\nCAP_BOG     -3.2650e-02  5.1324e-02 -0.6361  0.52468\nCAP_BC       2.2998e-03  6.0593e-03  0.3795  0.70428\nCAP_OCC     -4.4343e-02  2.1685e-02 -2.0449  0.04086\nCAP_CS       2.8775e-01  2.9320e-01  0.9814  0.32638\nPoblación    3.8417e-05  6.7901e-05  0.5658  0.57155\n\nRho: 0.13272\nApproximate (numerical Hessian) standard error: 0.18411\n    z-value: 0.72086, p-value: 0.471\nLambda: 0.40988\nApproximate (numerical Hessian) standard error: 0.27523\n    z-value: 1.4892, p-value: 0.13643\n\nLR test value: 4.7255, p-value: 0.094163\n\nLog likelihood: -197.1932 for sac model\nML residual variance (sigma squared): 12607, (sigma: 112.28)\nNumber of observations: 32 \nNumber of parameters estimated: 11 \nAIC: 416.39, (AIC for lm: 417.11)\n\n\n\n\nCálculo de variables significativas\nPueden calcularse las variables significativas de cada modelo de regresión, proporcionando los coeficientes estimados y los valores p asociados.\n\n#Calculo de variables significativas\nreg.eq2=CAP_BAC ~ PIB + CAP_BOG+CAP_BC + CAP_OCC + CAP_CS+ Población\nreg4=errorsarlm(reg.eq2,data=Insumo, Insumo.lw, zero.policy = TRUE)\n\nWarning in errorsarlm(reg.eq2, data = Insumo, Insumo.lw, zero.policy = TRUE): inversion of asymptotic covariance matrix failed for tol.solve = 2.22044604925031e-16 \n  número de condición recíproco = 9.34261e-18 - using numerical Hessian.\n\n\n\ns = summary\ns(reg4)#Lag Error (SEM)\n\n\nCall:errorsarlm(formula = reg.eq2, data = Insumo, listw = Insumo.lw, \n    zero.policy = TRUE)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-211.532  -51.640  -10.342   43.439  434.624 \n\nType: error \nRegions with no neighbours included:\n 28 \nCoefficients: (asymptotic standard errors) \n               Estimate  Std. Error z value Pr(&gt;|z|)\n(Intercept)  6.5053e+01  5.2382e+01  1.2419 0.214276\nPIB          3.7321e-03  2.5473e-03  1.4651 0.142880\nCAP_BOG     -2.6478e-02  4.8603e-02 -0.5448 0.585908\nCAP_BC       2.1298e-05  5.3721e-03  0.0040 0.996837\nCAP_OCC     -5.2253e-02  1.9059e-02 -2.7417 0.006113\nCAP_CS       2.5082e-01  2.8122e-01  0.8919 0.372449\nPoblación    5.3526e-05  6.4802e-05  0.8260 0.408807\n\nLambda: 0.53453, LR test value: 4.7167, p-value: 0.029871\nApproximate (numerical Hessian) standard error: 0.19933\n    z-value: 2.6816, p-value: 0.007327\nWald statistic: 7.191, p-value: 0.007327\n\nLog likelihood: -197.5033 for error model\nML residual variance (sigma squared): 12482, (sigma: 111.72)\nNumber of observations: 32 \nNumber of parameters estimated: 9 \nAIC: 413.01, (AIC for lm: 415.72)\n\n\n\nreg.eq3=CAP_BAC ~ PIB + CAP_BOG + CAP_OCC + CAP_CS+ Población\nreg4=errorsarlm(reg.eq3,data=Insumo, Insumo.lw, zero.policy = TRUE)\n\nWarning in errorsarlm(reg.eq3, data = Insumo, Insumo.lw, zero.policy = TRUE): inversion of asymptotic covariance matrix failed for tol.solve = 2.22044604925031e-16 \n  número de condición recíproco = 9.39308e-18 - using numerical Hessian.\n\n\n\ns(reg4)#Lag Error (SEM)\n\n\nCall:errorsarlm(formula = reg.eq3, data = Insumo, listw = Insumo.lw, \n    zero.policy = TRUE)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-211.604  -51.658  -10.314   43.452  434.644 \n\nType: error \nRegions with no neighbours included:\n 28 \nCoefficients: (asymptotic standard errors) \n               Estimate  Std. Error z value  Pr(&gt;|z|)\n(Intercept)  6.4949e+01  4.6184e+01  1.4063 0.1596331\nPIB          3.7353e-03  2.4024e-03  1.5548 0.1199876\nCAP_BOG     -2.6340e-02  3.5604e-02 -0.7398 0.4594136\nCAP_OCC     -5.2300e-02  1.4786e-02 -3.5372 0.0004044\nCAP_CS       2.5002e-01  2.0469e-01  1.2215 0.2219007\nPoblación    5.3668e-05  5.4615e-05  0.9827 0.3257723\n\nLambda: 0.53464, LR test value: 4.9211, p-value: 0.02653\nApproximate (numerical Hessian) standard error: 0.19966\n    z-value: 2.6777, p-value: 0.0074134\nWald statistic: 7.17, p-value: 0.0074134\n\nLog likelihood: -197.5033 for error model\nML residual variance (sigma squared): 12482, (sigma: 111.72)\nNumber of observations: 32 \nNumber of parameters estimated: 8 \nAIC: 411.01, (AIC for lm: 413.93)\n\n\n\nreg.eq4=CAP_BAC ~ PIB + CAP_OCC + CAP_CS+ Población\nreg4=errorsarlm(reg.eq4,data=Insumo, Insumo.lw, zero.policy = TRUE)\n\nWarning in errorsarlm(reg.eq4, data = Insumo, Insumo.lw, zero.policy = TRUE): inversion of asymptotic covariance matrix failed for tol.solve = 2.22044604925031e-16 \n  número de condición recíproco = 9.49253e-18 - using numerical Hessian.\n\n\n\ns(reg4)#Lag Error (SEM)\n\n\nCall:errorsarlm(formula = reg.eq4, data = Insumo, listw = Insumo.lw, \n    zero.policy = TRUE)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-197.278  -57.885  -10.374   35.522  448.779 \n\nType: error \nRegions with no neighbours included:\n 28 \nCoefficients: (asymptotic standard errors) \n               Estimate  Std. Error z value  Pr(&gt;|z|)\n(Intercept)  6.5631e+01  4.8473e+01  1.3540 0.1757428\nPIB          3.5303e-03  2.3971e-03  1.4727 0.1408221\nCAP_OCC     -5.0850e-02  1.4681e-02 -3.4638 0.0005327\nCAP_CS       1.0179e-01  3.7538e-02  2.7115 0.0066982\nPoblación    6.3364e-05  5.3434e-05  1.1858 0.2356933\n\nLambda: 0.57217, LR test value: 7.0658, p-value: 0.0078569\nApproximate (numerical Hessian) standard error: 0.17965\n    z-value: 3.185, p-value: 0.0014477\nWald statistic: 10.144, p-value: 0.0014477\n\nLog likelihood: -197.7534 for error model\nML residual variance (sigma squared): 12518, (sigma: 111.88)\nNumber of observations: 32 \nNumber of parameters estimated: 7 \nAIC: 409.51, (AIC for lm: 414.57)\n\n\n\nreg.eq5=CAP_BAC ~ PIB + CAP_OCC + CAP_CS\nreg4=errorsarlm(reg.eq5,data=Insumo, Insumo.lw, zero.policy = TRUE)\ns(reg4)#Lag Error (SEM)\n\n\nCall:errorsarlm(formula = reg.eq5, data = Insumo, listw = Insumo.lw, \n    zero.policy = TRUE)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-184.748  -63.304  -12.444   40.679  448.841 \n\nType: error \nRegions with no neighbours included:\n 28 \nCoefficients: (asymptotic standard errors) \n               Estimate  Std. Error z value  Pr(&gt;|z|)\n(Intercept) 88.65061930 44.45631621  1.9941  0.046140\nPIB          0.00617514  0.00092824  6.6525 2.881e-11\nCAP_OCC     -0.04719334  0.01471065 -3.2081  0.001336\nCAP_CS       0.07187945  0.02876778  2.4986  0.012468\n\nLambda: 0.55051, LR test value: 6.002, p-value: 0.014289\nAsymptotic standard error: 0.17223\n    z-value: 3.1964, p-value: 0.0013917\nWald statistic: 10.217, p-value: 0.0013917\n\nLog likelihood: -198.4352 for error model\nML residual variance (sigma squared): 13162, (sigma: 114.72)\nNumber of observations: 32 \nNumber of parameters estimated: 6 \nAIC: 408.87, (AIC for lm: 412.87)\n\n\n\n\nMapa estimado\n\nfit &lt;- reg2$fitted.values\nggplot(Insumo.utm) +\n  geom_sf(aes(fill = fit)) +\n  scale_fill_viridis_c() +\n  ggtitle(\"Valores ajustados mediante el modelo SEM para las captaciones del banco agrario en Colombia, cuarto trimestre 2020\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n###Test de moran residuales modelo SEM\nmoran.test(reg4$residuals, Insumo.lw)\n\n\n    Moran I test under randomisation\n\ndata:  reg4$residuals  \nweights: Insumo.lw  \nn reduced by no-neighbour observations  \n\nMoran I statistic standard deviate = 0.81038, p-value = 0.2089\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n       0.05128789       -0.03333333        0.01090389",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Modelos de Regresión Espacial</span>",
      "<span style='color: #728387 !important;'>Aplicación de los Modelos </span>"
    ]
  },
  {
    "objectID": "3-redes.html",
    "href": "3-redes.html",
    "title": "4  Pruebas de bondad de ajuste",
    "section": "",
    "text": "Palmira",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Modelos de Regresión Espacial</span>",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'><span style='color: #728387 !important;'>Redes </span></span>"
    ]
  },
  {
    "objectID": "3-redes.html#descriptivo-palmira",
    "href": "3-redes.html#descriptivo-palmira",
    "title": "4  Pruebas de bondad de ajuste",
    "section": "5.1 Descriptivo Palmira",
    "text": "5.1 Descriptivo Palmira\n\nPalmira=read.table(\"Palmira_Urbano_planas.txt\",head=T,sep = \",\")\nPalmira$INTERVALOS_HORA_t=as.POSIXct(as.character(Palmira$INTERVALOS_HORA), format=\"%R\")\n\n\n5.1.0.1 Mapas por uso de suelo, recortado dejando solo la zona urbana, con todos los puntos de los robos\n\nPalmira1_covar=filter(Palmira,GENERO %in% c(\"FEMENINO\",\"MASCULINO\"))\nPalmira1_covar$EDAD_Cat=cut(Palmira1_covar$EDAD, breaks=c(0,18,45,65,100), labels = c(\"Menor de 18\",\"18-45\",\"45-65\",\"Mayor de 65\"))\nPalmira1_covar$Armas_indicator=ifelse(Palmira1_covar$ARMAS==\"SINEMPLEODEARMAS\",\"Sin\",\"Con\")\nPalmira1_covar$SEMESTRE=dplyr::recode(Palmira1_covar$MES, \"ene\"=\"SEM_1\", \"feb\"=\"SEM_1\", \"mar\"=\"SEM_1\", \"abr\"=\"SEM_1\", \"may\"=\"SEM_1\",\"jun\"=\"SEM_1\",\"jul\"=\"SEM_2\",\"ago\"=\"SEM_2\",\"sep\"=\"SEM_2\",\"oct\"=\"SEM_2\",\"nov\"=\"SEM_2\",\"dic\"=\"SEM_2\")\nPalmira1_covar &lt;- subset(Palmira1_covar, select = c(\"X_plain\",\"Y_plain\",\"YEAR\",\"BARRIOS\",\"GENERO\",\"DIA_SEMANA\",\"INTERVALOS_HORA\",\"MODALIDAD\",\"EDAD_Cat\",\n\"Armas_indicator\",\"MES\",\"SEMESTRE\",\"LONGITUD\",\"LATITUD\"))\ntable(Palmira1_covar$YEAR,Palmira1_covar$SEMESTRE,Palmira1_covar$INTERVALOS_HORA,Palmira1_covar$GENERO)\n\n\ntable(Palmira1_covar$YEAR,Palmira1_covar$SEMESTRE,Palmira1_covar$INTERVALOS_HORA,Palmira1_covar$EDAD_Cat)\n\n\ntable(Palmira1_covar$YEAR,Palmira1_covar$SEMESTRE,Palmira1_covar$INTERVALOS_HORA,Palmira1_covar$Armas_indicator)\n\n\nPalmira1_covar$TRIMESTRE=dplyr::recode(Palmira1_covar$MES, \"ene\"=\"Trim_1\", \"feb\"=\"Trim_1\", \"mar\"=\"Trim_1\", \"abr\"=\"Trim_2\", \"may\"=\"Trim_2\",\"jun\"=\"Trim_2\",\"jul\"=\"Trim_3\",\"ago\"=\"Trim_3\",\"sep\"=\"Trim_3\",\"oct\"=\"Trim_4\",\"nov\"=\"Trim_4\",\"dic\"=\"Trim_4\")\nPalmira1_covar &lt;- subset(Palmira1_covar, select = c(\"X_plain\",\"Y_plain\",\"YEAR\",\"BARRIOS\",\"GENERO\",\"DIA_SEMANA\",\"INTERVALOS_HORA\",\"MODALIDAD\",\"EDAD_Cat\",\n\"Armas_indicator\",\"MES\",\"TRIMESTRE\",\"LONGITUD\",\"LATITUD\"))\ntable(Palmira1_covar$YEAR,Palmira1_covar$TRIMESTRE,Palmira1_covar$INTERVALOS_HORA,Palmira1_covar$GENERO)\n\n\ntable(Palmira1_covar$YEAR,Palmira1_covar$TRIMESTRE,Palmira1_covar$INTERVALOS_HORA,Palmira1_covar$EDAD_Cat)\n\n\ntable(Palmira1_covar$YEAR,Palmira1_covar$TRIMESTRE,Palmira1_covar$INTERVALOS_HORA,Palmira1_covar$Armas_indicator)\n\n\nPalmira1_covar$BIMESTRE=dplyr::recode(Palmira1_covar$MES, \"ene\"=\"Bim_1\", \"feb\"=\"Bim_1\", \"mar\"=\"Bim_2\", \"abr\"=\"Bim_2\", \"may\"=\"Bim_3\",\"jun\"=\"Bim_3\",\"jul\"=\"Bim_4\",\"ago\"=\"Bim_4\",\"sep\"=\"Bim_5\",\"oct\"=\"Bim_5\",\"nov\"=\"Bim_6\",\"dic\"=\"Bim_6\")\nPalmira1_covar &lt;- subset(Palmira1_covar, select = c(\"X_plain\",\"Y_plain\",\"YEAR\",\"BARRIOS\",\"GENERO\",\"DIA_SEMANA\",\"INTERVALOS_HORA\",\"MODALIDAD\",\"EDAD_Cat\",\n\"Armas_indicator\",\"MES\",\"BIMESTRE\",\"LONGITUD\",\"LATITUD\"))\ntable(Palmira1_covar$YEAR,Palmira1_covar$BIMESTRE,Palmira1_covar$INTERVALOS_HORA,Palmira1_covar$GENERO)\n\n\ntable(Palmira1_covar$YEAR,Palmira1_covar$BIMESTRE,Palmira1_covar$INTERVALOS_HORA,Palmira1_covar$EDAD_Cat)\n\n\ntable(Palmira1_covar$YEAR,Palmira1_covar$BIMESTRE,Palmira1_covar$INTERVALOS_HORA,Palmira1_covar$Armas_indicator)\n\n\nPalmira1_covar$CUATRIMESTRE=dplyr::recode(Palmira1_covar$MES, \"ene\"=\"CUATrim_1\", \"feb\"=\"CUATrim_1\", \"mar\"=\"CUATrim_1\", \"abr\"=\"CUATrim_1\", \"may\"=\"CUATrim_2\",\"jun\"=\"CUATrim_2\",\"jul\"=\"CUATrim_2\",\"ago\"=\"CUATrim_2\",\"sep\"=\"CUATrim_3\",\"oct\"=\"CUATrim_3\",\"nov\"=\"CUATrim_3\",\"dic\"=\"CUATrim_3\")\nPalmira1_covar &lt;- subset(Palmira1_covar, select = c(\"X_plain\",\"Y_plain\",\"YEAR\",\"BARRIOS\",\"GENERO\",\"DIA_SEMANA\",\"INTERVALOS_HORA\",\"MODALIDAD\",\"EDAD_Cat\",\"Armas_indicator\",\"MES\",\"CUATRIMESTRE\",\"LONGITUD\",\"LATITUD\"))\ntable(Palmira1_covar$YEAR,Palmira1_covar$CUATRIMESTRE,Palmira1_covar$INTERVALOS_HORA,Palmira1_covar$GENERO)\n\n\ntable(Palmira1_covar$YEAR,Palmira1_covar$CUATRIMESTRE,Palmira1_covar$INTERVALOS_HORA,Palmira1_covar$EDAD_Cat)\n\n\ntable(Palmira1_covar$YEAR,Palmira1_covar$CUATRIMESTRE,Palmira1_covar$INTERVALOS_HORA,Palmira1_covar$Armas_indicator)",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Modelos de Regresión Espacial</span>",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'><span style='color: #728387 !important;'>Redes </span></span>"
    ]
  },
  {
    "objectID": "14-Encuesta Multipropoosito.html",
    "href": "14-Encuesta Multipropoosito.html",
    "title": "5  Encuesta multiproposito",
    "section": "",
    "text": "5.1 R Markdown\nThis is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.rstudio.com.\nWhen you click the Knit button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:\nrequire(spatialreg) #test.W, scores.listw\nrequire(ade4)\nrequire(maptools) #readShapeSpatial\nrequire(spdep) #poly2nb, tri2nb, graphneigh, knn2nb, knearneigh, nb2listw\nrequire(RANN)\nrequire(sp) #coordinates, spplot\nrequire(rgdal)\nrequire(tripack) #neighbours\nrequire(RColorBrewer)\nrequire(epitools) #pois.conf.int\nrequire(DCluster)\nrequire(MASS)\nrequire(R2WinBUGS)\nrequire(dispmod)\nrequire(SpatialPack)\nrequire(nlme)\nrequire(mgcv)\nrequire(CARBayes)\nlibrary(tidyr)\nlibrary(dplyr)\nlibrary(gridExtra)\nlibrary(colorspace)\nlibrary(cowplot)\nlibrary(poissonreg)\nlibrary(VGAM)\nlibrary(pscl)\nlibrary(adespatial)\nlibrary(spdplyr)\nlibrary(ggplot2)\nlibrary(sf)\nlibrary(stringr)\n#install.packages(\"countreg\", repos=\"http://R-Forge.R-project.org\")\nlibrary(poissonreg)\n#library(countreg)\nlibrary(devtools)\n#library(sppois)\nReading the shapefile of 1124 Colombian municipalities, defining the Coordinate Reference System and centroid and building some variables\nsetwd(\"D:/RedesOlga/Multiproposito Bogota\")\nlocalibog&lt;-st_read(\"geovar.shp\")\nlocalibog&lt;- st_as_sf(localibog)\n\n##estud\nggplot() + geom_sf(data=localibog, aes(fill=estud), color=\"grey85\") + theme(text = element_text(size=12))",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Modelos de Regresión Espacial</span>",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'><span style='color: #728387 !important;'>Encuesta Bogotá Multipropósito </span></span>"
    ]
  },
  {
    "objectID": "5.html",
    "href": "5.html",
    "title": "Definición",
    "section": "",
    "text": "Estadística Espacial Funcional",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Estadística Espacial Funcional</span>",
      "<span style='color: #728387 !important;'>Estadística Espacial Funcional</span>"
    ]
  },
  {
    "objectID": "5.html#definición",
    "href": "5.html#definición",
    "title": "Definición",
    "section": "Definición",
    "text": "Definición\nLa geoestadística funcional es una extensión del marco teórico de la geoestadística tradicional, que permite el análisis y modelado de datos funcionales correlacionados espacialmente, tanto univariados como multivariados. Este enfoque incluye herramientas exploratorias, predicción espacial mediante kriging y cokriging, muestreo óptimo, clasificación supervisada y simulación. A través de este enfoque, se modela la estructura de dependencia espacial entre curvas, lo que permite realizar predicciones en ubicaciones no muestreadas utilizando predictores funcionales que minimizan las varianzas del error de predicción. Además, se ofrece la optimización de la configuración de las ubicaciones de muestreo para mejorar la predicción espacial funcional.\nLas herramientas disponibles también permiten la representación gráfica de las curvas predichas en cada ubicación y el mapeo de las superficies en cada punto temporal. La clasificación supervisada integra la correlación espacial, y se extiende a escenarios con medidas funcionales repetidas en cada localización. Finalmente, la simulación de datos funcionales correlacionados espacialmente puede ser tanto condicional como incondicional, y se fundamenta en el supuesto de espacios de Hilbert conjuntos gaussianos.",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Estadística Espacial Funcional</span>",
      "<span style='color: #728387 !important;'>Estadística Espacial Funcional</span>"
    ]
  },
  {
    "objectID": "5.html#datos-funcionales",
    "href": "5.html#datos-funcionales",
    "title": "Definición",
    "section": "Datos Funcionales",
    "text": "Datos Funcionales\nImaginemos que estamos interesados en estudiar cómo varía la temperatura en diferentes ciudades del mundo durante un año completo. Para hacerlo, en lugar de tomar una sola medida de la temperatura, registramos el promedio mensual de la termperatura durante todo un año.\nEn lugar de analizar cada punto de temperatura de manera independiente, podemos ver la temperatura a lo largo del añi como una función continua del tiempo. Esta función nos describe cómo la temperatura cambia en cada instante del día, lo cual permite realizar análisis mucho más precisos.\n\n\n\n\nPZmaps, CC BY-SA 3.0, via Wikimedia Commons\n\n\n\nLos datos funcionales son los que en lugar de contemplar cada dato como una observación puntual, se consideran como funciones continuas observadas en un conjunto de puntos. Los datos funcionales permiten capturar mejor la complejidad de fenómenos que además de variar en el espacio, varían en dominios continuos como el tiempo o la altitud, además de facilitar la detección de tendencias o anomalías teniendo en cuenta múltiples dimensiones de variación.",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Estadística Espacial Funcional</span>",
      "<span style='color: #728387 !important;'>Estadística Espacial Funcional</span>"
    ]
  },
  {
    "objectID": "6.html",
    "href": "6.html",
    "title": "SpatFD",
    "section": "",
    "text": "SpatFD",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Estadística Espacial Funcional</span>",
      "<span style='color: #728387 !important;'>Paquete </span>"
    ]
  },
  {
    "objectID": "6.html#about",
    "href": "6.html#about",
    "title": "SpatFD",
    "section": "About",
    "text": "About\nSpatFD es un paquete en R diseñado para facilitar el análisis de datos espaciales con componentes funcionales. Proporciona herramientas para manejar datos funcionales espaciales, permitiendo a investigadores y analistas explorar, modelar y visualizar de manera eficiente la variabilidad y dependencias espaciales en conjuntos de datos complejos.\nNuestro paquete está pensado para soportar una amplia gama de aplicaciones, desde estudios ambientales hasta econometría, ofreciendo métodos adaptables a diversos dominios. Ya sea que estés trabajando con tendencias geoespaciales, dinámicas temporales o relaciones funcionales, SpatFD te brinda la flexibilidad y las herramientas necesarias para extraer conclusiones significativas.\nSpatFD ha sido desarrollado con un enfoque en la usabilidad y el rendimiento, asegurando que tanto usuarios novatos como experimentados de R puedan aprovechar sus capacidades para realizar investigaciones avanzadas en estadística espacial. Únete a nuestra creciente comunidad de usuarios y explora el potencial de los datos funcionales espaciales con SpatFD.",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Estadística Espacial Funcional</span>",
      "<span style='color: #728387 !important;'>Paquete </span>"
    ]
  },
  {
    "objectID": "6.html#referencias",
    "href": "6.html#referencias",
    "title": "SpatFD",
    "section": "Referencias",
    "text": "Referencias\n\nBohorquez, M., Giraldo, R., & Mateu, J. (2016). Optimal sampling for spatial prediction of functional data. Statistical Methods & Applications, 25(1), 39-54.\nBohorquez, M., Giraldo, R., & Mateu, J. (2016). Multivariate functional random fields: prediction and optimal sampling. Stochastic Environmental Research and Risk Assessment, 31, pages53–70 (2017).\nBohorquez M., Giraldo R. and Mateu J. (2021). Spatial prediction and optimal sampling of functional data in Geostatistical Functional Data Analysis: Theory and Methods. John Wiley Sons, Chichester, UK. ISBN: 978-1-119-38784-8. https://www.wiley.com/en-us/Geostatistical+Functional+Data+Analysis-p-9781119387848.",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Estadística Espacial Funcional</span>",
      "<span style='color: #728387 !important;'>Paquete </span>"
    ]
  },
  {
    "objectID": "5-Análisis de datos funcionales (ADF) - Modelos de regresión.html",
    "href": "5-Análisis de datos funcionales (ADF) - Modelos de regresión.html",
    "title": "6  Análisis de datos funcionales (ADF) - Modelos de regresión",
    "section": "",
    "text": "Modelos lineales funcionales (Regresión Funcional)\nPara explicar la variabilidad de una determinada variable con respecto a otras explicativas, consideradas como covariables, el análisis de varianza y la regresión lineal son los procedimientos que generalmente se utilizan. En este sentido el modelo de regresión funcional es la extensión natural del modelo de regresión usual al caso en el cual se cuenta con una variable respuesta funcional o con covariables funcionales (Aristizabal, 2011).",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Estadística Espacial Funcional</span>",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'><span style='color: #728387 !important;'>FDA-Regresión funcional</span></span>"
    ]
  },
  {
    "objectID": "5-Análisis de datos funcionales (ADF) - Modelos de regresión.html#regresión-lineal-funcional-con-respuesta-funcional-anova-funcional",
    "href": "5-Análisis de datos funcionales (ADF) - Modelos de regresión.html#regresión-lineal-funcional-con-respuesta-funcional-anova-funcional",
    "title": "6  Análisis de datos funcionales (ADF) - Modelos de regresión",
    "section": "6.1 Regresión lineal funcional con respuesta funcional (ANOVA Funcional)",
    "text": "6.1 Regresión lineal funcional con respuesta funcional (ANOVA Funcional)\nEn términos formales (Ramsay & Silverman, 2005) se asume que se cuenta con \\(\\mathbf{G}\\) “tratamientos” cada uno con un número \\(\\mathbf{N_g}\\) de sujetos.\nEl modelo para la \\(m\\) -ésima función (curva) en el g-ésimo grupo (\\((y_{mg}(t))\\), esta dada por:\n\\[\ny_{mg} = \\mu(t) + \\alpha_g(t) + \\varepsilon_{mg}(t)\n\\]\ndónde la función \\(\\mu\\) es la media general, \\(\\alpha_g\\) representa la función media para cada “tratamiento” y \\(\\varepsilon_{mg}\\) es la función de error en cada caso.\nLa tarea entonces, es establecer la matriz de diseño para lograr estimar los parámetros funcionales \\(\\mu\\) y \\(\\alpha_g\\), bajo la condición de que \\(\\sum_g \\alpha_g(t)=0\\) para todo \\(t\\) con el fin de garantizar la estimabilidad de los mismos.\nEn términos matriciales el modelo queda determinado como:\n$$\ny_{mg}(t) =",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Estadística Espacial Funcional</span>",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'><span style='color: #728387 !important;'>FDA-Regresión funcional</span></span>"
    ]
  },
  {
    "objectID": "6-Análisis de datos funcionales (ADF) - Modelos de regresión (Parte 2).html",
    "href": "6-Análisis de datos funcionales (ADF) - Modelos de regresión (Parte 2).html",
    "title": "7  Análisis de datos funcionales (ADF) - Modelos de regresión",
    "section": "",
    "text": "Modelos lineales",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Estadística Espacial Funcional</span>",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'><span style='color: #728387 !important;'>FDA-Regresión escalar</span></span>"
    ]
  },
  {
    "objectID": "6-Análisis de datos funcionales (ADF) - Modelos de regresión (Parte 2).html#regresión-lineal-funcional-con-respuesta-escalar",
    "href": "6-Análisis de datos funcionales (ADF) - Modelos de regresión (Parte 2).html#regresión-lineal-funcional-con-respuesta-escalar",
    "title": "7  Análisis de datos funcionales (ADF) - Modelos de regresión",
    "section": "8.1 Regresión Lineal funcional con respuesta escalar",
    "text": "8.1 Regresión Lineal funcional con respuesta escalar\nLa función fRegress realiza un análisis de regresión funcional, donde la variable dependiente o una o más variables independientes son funcionales. Las variables no funcionales se pueden utilizar en cualquier lado de la ecuación. En un problema simple donde hay una sola covariable escalar independiente con valores \\(z_i\\) con \\(i=1,2,...n\\) y una sola covariable funcional con valores \\(x_i(t)\\), el modelo establecido es:\n\\[\ny_i = \\beta_1z_i + \\int x_i(t)\\beta_2(t)dt + e_i\n\\] A través de esta función también es posible llevar a cabo la estimación de los parámetros del modelo concurrente con la variable dependiente funcional dado por:\n\\[\ny_i = \\beta_1 z_i + \\beta_2(t)x_i(t) +e_i(t)\n\\] Los parámetos \\(e_i\\) y \\(e_i(t)\\)son los residuales modelo (falta de ajuste o término error). Observe que, en el modelo lineal funcional concurrente para una variable dependiente funcional, todas las variables funcionales se evalúan en un tiempo común o valor de argumento \\(t\\). Es decir, el ajuste se define en términos del comportamiento de todas las variables en un momento fijo, o en términos del comportamiento del “ahora”.\nTodas las funciones de coeficientes \\(\\beta_j(t)\\) son consideradas objetos funcionales. En el caso de una variable dependiente escalar, el coeficiente de regresión para una covariable escalar es convertido a una variable funcional con una base de constantes. Todas las funciones de coeficientes de regresión se pueden forzar para que sean uniformes mediante el uso de penalizaciones por aspereza o rugosidad y, en consecuencia, se especifican en la lista de argumentos como objetos de los parámetros funcionales.\nEn esta sección vamos a predecir el logaritmo de la precipitación anual para 35 estaciones meteorológicas canadienses a partir de sus perfiles de temperatura. Se utiliza como variable predictora el perfil de temperatura completo y un intercepto constante. Estas dos covariables se pueden almacenar en una lista de longitud 2. Así, configuramos un objeto de datos funcional para la temperatura con 35 perfiles en un objeto llamado tempfd. Asmismo, utilizamos 65 funciones de una base de Fourier sin penalización. Este número de funciones de base es adecuado para la mayoría de los propósitos y puede, por ejemplo, capturar la ondulaciones observadas a principios de la primavera en muchas estaciones meteorológicas (Ramsay & Silverman, 2005).\n\nlibrary(fda)\nlibrary(fda.usc)\nlibrary(rainbow)\nlibrary(MASS)\nlibrary(xtable)\nannualprec = log10(apply(daily$precav,2,sum))\ntempbasis =create.fourier.basis(c(0,365),65)\ntempSmooth=smooth.basis(day.5,daily$tempav,tempbasis)\ntempfd =tempSmooth$fd\ntemplist = vector(\"list\",2)\ntemplist[[1]] = rep(1,35)\ntemplist[[2]] = tempfd\n\nLa estrategia más simple para estimar los parámetros funionales es mantener una dimensionalidad en el proceso de suavizamiento relativamente pequeño. Para este caso, trabajaremos con cinco funciones de una base de Fourier para la estimación del coeficiente de regresión (pendiente) y una función constante para el intercepto.\n\nconbasis = create.constant.basis(c(0,365))\nbetabasis = create.fourier.basis(c(0,365),5)\nbetalist = vector(\"list\",2)\nbetalist[[1]] = conbasis\nbetalist[[2]] = betabasis\n\nUna vez definidas las funciones base para los parámetros de regresión, procedemos a realizar el proceso de regresión:\n\nfRegressList = fRegress(annualprec,templist,betalist)\nbetaestlist = fRegressList$betaestlist\ntempbetafd = betaestlist[[2]]$fd\nplot(tempbetafd, xlab=\"Día\",\nylab=\"Coeficiente Beta para temperatura\")\n\n\n\n\n\n\n\n\n[1] \"done\"\n\n\nLa Figura anterior muestra el resultado. El intercepto se puede obtener de coef(betaestlist[[1]]).Su valor en este caso es 3.464844.\nPara evaluar la calidad de este ajuste, se extraen los valores ajustados definido por este modelo y se calculan los residuos. De manera análoga que en el caso escalar, se calculan las sumas de cuadrados de los residuales con el modelo completo y utilizando solo el parámetro de intercepto y se comparan a través de la estadística \\(F\\).\n\nannualprechat1 = fRegressList$yhatfdobj\nannualprecres1 = annualprec - annualprechat1\nSSE1 = sum(annualprecres1^2)\nSSE0 = sum((annualprec - mean(annualprec))^2)\nRSQ1 = (SSE0-SSE1)/SSE0\nRSQ1\n\n[1] 0.7955986\n\n\n\nFratio1 = ((SSE0-SSE1)/5)/(SSE1/29)\nFratio1\n\n[1] 22.57554\n\n\n\nFratio1 = ((SSE0-SSE1)/5)/(SSE1/29)\nFratio1\n\n[1] 22.57554\n\n\nEl coeficiente de correlación al cuadrado presenta un valor de 0.7955 y la estadística F un valor de 22.57, que tiene asociado un valor p menor al 1%",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Estadística Espacial Funcional</span>",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'><span style='color: #728387 !important;'>FDA-Regresión escalar</span></span>"
    ]
  },
  {
    "objectID": "6-Análisis de datos funcionales (ADF) - Modelos de regresión (Parte 2).html#estimación-de-los-coeficientes-β-con-regularización",
    "href": "6-Análisis de datos funcionales (ADF) - Modelos de regresión (Parte 2).html#estimación-de-los-coeficientes-β-con-regularización",
    "title": "7  Análisis de datos funcionales (ADF) - Modelos de regresión",
    "section": "8.2 Estimación de los coeficientes β con regularización",
    "text": "8.2 Estimación de los coeficientes β con regularización\nHay dos maneras de obtener un ajuste suave de las curvas de parámetros \\(\\beta(t)\\). La más sencilla es la revisada anteriomente en la cual se utiliza un modelo de baja dimensión. Sin embargo, podemos tener un control más directo sobre la “suavidad” de la curva mediante el uso de una penalización por rugosidad como se vió en la guía 1 (Ramsay & Silverman, 2005).\nAplicando este enfoque para predecir las precipitaciones logarítmicas anuales se debe configurar un operador de aceleración armónica:\n\nLcoef = c(0,(2*pi/365)^2,0)\nharmaccelLfd = vec2Lfd(Lcoef, c(0,365))\n\nAhora creamos el objeto funcional incorporando la penalización por rugosidad:\n\nbetabasis = create.fourier.basis(c(0, 365), 35)\nlambda = 10^12.5\nbetafdPar = fdPar(betabasis, harmaccelLfd, lambda)\nbetalist[[2]] = betafdPar\n\nY estimamos los parámetros funcionales con el uso de la función fRegress:\n\nannPrecTemp = fRegress(annualprec, templist,\nbetalist)\nbetaestlist2 = annPrecTemp$betaestlist\nannualprechat2 = annPrecTemp$yhatfdobj\n\nFinalmente, calculamos las estadísticas habituales de \\(R^2\\)y la razón \\(F\\)para evaluar el ajuste del modelo:\n\nSSE2 = sum((annualprec-annualprechat2)^2)\nRSQ2 = (SSE0 - SSE2)/SSE0\nRSQ2\n\n[1] 0.7537658\n\n\n\nFratio2 = ((SSE0-SSE2)/3.7)/(SSE1/30.3)\nFratio2\n\n[1] 30.19907\n\n\nPara completar el análisis, se utiliza una base constante para la estimación del intercepto y se compara con el modelo completo. Los grados de libertad de este modelo reducido son ahora 2.\n\nbetafdPar = fdPar(betabasis, harmaccelLfd, lambda)\nbetalist[[2]] = betafdPar\nfRegressList = fRegress(annualprec, templist,\nbetalist)\nbetaestlist = fRegressList$betaestlist\nannualprechat = fRegressList$yhatfdobj\nSSE1 = sum((annualprec-annualprechat)^2)\nRSQ = (SSE0 - SSE1)/SSE0\nRSQ \n\n[1] 0.7537658\n\n\n\nFratio = ((SSE0-SSE1)/1)/(SSE1/33)\nFratio\n\n[1] 101.0188\n\n\nAsimismo, es posible estimar intervalos de confianza:\n\n8.2.1 Prueba F para ajuste del modelo a través de permutaciones\nDebido a la naturaleza de las estadísticas funcionales, es difícil intentar derivar una distribución nula teórica para cualquier estadística de prueba, ya que se tendría que tener en cuenta el parámetro de suavizamiento. Ramsay & Silverman (2005) proponen utilizar una metodología de prueba basada en permutaciones. El supuesto utilizado es que si no hay relación entre la respuesta y las covariables, no debería darse ninguna diferencia si se reorganiza al azar la forma en que están emparejados. La función para realizar la respectiva prueba de hipótesis es Fperm.fd",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Estadística Espacial Funcional</span>",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'><span style='color: #728387 !important;'>FDA-Regresión escalar</span></span>"
    ]
  },
  {
    "objectID": "7-Análisis de datos funcionales (ADF) - Análisis gráfico.html",
    "href": "7-Análisis de datos funcionales (ADF) - Análisis gráfico.html",
    "title": "8  Análisis de datos funcionales (ADF) - Modelos de regresión",
    "section": "",
    "text": "ADF",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Estadística Espacial Funcional</span>",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'><span style='color: #728387 !important;'>FDA-Regresión escalar</span></span>"
    ]
  },
  {
    "objectID": "7-Análisis de datos funcionales (ADF) - Análisis gráfico.html#análisis-gráfico",
    "href": "7-Análisis de datos funcionales (ADF) - Análisis gráfico.html#análisis-gráfico",
    "title": "8  Análisis de datos funcionales (ADF) - Modelos de regresión",
    "section": "8.1 Análisis gráfico",
    "text": "8.1 Análisis gráfico\nPor ejemplo, consideremos la temperatura promedio mensual de la superficie del océano en grados Celsius, registrada desde Enero de 1982 a Abril de 2022, disponible en:https://www.cpc.ncep.noaa.gov/data/indices/sstoi.indices.\nRealizamos la lectura de los datos:\n\nlibrary(fda)\nlibrary(fda.usc)\nlibrary(rainbow)\nlibrary(MASS)\nlibrary(xtable)\nsetwd(\"C:/Users/jpari/Dropbox/FDA\")\nDatos =read.delim2(\"sstoi.indices1.txt\",header=T,dec=\".\", sep = \"\\t\")\nsummary(Datos)\n\nReorganizamos la información para que cada año sea una curva. No tenemos en cuenta el año 2022 por no disponer de la información de todo el año.\n\n\ntemp &lt;- matrix(Datos$NINO1.2[-c(481:484)], nrow=12, 40)\ncolnames(temp)=c(1982:2021)\n\nConstruimos las gráficas para cada año\n\nmonth&lt;-1:12\nplot(month, temp[,1], type=\"b\", ylim=c(18, 30), xlab=\"Mes\", ylab=\"temperatura\")\nfor(i in 2:ncol(temp))\nlines(month, temp[,i], type=\"b\", col=i)\n\n\n8.1.1 Deteccción de curvas atípicas\nEs posible realizar detección de datos atípicos (outliers) a través de las herramientas: bagplot, HDR y boxplot para datos funcionales.\nCon respecto a la base de datos de la temperatura, utilizando las profundidades dadas a través del criterio de bagplot, se muestran nueves curvas atípicas. La identicación de las curvas se encuentra en la parte superior del panel izquierdo de la siguiente figura. Se destaca, que el factor de inflación utilizado en este caso toma el valor de 1.96 que es el establecido por defecto en la función tipo bag.\n\nTempTs = sfts(ts(as.numeric(temp), start = c(1982,1),frequency = 12), xname = \"Mes\",\nyname = \"Temperatura oC\")\npar(mfrow=c(1,2))\nfboxplot(data= TempTs, plot.type = \"functional\", type = \"bag\", projmethod = \"PCAproj\")\nfboxplot(data= TempTs, plot.type = \"bivariate\", type = \"bag\", projmethod = \"PCAproj\",\nylim = c(-6,6), xlim = c(-15,6))\n\nAnálogamente, teniendo en cuenta la profundidad a través del criterio de HDR plot, se evidencian dos curvas atípicas identificadas con los años 1997 y 2015. Para este caso los porcentajes de cobertura de los datos atípicos y de la región central tenidos en cuenta fueron los establecidos por defecto en la respectiva función (0.05, 0.5).\n\npar(mfrow=c(1,2))\nfboxplot(data= TempTs, plot.type = \"functional\", type = \"hdr\", projmethod = \"PCAproj\")\nfboxplot(data= TempTs, plot.type = \"bivariate\", type = \"hdr\", projmethod = \"PCAproj\",\nylim = c(-6,6), xlim = c(-15,6))\n\nFinalmente, al utilizar la herramienta del boxplot funcional, teniendo en cuenta la profundidad dada por la versión modificada de Band-depth, existe una curva atípica (1990). La probabilidad de la región central utilizada para realizar el gráfico fue de 0.5.\n\npar(mfrow=c(1,1))\nfbplot(fit= temp, method = \"BD2\", xlab = \"Mes\", ylab = \"Temperatura oC\")\n\nAl comparar la detección de datos atípicos utilizando las tres herramientas mencionadas (bagplot, hdr plot y fbplot) en la muestra de las 40 curvas de temperatura, se evidencia que el bagplot resulta ser la herramienta más estricta o exigente en cuanto a que detecta nueve curvas como atípicas, mientras que las otras dos detectaron dos y una, respectivamente. Es importante destacar que, lo que permite comparar las diferentes herramientas en términos de exigencia es utilizar las opciones de probabilidades de cobertura y factor de infación establecidas por defecto.\n\n\n8.1.2 Otras medidas de resumen\nCon datos funcionales también es posible calcular otras etadísticas de resumen como la moda, medias recortadas y la mediana.\n\n#*********************************************************\n#Parámetros estimados - Media recortada al 10%\n#*********************************************************\npar(mfrow=c(1,1))\n###Calcula la profundidad de Fraiman and Muniz (2001)\nMedFM = fdepth(data = TempTs, type = \"FM\", trim = 0.1)\nplot(MedFM)\n\n\n###Calcula la profundidad a través de proyecciones aletorias de Cuevas et al. (2007)\nMedRP = fdepth(data = TempTs, type = \"RP\", trim = 0.1)\nplot(MedRP)\n\n\nMedRPD = fdepth(data = TempTs, type = \"RPD\", trim = 0.1)\nplot(MedRPD)\n\n\n#***********************************************************\n#Parametros estimados - Moda\n#***********************************************************\nMODA = fdepth(data = TempTs, type = \"mode\", trim = 0.1)\nplot(MODA)\n\nFinalmemnte, a través de procedimientos bootstrap es posible estimar intervalos de confianza para las medidas de resumen.\n\n#***********************************************************\n#Boostrap Funcional\n#***********************************************************\n\n\nBSpl &lt;- create.bspline.basis(norder=4, breaks=seq(0,12,length=5))\nFtemp &lt;- Data2fd(temp, basisobj=BSpl)\n\n\nplot(Ftemp, main=\"Datos suavizados de la Temperatura\", xlab = \"Mes\", ylab = \"Temperatura oC\",\nylim=c(18,30))\n\n\nout.boot1=fdata.bootstrap(Ftemp,statistic=func.mean,nb=200,draw=TRUE)\n\n\nout.boot2=fdata.bootstrap(Ftemp,statistic=func.trim.FM,nb=100,draw=TRUE)\n\n\nout.boot2=fdata.bootstrap(Ftemp,statistic=func.trim.mode,nb=100,draw=TRUE, trim = 0.1)\n\n\nout.boot2=fdata.bootstrap(Ftemp,statistic=func.trim.RP,nb=100,draw=TRUE, trim = 0.1)\n\n\n\n8.1.3 Análisis en Componentes Principales (ACPF)\nEl análisis de componentes principales funcionales (ACPF) es una extensión del ACP clásico en el que las componentes principales están representadas por funciones y no por vectores (Ramsay & Sylverman, 2005). La idea fundamental del análisis de componentes principales es reducir la dimensión del conjunto de datos conservando tanto como sea posible la variación presente en los mismos.\n\n\n\n\n\nFuente: Chávez-Chong,Sánchez-García y DelaCerda-Gastélum (2015), disponile en https://rio.upo.es/xmlui/bitstream/handle/10433/2768/1694-5314-1-SM.pdf?sequence=1&isAllowed=y#:~:text=AN%C3%81LISIS%20DE%20COMPONENTES%20PRINCIPALES%20(ACP)&text=Es%20decir%3A%20reducir%20la%20dimensi%C3%B3n,la%20biometr%C3%ADa%20de%20la%20%C3%A9poca.\nSi se aplica el método a las curvas de temperturas trabajadas hasta el momento, reteniendo en el análisis 4 componentes, la primera función retiene el 70.1% de la variabilidad total de las curvas, la segunda función, el 20.9%, la tercera, el 4.8% y la cuarta, el 2.7%. Las funciones de componentes principales se muestran como perturbaciones de la curva media, que es la línea continua. Los + muestran lo que sucede cuando una pequeña cantidad de un componente principal se suma a la media, y los - muestran el efecto de restar este componente.\n\n#***********************************************************\n#ACPF\n#***********************************************************\nPCA = pca.fd(Ftemp, 4)\nplot(PCA\n\n\nplot.pca.fd(PCA)\n\n\nplot(x = PCA$scores[,1], y = PCA$scores[,2], cex = 0.001)\ntext(x = PCA$scores[,1], y = PCA$scores[,2] , seq(1982,2021,1), cex = 0.5 )",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Estadística Espacial Funcional</span>",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'><span style='color: #728387 !important;'>FDA-Regresión escalar</span></span>"
    ]
  },
  {
    "objectID": "9-Análisis de datos funcionales (ADF) - Análisis exploratorio.html",
    "href": "9-Análisis de datos funcionales (ADF) - Análisis exploratorio.html",
    "title": "9  Análisis de datos funcionales (ADF)- Análisis exploratorio",
    "section": "",
    "text": "Datos funcionales",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Estadística Espacial Funcional</span>",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'><span style='color: #728387 !important;'>FDA – Análisis descriptivo</span></span>"
    ]
  },
  {
    "objectID": "9-Análisis de datos funcionales (ADF) - Análisis exploratorio.html#datos-funcionales-1",
    "href": "9-Análisis de datos funcionales (ADF) - Análisis exploratorio.html#datos-funcionales-1",
    "title": "9  Análisis de datos funcionales (ADF)- Análisis exploratorio",
    "section": "9.1 Datos funcionales",
    "text": "9.1 Datos funcionales\n\n9.1.1 Descripción\nLos desarrollos tecnólogicos han hecho posible que los investigadores de muchas áreas dispongan de grandes volúmenes de información para un mismo individuo. Usualmente éstos datos pueden ser representados a través de curvas o en general de funciones.\nEn el ADF la unidad básica de información es la función completa, más que un conjunto de valores (Ramsay and Dalzell, 1991), es decir, que un dato funcional se puede establecer como la extensión de medidas repetidas cuando la cantidad de mediciones \\((M)\\) en un determinado individuo es muy grande.\nFerraty and Vieu (2006) definen una variable aleatoria funcional \\(\\chi\\) como una variable aleatoria que toma valores en un espacio de funciones, es decir, un espacio infinito dimensional (espacio funcional). Una observación \\(x\\) de la variable aleatoria \\(\\chi\\) se denomina dato funcional.\nUn conjunto de datos funcionales \\(x_1,x_2,...,x_n\\) es la observación \\(n\\) variables funcionales distribuidas como \\(\\chi\\). Un dato funcional \\(x_i(t), t \\in T=[a,b] \\subset R\\), es representado usualmente como un conjunto finito de pares \\((t_j, x_{ij})\\) con \\(t_j \\in T, j=1,2,...,M\\), dónde \\(M\\) representa la cantidad de puntos de los cuales es obserbada la variable de interés y \\(y_{ij}= \\chi_i(t_j)\\) (si o existe error observacional ) o \\(y_{ij} = \\chi_i(t_j) + \\varepsilon_j\\) (en caso contrario).\nPor eje,plo, consideremos la temperatura promedio mensual de la superficie del óceano en grados Celsius registrada desde Enero 1982 a abril de 2022, disponible en: https://www.cpc.ncep.noaa.gov/data/indices/sstoi.indices.\nRealizamos la lectura de los datos:\n\nlibrary(fda)\n\n\nlibrary(fda.usc)\n\n\nlibrary(rainbow)\nlibrary(MASS)\nlibrary(xtable)\nsetwd(\"C:/Users/jpari/Dropbox/FDA\")\nDatos =read.delim2(\"sstoi.indices1.txt\",header=T,dec=\".\", sep = \"\\t\")\nsummary(Datos)\n\nReorganizamos la información para que cada año sea una curva. No tenemos en cuenta el año 2022 por no disponer de la información de todo el año.\n\ntemp &lt;- matrix(Datos$NINO1.2[-c(481:484)], nrow=12, 40)\ncolnames(temp)=c(1982:2021)\n\nConstruimos las gráficas para cada año\n\nmonth&lt;-1:12\nplot(month, temp[,1], type=\"b\", ylim=c(18, 30), xlab=\"Mes\", ylab=\"temperatura\")\nfor(i in 2:ncol(temp))\nlines(month, temp[,i], type=\"b\", col=i\n\n\n\n9.1.2 Suavizamiento de curvas\nUna herramienta no paramétrica de mucha utilidad en el ADF es el suavizado de curvas a través de funciones. El procedimiento consiste en aproximar las funciones del espacio considerado a través de (Ramsay and Silverman, 2005):\n\\[\n\\chi(t) = \\sum_{l=1}^K c_lB_l(t) = c'B(t)\n\\]\ndonde K es el número de funciones de la base.\nEn la literatura exisste varias funciones base que permiten desarrollar la expansión. La selección del tipo de funciones de la base depende de las caracteríticas que cumpla que fenómeno de estudio. Por ejemplo, las series de Fourier se utilizan para funciones con comportamientos cíclicos o periódicos y las bases monomiales se utilizan cuando existen tendencias simples que pueden ser ajustadas mediante líneas rectas, polinomios cuadráticos, polinomios de orden superior, etc. Las bases más usuales son aquellas basadas en splines debido a que son más flexibles y se ajustan de mejor manera a diferentes comportamientos. Dentro de estas se encuentran B-splines, M-splines, I-splines, y fucniones de potencia truncadas.\n\n9.1.2.1 Bases monomiales\nLas bases monomiales requieren el dominio y el número de base. Por ejemplo, la base monomial con K=6 funciones de base definidas en el intervalo [0,1] se puede construir con:\n\nlibrary(fda)\nbbasis_obj = create.monomial.basis(rangeval=c(0,1), nbasis = 6)\n\nEsto devolverá una salida de “funciones”. Para evaluar las bases en una cuadrícula de puntos \\(s\\), debemos:\n\nlibrary(fda)\nx &lt;- seq(0,1,length.out=100)\nbbasisevals &lt;- eval.basis(x, bbasis_obj)\n# dim(basisevals)\nmatplot(x, bbasisevals, type='l', lty=1, col=rainbow(6),\n        xlab=\"x\", ylab=\"bases\", \n        main=\"base monomial con k = 6\")\n\n\n\n9.1.2.2 Bases de Fourier\nPara utilizarlas bases de Fourier se requiere que se defina el dominio, el período de oscilación y el número de funciones de base.\n\nfbasis_obj &lt;- create.fourier.basis(rangeval=c(0,1), \n                                   nbasis=65, period = 1)\nfbasisevals &lt;- eval.basis(x, fbasis_obj)\nmatplot(x, fbasisevals[, 1:3], type='l', lty=1, col=rainbow(3),\n        xlab=\"x\", ylab=\"bases\", \n        main=\"Primeras tres bases de Fourier\")\n\n\n\n9.1.2.3 B-splines\nLas bases B-spline requieren el dominio, el número de funciones de la base y el orden.\n\nbsbasis_obj &lt;- create.bspline.basis(rangeval=c(0,1),\n                                    nbasis=10, norder=4)\nbsbasisevals &lt;- eval.basis(x, bsbasis_obj)\nmatplot(x, bsbasisevals, type='l', lty=1, col=rainbow(15),\n        xlab=\"x\", ylab=\"bases\", \n        main=\"B-spline cubica con K = 10\")\n\n\n\n9.1.2.4 Otras bases\nEl paquete también se puede usar para construir otros tipos de bases. Para revisar la lista de bases disponibles se puede utilizar $ ?create. + tab$\n\n\n9.1.2.5 Suavizamiento de la temperatura\nLa temperatura es una variable que se puede tomar en intervalos más pequeños (diaria, cada hora, etc). Es decir, al realizar la gráfica anterior estamos suponiendo que podemos discretizar la variable de temperatura a través de la medición mensual.La primera tarea es convertir estos valores discretos en una función que puede tomar valores en cualquier valor de argumento deseado \\(x_i(t)\\) Si se supone que estas observaciones no presentan un término de error asociado, el proceso de generación de la función (curva) será un proceso de interpolación, pero si tienen algún error observacional que necesita modelarse, entonces la conversión de datos (finitos) a funciones (que teóricamente se pueden evaluar en un número infinito de puntos) se enmarca en los procesos de suavizamiento.\nEn consecuencia, requerimos una estrategia para construir funciones con parámetros que sean fáciles de estimar y que puedan ajustarse casi a cualquier característica de la curva. Por otro lado, no queremos usar más parámetros de los que necesitamos, ya que hacerlo aumentaría en gran medida el tiempo de cálculo y complicar los análisis. Para el caso de la temperatura se utiliza una B-spline de orden 4.\n\nBSpl &lt;- create.bspline.basis(norder=4, breaks=seq(0,12,length=5))\nplot(BSpl)\n\n\nFtemp &lt;- Data2fd(temp, basisobj=BSpl)\n\n\nplot(Ftemp, main=\"Datos suavizados de la Temperatura\", xlab = \"Mes\", ylab = \"Temperatura oC\",\nylim=c(18,30))\n\nEn el proceso de suavizamiento es necesario tener en cuenta la rugosidad como un aspecto fundamental. El método utilizado para aproximar funciones mediante una base de funciones B-splines se basa en minimizar el sistema:\n\\[\nGCV = \\min_{c} \\sum_{j=1}^{M} (y_{j} - S(t_{j}))^{2} + \\lambda \\int_{t} (S''(t)dt)\n\\]\ncon \\(\\lambda\\) un parámetro de penalización para disminuir la variabilidad del ajuste. El número de funciones base (K) y el coeficiente \\(\\lambda\\) son estimados a través de procedimientos de validación cruzada (Ramsay and Silverman, 2005). Con el siguiente programa se puede establecer la estimación del parámetro de suavizamiento óptimo.\n\nloglam = seq(0,0.05,0.001)\nnlam = length(loglam)\ndfsave = rep(NA,nlam)\ngcvsave = rep(NA,nlam)\nfor (ilam in 1:nlam) {\nlambda = loglam[ilam]\nfdParobj = fdPar(BSpl, Lfdobj=NULL, lambda= lambda)\nsmoothlist = smooth.basis(1:12, temp, fdParobj)\ndfsave[ilam] = smoothlist$df\ngcvsave[ilam] = sum(smoothlist$gcv)\n}\nplot(loglam,gcvsave,xlab=expression(lambda),ylab=expression(GCV(lambda)),\nmain=\"Parámetros de suavizamiento versus GCV\",type=\"b\",cex=0.7)\n\nTomando como referencia los 40 añoos reportados (de 1982 a 2021) en la base de datos de interés, se evidencia que el punto que minimiza la estadística GCV se encuentra alrededor de \\(\\nu=0.017\\) con valores muy superiores antes de 0.01 y después de 0.04. Se destaca que dicho parámetro minimiza la suma del criterio GCV de todas las 40 curvas que se encuentran dentro de la muestra, es decir, el valor de dicho parámetro resulta ser el óptimo en relación con el proceso de suavizamiento de todas las curvas dentro de la muestra.\n\n\n\n9.1.3 Estadística descriptiva\nDado un conjunto de datos funcionales \\(x_1,x_2,...,x_n\\) definicos en \\(t \\subset T \\in R\\), las correspondientes funciones descriptivas están dadas por las expresiones (Ramsay and silverman, 2005):\n\\[\nMedia: \\quad  \\bar{\\chi}(t) = \\frac{\\sum_{i=1}^{n} \\chi_{i}(t)}{n}\n\\]\n\\[\nVarianza: \\quad \\bar{\\chi}(t) = \\frac{\\sum_{i=1}^{n} \\chi_{i}(t)}{n}\n\\]\n\\[\nDesviación \\ estándar : \\quad \\sigma(\\chi(t)) = \\sqrt{var(\\chi(t))}\n\\]\nAsí, se puede concluir que las estadísticas descriptivas univariadas clásicas se aplican igualmente cuando se tienen datos funcionales. Sin embargo se resalta que en este caso, los objetos calculados corresponden a curvas.\n\nmeanfdh &lt;- mean.fd(Ftemp)\nvarfdh &lt;-var.fd(Ftemp)\nstdvfdh &lt;- stddev.fd(Ftemp)\nplot(Ftemp,col=8, lty=1, xlab = \"Mes\", ylab = \"Temperatura oC\")\n\n\nlines(meanfdh,col=2,lwd=2)\n\n\npar(mfrow=c(1,2))\nplot(varfdh, main=\" Superficie de varianza\", xlab = \"t\", ylab = \"s\")\n\n\npar(mfrow=c(1,2))\nplot(varfdh, main=\" Superficie de varianza\", xlab = \"t\", ylab = \"s\")",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Estadística Espacial Funcional</span>",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'><span style='color: #728387 !important;'>FDA – Análisis descriptivo</span></span>"
    ]
  },
  {
    "objectID": "7.html",
    "href": "7.html",
    "title": "Objetos SpatFD",
    "section": "",
    "text": "Objetos SpatFD\nEl objeto SpatFD crea objetos univariados y multivariados de clase SpatFD a partir de coordenadas espaciales, funciones o series temporales observadas en cada ubicación espacial. El término “series temporales” es genérico, ya que las observaciones pueden estar relacionadas con la frecuencia u otra dimensión espacial, como la profundidad, en lugar del tiempo.",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Objetos </span>",
      "<span style='color: #728387 !important;'>SpatFD</span>"
    ]
  },
  {
    "objectID": "7.html#argumentos",
    "href": "7.html#argumentos",
    "title": "Objetos SpatFD",
    "section": "Argumentos",
    "text": "Argumentos\n\ndata: Los datos deben ser proporcionados en un data-frame o una matriz donde cada columna corresponde a una ubicación, y las filas son una secuencia de puntos de datos, ordenados según el tiempo, frecuencia, profundidad, etc. También puede ser un objeto fd del paquete fda.\ncoords: Un data-frame o matriz con coordenadas espaciales (x, y). El número de columnas en data debe coincidir con el número de filas en coords para cada variable.\nbasis: Funciones base. Puede ser “Fourier” o “Bsplines” (predeterminado: “Bsplines”).\nnbasis: El número de funciones base.\nlambda: Valor del parámetro de suavizado.\nnharm: Número de armónicos o funciones propias reportados en los resultados de Componentes Principales Funcionales.\nname: Se puede asignar un nuevo nombre a los datos.\nadd: Se pueden agregar otras variables para la predicción funcional multivariada espacial (cokriging funcional). No es necesario que todas las variables estén observadas en las mismas ubicaciones espaciales.\n…: Argumentos adicionales de fda como create.bspline.basis o create.fourier.basis.",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Objetos </span>",
      "<span style='color: #728387 !important;'>SpatFD</span>"
    ]
  },
  {
    "objectID": "7.html#detalles",
    "href": "7.html#detalles",
    "title": "Objetos SpatFD",
    "section": "Detalles",
    "text": "Detalles\nLos objetos SpatFD almacenan los datos funcionales, sus parámetros, los resultados de análisis de componentes principales funcionales, y las coordenadas espaciales para cada variable. Cada variable tiene su propio conjunto de datos funcionales, data-frame o matriz, y archivo de coordenadas espaciales.",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Objetos </span>",
      "<span style='color: #728387 !important;'>SpatFD</span>"
    ]
  },
  {
    "objectID": "7.html#valor",
    "href": "7.html#valor",
    "title": "Objetos SpatFD",
    "section": "Valor",
    "text": "Valor\nPara cada variable: Se proporcionan los datos funcionales y los componentes principales funcionales vinculados con las coordenadas espaciales.",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Objetos </span>",
      "<span style='color: #728387 !important;'>SpatFD</span>"
    ]
  },
  {
    "objectID": "7.html#notas",
    "href": "7.html#notas",
    "title": "Objetos SpatFD",
    "section": "Notas",
    "text": "Notas\n\nAunque no hay un límite para el número de variables en el cokriging funcional, la verdadera limitación está en los requisitos para encontrar un modelo de covarianza multivariada válido. Se recomienda aplicar el principio de parsimonia.\nLas ubicaciones deben estar en la misma región de interés para que tenga sentido incluirlas en el mismo modelo de predicción. Sin embargo, cada variable puede estar observada en diferentes ubicaciones espaciales y tener un número diferente de observaciones",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Objetos </span>",
      "<span style='color: #728387 !important;'>SpatFD</span>"
    ]
  },
  {
    "objectID": "7.html#forma-de-uso",
    "href": "7.html#forma-de-uso",
    "title": "Objetos SpatFD",
    "section": "Forma de uso",
    "text": "Forma de uso\n\nlibrary(SpatFD)\n# Cargar datos\ndata(AirQualityBogota)\n\n# Crear un objeto univariado usando 2 nharm\nSFD_PM10 &lt;- SpatFD(PM10, coords = coord[,2:3], basis = \"Bsplines\", nbasis = 91,\nlambda = 0.00002, nharm = 2)\n\n\nstr(SFD_PM10)\n\nList of 1\n $ PM10:List of 7\n  ..$ data         :'data.frame':   8761 obs. of  10 variables:\n  .. ..$ Bosque       : int [1:8761] 29 32 32 24 29 31 24 26 25 36 ...\n  .. ..$ IDRD         : int [1:8761] 53 48 25 36 17 7 9 12 12 13 ...\n  .. ..$ Carvajal_Sony: int [1:8761] 72 69 61 30 42 44 30 39 53 49 ...\n  .. ..$ Guaymaral    : int [1:8761] 74 55 58 51 41 39 46 60 54 41 ...\n  .. ..$ Suba_Corpas  : int [1:8761] 53 52 45 45 38 40 44 67 51 41 ...\n  .. ..$ Fontibon     : int [1:8761] 65 49 35 40 26 23 21 29 32 30 ...\n  .. ..$ PteAranda    : int [1:8761] 91 70 45 43 33 11 15 28 24 31 ...\n  .. ..$ MAVDT        : int [1:8761] 31 32 32 29 21 21 25 29 26 32 ...\n  .. ..$ Kennedy      : int [1:8761] 135 94 68 53 47 45 49 59 62 71 ...\n  .. ..$ Tunal        : int [1:8761] 38 29 18 17 24 24 19 15 20 35 ...\n  ..$ coords       :'data.frame':   10 obs. of  2 variables:\n  .. ..$ X: num [1:10] 105076 99661 92104 103675 98239 ...\n  .. ..$ Y: num [1:10] 112526 106572 99968 120780 118365 ...\n  ..$ coordsnames  : chr [1:10] \"Bosque\" \"IDRD\" \"Carvajal_Sony\" \"Guaymaral\" ...\n  ..$ data_fd      :List of 3\n  .. ..$ coefs  : num [1:91, 1:10] 22.6 37.3 13.3 40.6 26.2 ...\n  .. .. ..- attr(*, \"dimnames\")=List of 2\n  .. .. .. ..$ : chr [1:91] \"bspl4.1\" \"bspl4.2\" \"bspl4.3\" \"bspl4.4\" ...\n  .. .. .. ..$ : chr [1:10] \"Bosque\" \"IDRD\" \"Carvajal_Sony\" \"Guaymaral\" ...\n  .. ..$ basis  :List of 10\n  .. .. ..$ call       : language basisfd(type = type, rangeval = rangeval, nbasis = nbasis, params = params,      dropind = dropind, quadvals = qu| __truncated__\n  .. .. ..$ type       : chr \"bspline\"\n  .. .. ..$ rangeval   : num [1:2] 1 8761\n  .. .. ..$ nbasis     : num 91\n  .. .. ..$ params     : num [1:87] 101 200 300 399 499 ...\n  .. .. ..$ dropind    : NULL\n  .. .. ..$ quadvals   : NULL\n  .. .. ..$ values     : list()\n  .. .. ..$ basisvalues: list()\n  .. .. ..$ names      : chr [1:91] \"bspl4.1\" \"bspl4.2\" \"bspl4.3\" \"bspl4.4\" ...\n  .. .. ..- attr(*, \"class\")= chr \"basisfd\"\n  .. ..$ fdnames:List of 3\n  .. .. ..$ time  : chr [1:8761] \"1\" \"2\" \"3\" \"4\" ...\n  .. .. ..$ reps  : chr [1:10] \"Bosque\" \"IDRD\" \"Carvajal_Sony\" \"Guaymaral\" ...\n  .. .. ..$ values: chr \"value\"\n  .. ..- attr(*, \"class\")= chr \"fd\"\n  ..$ fpca         :List of 5\n  .. ..$ harmonics:List of 3\n  .. .. ..$ coefs  : num [1:91, 1:2] 0.006843 0.006646 0.013123 0.000889 0.005331 ...\n  .. .. .. ..- attr(*, \"dimnames\")=List of 2\n  .. .. .. .. ..$ : chr [1:91] \"bspl4.1\" \"bspl4.2\" \"bspl4.3\" \"bspl4.4\" ...\n  .. .. .. .. ..$ : chr [1:2] \"PC1\" \"PC2\"\n  .. .. ..$ basis  :List of 10\n  .. .. .. ..$ call       : language basisfd(type = type, rangeval = rangeval, nbasis = nbasis, params = params,      dropind = dropind, quadvals = qu| __truncated__\n  .. .. .. ..$ type       : chr \"bspline\"\n  .. .. .. ..$ rangeval   : num [1:2] 1 8761\n  .. .. .. ..$ nbasis     : num 91\n  .. .. .. ..$ params     : num [1:87] 101 200 300 399 499 ...\n  .. .. .. ..$ dropind    : NULL\n  .. .. .. ..$ quadvals   : NULL\n  .. .. .. ..$ values     : list()\n  .. .. .. ..$ basisvalues: list()\n  .. .. .. ..$ names      : chr [1:91] \"bspl4.1\" \"bspl4.2\" \"bspl4.3\" \"bspl4.4\" ...\n  .. .. .. ..- attr(*, \"class\")= chr \"basisfd\"\n  .. .. ..$ fdnames:List of 3\n  .. .. .. ..$ : chr [1:91] \"bspl4.1\" \"bspl4.2\" \"bspl4.3\" \"bspl4.4\" ...\n  .. .. .. ..$ : chr [1:2] \"PC1\" \"PC2\"\n  .. .. .. ..$ : chr \"values\"\n  .. .. ..- attr(*, \"class\")= chr \"fd\"\n  .. ..$ values   : num [1:91] 2634394 107330 53673 42406 38477 ...\n  .. ..$ scores   : num [1:10, 1:2] -1448 -1888 3430 112 515 ...\n  .. ..$ varprop  : num [1:2] 0.9006 0.0367\n  .. ..$ meanfd   :List of 3\n  .. .. ..$ coefs  : num [1:91, 1] 28.1 47 43.8 40.4 34.9 ...\n  .. .. .. ..- attr(*, \"dimnames\")=List of 2\n  .. .. .. .. ..$ : NULL\n  .. .. .. .. ..$ : chr \"mean\"\n  .. .. ..$ basis  :List of 10\n  .. .. .. ..$ call       : language basisfd(type = type, rangeval = rangeval, nbasis = nbasis, params = params,      dropind = dropind, quadvals = qu| __truncated__\n  .. .. .. ..$ type       : chr \"bspline\"\n  .. .. .. ..$ rangeval   : num [1:2] 1 8761\n  .. .. .. ..$ nbasis     : num 91\n  .. .. .. ..$ params     : num [1:87] 101 200 300 399 499 ...\n  .. .. .. ..$ dropind    : NULL\n  .. .. .. ..$ quadvals   : NULL\n  .. .. .. ..$ values     : list()\n  .. .. .. ..$ basisvalues: list()\n  .. .. .. ..$ names      : chr [1:91] \"bspl4.1\" \"bspl4.2\" \"bspl4.3\" \"bspl4.4\" ...\n  .. .. .. ..- attr(*, \"class\")= chr \"basisfd\"\n  .. .. ..$ fdnames:List of 3\n  .. .. .. ..$ time  : chr [1:8761] \"1\" \"2\" \"3\" \"4\" ...\n  .. .. .. ..$ reps  : chr \"mean\"\n  .. .. .. ..$ values: chr \"mean value\"\n  .. .. ..- attr(*, \"class\")= chr \"fd\"\n  .. ..- attr(*, \"class\")= chr \"pca.fd\"\n  ..$ variable_name: chr \"PM10\"\n  ..$ call_args    :List of 9\n  .. ..$ data   :'data.frame':  8761 obs. of  10 variables:\n  .. .. ..$ Bosque       : int [1:8761] 29 32 32 24 29 31 24 26 25 36 ...\n  .. .. ..$ IDRD         : int [1:8761] 53 48 25 36 17 7 9 12 12 13 ...\n  .. .. ..$ Carvajal_Sony: int [1:8761] 72 69 61 30 42 44 30 39 53 49 ...\n  .. .. ..$ Guaymaral    : int [1:8761] 74 55 58 51 41 39 46 60 54 41 ...\n  .. .. ..$ Suba_Corpas  : int [1:8761] 53 52 45 45 38 40 44 67 51 41 ...\n  .. .. ..$ Fontibon     : int [1:8761] 65 49 35 40 26 23 21 29 32 30 ...\n  .. .. ..$ PteAranda    : int [1:8761] 91 70 45 43 33 11 15 28 24 31 ...\n  .. .. ..$ MAVDT        : int [1:8761] 31 32 32 29 21 21 25 29 26 32 ...\n  .. .. ..$ Kennedy      : int [1:8761] 135 94 68 53 47 45 49 59 62 71 ...\n  .. .. ..$ Tunal        : int [1:8761] 38 29 18 17 24 24 19 15 20 35 ...\n  .. ..$ coords :'data.frame':  10 obs. of  2 variables:\n  .. .. ..$ X: num [1:10] 105076 99661 92104 103675 98239 ...\n  .. .. ..$ Y: num [1:10] 112526 106572 99968 120780 118365 ...\n  .. ..$ basis  : chr \"Bsplines\"\n  .. ..$ nbasis : num 91\n  .. ..$ lambda : num 2e-05\n  .. ..$ nharm  : num 2\n  .. ..$ name   : NULL\n  .. ..$ add    : NULL\n  .. ..$ basisfd:List of 10\n  .. .. ..$ call       : language basisfd(type = type, rangeval = rangeval, nbasis = nbasis, params = params,      dropind = dropind, quadvals = qu| __truncated__\n  .. .. ..$ type       : chr \"bspline\"\n  .. .. ..$ rangeval   : num [1:2] 1 8761\n  .. .. ..$ nbasis     : num 91\n  .. .. ..$ params     : num [1:87] 101 200 300 399 499 ...\n  .. .. ..$ dropind    : NULL\n  .. .. ..$ quadvals   : NULL\n  .. .. ..$ values     : list()\n  .. .. ..$ basisvalues: list()\n  .. .. ..$ names      : chr [1:91] \"bspl4.1\" \"bspl4.2\" \"bspl4.3\" \"bspl4.4\" ...\n  .. .. ..- attr(*, \"class\")= chr \"basisfd\"\n - attr(*, \"class\")= chr \"SpatFD\"\n\n\nPara cada variable incluida en el objeto SpatFD, la función summary retorna:\n\nHead of data: Primeras filas de los datos asociados.\nCoordinates: Coordenadas espaciales correspondientes a cada ubicación.\nEigenvalues: Valores propios de la descomposición en componentes principales.\nMean coefficients: Coeficientes medios de la representación funcional.\nProportion of explained variance by each component: Proporción de varianza explicada por cada componente principal.\n\n\nsummary(SFD_PM10)\n\n#  PM10 \n## Data \n     Bosque IDRD Carvajal_Sony Guaymaral Suba_Corpas Fontibon PteAranda MAVDT\n1        29   53            72        74          53       65        91    31\n2        32   48            69        55          52       49        70    32\n3        32   25            61        58          45       35        45    32\n4        24   36            30        51          45       40        43    29\n5       ...  ...           ...       ...         ...      ...       ...   ...\n8758     50   88            99        27          41       66        56    61\n8759     40   73            99        27          43       36        71    43\n8760     52   37            84        92          57       39        58    44\n8761     46   45            87        65          60       49        38    40\n     Kennedy Tunal\n1        135    38\n2         94    29\n3         68    18\n4         53    17\n5        ...   ...\n8758      64    39\n8759      76    32\n8760      75    48\n8761      79    17\n\n ## Coordinates \n           X          Y\n1 105075.655 112526.216\n2 99661.2289 106572.463\n3 92103.6962 99967.8739\n4 103675.229 120779.813\n5        ...        ...\n\n ## Eigenvalues \n                ev\n1 2634394.04728212\n2 107329.989552922\n3 53673.3376594282\n4 42406.3364006517\n5              ...\n\n ## Mean coefficients \n               mean\n1  28.1142060830838\n2  46.9632482975211\n3  43.8359915678551\n4  40.4199430064293\n5               ...\n88 68.0581607089687\n89 65.8120473593034\n90 20.2318977856245\n91 74.2871948785061\n\n ## Proportion of explained variance by component \n     varprop\n1 0.90063221\n2 0.03669339",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Objetos </span>",
      "<span style='color: #728387 !important;'>SpatFD</span>"
    ]
  },
  {
    "objectID": "8.html",
    "href": "8.html",
    "title": "gfdata",
    "section": "",
    "text": "gfdata",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Objetos </span>",
      "<span style='color: #728387 !important;'>gfdata </span>"
    ]
  },
  {
    "objectID": "8.html#descripción",
    "href": "8.html#descripción",
    "title": "gfdata",
    "section": "Descripción",
    "text": "Descripción\nLos objetos de clase gfdata son una extensión de los objetos SpatFD para mediciones repetidas, combinan coordenadas espaciales con funciones o series temporales observadas en cada ubicación espacial. Aunque el término “serie temporal” es genérico, las observaciones también pueden estar distribuidas según la frecuencia, profundidad u otra dimensión espacial, en lugar de tiempo.",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Objetos </span>",
      "<span style='color: #728387 !important;'>gfdata </span>"
    ]
  },
  {
    "objectID": "8.html#argumentos",
    "href": "8.html#argumentos",
    "title": "gfdata",
    "section": "Argumentos",
    "text": "Argumentos\n\ndata: Matriz que contiene los datos, donde cada columna corresponde a un sujeto, y las filas representan una secuencia de puntos de datos (ordenados según el tiempo, frecuencia, profundidad, etc.). La última columna debe incluir las clases para clasificación.\np: Número de repeticiones para cada clase.\nbasis: Tipo de funciones base a utilizar. Puede ser “Fourier” o “Bsplines” (predeterminado es “Bsplines”).\ncoords: Matriz con las coordenadas espaciales (x, y).\nnbasis: Número de funciones base.\nnames: Nombres de las clases de datos.\nlambda: Valor del parámetro de suavizado.",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Objetos </span>",
      "<span style='color: #728387 !important;'>gfdata </span>"
    ]
  },
  {
    "objectID": "8.html#detalles",
    "href": "8.html#detalles",
    "title": "gfdata",
    "section": "Detalles",
    "text": "Detalles\nLos objetos de clase gfdata almacenan los datos funcionales, sus parámetros, los resultados del análisis de componentes principales funcionales (PCA funcional), y las coordenadas espaciales para cada variable. Cada variable tiene su propio conjunto de datos funcionales, data.frame o matriz, y su correspondiente archivo de coordenadas espaciales.\n\nlibrary(SpatFD)\n\ndata(vowels)\n\n# Definir parámetros y nombres para los datos\np = 228\nnelec = 21\nnvow = 5\nnames_vowels = c(\"a\", \"e\", \"i\", \"o\", \"u\")\nn.basis = c(14, 13, 12, 13, 11)\n\n# Crear el objeto gfdata\ns4.gfdata = gfdata(data = vowels, p = p, names = names_vowels, coords = vowels_coords, nbasis = n.basis)",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Objetos </span>",
      "<span style='color: #728387 !important;'>gfdata </span>"
    ]
  },
  {
    "objectID": "8.html#summary",
    "href": "8.html#summary",
    "title": "gfdata",
    "section": "Summary",
    "text": "Summary\nPara cada variable incluida en el objeto gfdata, esta función devuelve:\n\nHead of data: Muestra las primeras filas de los datos funcionales.\nCoordinates: Muestra las coordenadas espaciales asociadas a las observaciones.\nEigenvalues: Valores propios obtenidos del análisis de componentes principales.\nMean coefficients: Coeficientes medios de las funciones base.\nProportion of explained variance by each component: Proporción de la varianza explicada por cada componente principal.\n\n\n#summary.gfdata(s4.gfdata)",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Objetos </span>",
      "<span style='color: #728387 !important;'>gfdata </span>"
    ]
  },
  {
    "objectID": "9.html",
    "href": "9.html",
    "title": "AirQualityBogota",
    "section": "",
    "text": "AirQualityBogota",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Datasets </span>",
      "<span style='color: #728387 !important;'>AirQualityBogota</span>"
    ]
  },
  {
    "objectID": "9.html#descripción",
    "href": "9.html#descripción",
    "title": "AirQualityBogota",
    "section": "Descripción",
    "text": "Descripción\nEl conjunto de datos AirQualityBogota contiene información sobre la calidad del aire en Bogotá, Colombia. Específicamente, incluye mediciones de material particulado 10 (PM10) recolectadas en 10 estaciones de monitoreo distribuidas por la ciudad. Al cargar los datos encontrará en el ambiente\n\ncoord: Un DataFrame con los nombres y coordenadas de cada una de las estaciones de monitoreo.\nmap: Un objeto del tipo sf que contiene el mapa de Bogotá.\nPM10: Contiene las observaciones de PM10 de cada estación.",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Datasets </span>",
      "<span style='color: #728387 !important;'>AirQualityBogota</span>"
    ]
  },
  {
    "objectID": "9.html#qué-es-el-pm10",
    "href": "9.html#qué-es-el-pm10",
    "title": "AirQualityBogota",
    "section": "¿Qué es el PM10?",
    "text": "¿Qué es el PM10?\nEl PM10 se refiere a partículas de materia en el aire con un diámetro de 10 micrómetros o menos. Estas partículas son lo suficientemente pequeñas como para ser inhaladas y pueden tener efectos negativos en la salud humana, especialmente en los sistemas respiratorio y cardiovascular.",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Datasets </span>",
      "<span style='color: #728387 !important;'>AirQualityBogota</span>"
    ]
  },
  {
    "objectID": "9.html#uso",
    "href": "9.html#uso",
    "title": "AirQualityBogota",
    "section": "Uso",
    "text": "Uso\nPara cargar los datos en R, usa el siguiente comando:\n\nlibrary(sf)\n\nWarning: package 'sf' was built under R version 4.4.3\n\n\nLinking to GEOS 3.13.0, GDAL 3.10.1, PROJ 9.5.1; sf_use_s2() is TRUE\n\nlibrary(SpatFD)\ndata(AirQualityBogota)\n\n\nstr(coord)\n\n'data.frame':   10 obs. of  3 variables:\n $ ESTACION: chr  \"Bsq\" \"IDRD\" \"Sony\" \"EscIng\" ...\n $ X       : num  105076 99661 92104 103675 98239 ...\n $ Y       : num  112526 106572 99968 120780 118365 ...\n\n\n\nstr(PM10)\n\n'data.frame':   8761 obs. of  10 variables:\n $ Bosque       : int  29 32 32 24 29 31 24 26 25 36 ...\n $ IDRD         : int  53 48 25 36 17 7 9 12 12 13 ...\n $ Carvajal_Sony: int  72 69 61 30 42 44 30 39 53 49 ...\n $ Guaymaral    : int  74 55 58 51 41 39 46 60 54 41 ...\n $ Suba_Corpas  : int  53 52 45 45 38 40 44 67 51 41 ...\n $ Fontibon     : int  65 49 35 40 26 23 21 29 32 30 ...\n $ PteAranda    : int  91 70 45 43 33 11 15 28 24 31 ...\n $ MAVDT        : int  31 32 32 29 21 21 25 29 26 32 ...\n $ Kennedy      : int  135 94 68 53 47 45 49 59 62 71 ...\n $ Tunal        : int  38 29 18 17 24 24 19 15 20 35 ...\n\n\n\nplot(map$geometry)",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Datasets </span>",
      "<span style='color: #728387 !important;'>AirQualityBogota</span>"
    ]
  },
  {
    "objectID": "10.html",
    "href": "10.html",
    "title": "Vowels",
    "section": "",
    "text": "Vowels",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Datasets </span>",
      "<span style='color: #728387 !important;'>Vowels</span>"
    ]
  },
  {
    "objectID": "10.html#descripción",
    "href": "10.html#descripción",
    "title": "Vowels",
    "section": "Descripción",
    "text": "Descripción\nEl conjunto de datos vowels contiene señales de electroencefalograma (EEG) tomadas de 21 electrodos, durante la actividad mental de imaginar las cinco vocales del idioma español. Este conjunto de datos se desarrolló para ser aplicado en una interfaz cerebro-computadora (BCI, por sus siglas en inglés) destinada al control de una prótesis de mano.",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Datasets </span>",
      "<span style='color: #728387 !important;'>Vowels</span>"
    ]
  },
  {
    "objectID": "10.html#qué-es-una-interfaz-cerebro-computadora-bci",
    "href": "10.html#qué-es-una-interfaz-cerebro-computadora-bci",
    "title": "Vowels",
    "section": "¿Qué es una interfaz cerebro-computadora (BCI)?",
    "text": "¿Qué es una interfaz cerebro-computadora (BCI)?\nUna BCI permite a las personas controlar dispositivos externos, como prótesis, usando únicamente señales cerebrales. En este caso, el conjunto de datos recoge la actividad cerebral relacionada con el pensamiento imaginario de las vocales, lo que se espera que ayude a entrenar modelos para la clasificación y control de una prótesis.\n\n\n\nBrain BCI, Adindva1, CC BY-SA 4.0",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Datasets </span>",
      "<span style='color: #728387 !important;'>Vowels</span>"
    ]
  },
  {
    "objectID": "10.html#uso",
    "href": "10.html#uso",
    "title": "Vowels",
    "section": "USO",
    "text": "USO\nPara cargar los datos en R, usa el siguiente comando:\n\ndata(\"vowels\")\n\nWarning in data(\"vowels\"): data set 'vowels' not found",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Datasets </span>",
      "<span style='color: #728387 !important;'>Vowels</span>"
    ]
  },
  {
    "objectID": "11.html",
    "href": "11.html",
    "title": "Mex PM10",
    "section": "",
    "text": "Mex PM10",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Datasets </span>",
      "<span style='color: #728387 !important;'>CokMexico</span>"
    ]
  },
  {
    "objectID": "11.html#descripción",
    "href": "11.html#descripción",
    "title": "Mex PM10",
    "section": "Descripción",
    "text": "Descripción\nEl conjunto de datos COKMexico contiene información sobre la calidad del aire en 13 ubicaciones de México. Específicamente, incluye mediciones de material particulado 10 (PM10) y N02 recolectadas en 13 estaciones de monitoreo distribuidas por el país. Al cargar los datos encontrará en el ambiente.\n\ncoord_NO2: Un DataFrame con las coordenadas de cada una de las estaciones de monitoreo donde se midió el NO2.\ncoord_PM10 Un DataFrame con las coordenadas de cada una de las estaciones de monitoreo donde se midió el PM10.\nmap_mex: Un objeto del tipo sf que contiene el mapa de Bogotá.\nMex_PM10: Contiene las observaciones de PM10 de cada estación.\nNO2: Contiene las observaciones de NO2 de cada estación.",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Datasets </span>",
      "<span style='color: #728387 !important;'>CokMexico</span>"
    ]
  },
  {
    "objectID": "11.html#qué-es-el-pm10",
    "href": "11.html#qué-es-el-pm10",
    "title": "Mex PM10",
    "section": "¿Qué es el PM10?",
    "text": "¿Qué es el PM10?\nEl PM10 se refiere a partículas de materia en el aire con un diámetro de 10 micrómetros o menos. Estas partículas son lo suficientemente pequeñas como para ser inhaladas y pueden tener efectos negativos en la salud humana, especialmente en los sistemas respiratorio y cardiovascular.",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Datasets </span>",
      "<span style='color: #728387 !important;'>CokMexico</span>"
    ]
  },
  {
    "objectID": "11.html#qué-es-el-no2",
    "href": "11.html#qué-es-el-no2",
    "title": "Mex PM10",
    "section": "¿Qué es el NO2?",
    "text": "¿Qué es el NO2?\nEl dióxido de nitrógeno NO2 es un contaminante del aire que se forma como subproducto en los procesos de combustión a altas temperaturas. Suele ser un contaminante común sobretodo en zonas urbanas.",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Datasets </span>",
      "<span style='color: #728387 !important;'>CokMexico</span>"
    ]
  },
  {
    "objectID": "11.html#uso",
    "href": "11.html#uso",
    "title": "Mex PM10",
    "section": "Uso",
    "text": "Uso\nPara cargar los datos en R, usa el siguiente comando:\n\nLinking to GEOS 3.12.2, GDAL 3.9.3, PROJ 9.4.1; sf_use_s2() is TRUE\n\n\nlibrary(sf)\n\nWarning: package 'sf' was built under R version 4.4.3\n\n\nLinking to GEOS 3.13.0, GDAL 3.10.1, PROJ 9.5.1; sf_use_s2() is TRUE\n\nlibrary(SpatFD)\n\n\ndata(\"COKMexico\")\n\n\nstr(coord_NO2)\n\n'data.frame':   18 obs. of  2 variables:\n $ X: num  509226 473346 482180 469366 479189 ...\n $ Y: num  2171149 2164689 2152665 2141275 2180751 ...\n\n\n\nstr(coord_PM10)\n\n'data.frame':   13 obs. of  2 variables:\n $ X: num  509226 479189 474444 484020 487445 ...\n $ Y: num  2171149 2180751 2154232 2146380 2147815 ...\n\n\n\nstr(Mex_PM10)\n\n int [1:4344, 1:13] 84 110 140 131 151 181 147 139 118 74 ...\n - attr(*, \"dimnames\")=List of 2\n  ..$ : chr [1:4344] \"1\" \"2\" \"3\" \"4\" ...\n  ..$ : chr [1:13] \"ACO\" \"CUT\" \"FAC\" \"HGM\" ...\n\n\n\nstr(Mex_PM10)\n\n int [1:4344, 1:13] 84 110 140 131 151 181 147 139 118 74 ...\n - attr(*, \"dimnames\")=List of 2\n  ..$ : chr [1:4344] \"1\" \"2\" \"3\" \"4\" ...\n  ..$ : chr [1:13] \"ACO\" \"CUT\" \"FAC\" \"HGM\" ...\n\n\n\nstr(NO2)\n\n int [1:4292, 1:18] 21 21 21 18 16 12 12 10 9 10 ...\n - attr(*, \"dimnames\")=List of 2\n  ..$ : chr [1:4292] \"1\" \"2\" \"3\" \"4\" ...\n  ..$ : chr [1:18] \"ACO\" \"ATI\" \"CAM\" \"CUA\" ...\n\n\n\nplot(map_mex)",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Datasets </span>",
      "<span style='color: #728387 !important;'>CokMexico</span>"
    ]
  },
  {
    "objectID": "12.html",
    "href": "12.html",
    "title": "Definición",
    "section": "",
    "text": "Kriging",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Kriging</span>",
      "Teoría de Kriging"
    ]
  },
  {
    "objectID": "12.html#definición",
    "href": "12.html#definición",
    "title": "Definición",
    "section": "Definición",
    "text": "Definición\nEl Kriging es un método de interpolación basado en la teoría de procesos estocástocos que permite estimar los valores que toma una variable en lugares no muestreados a partir de la suposición de que las ubicaciones están correlacionadas espacialmente.",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Kriging</span>",
      "Teoría de Kriging"
    ]
  },
  {
    "objectID": "12.html#kriging-ordinario",
    "href": "12.html#kriging-ordinario",
    "title": "Definición",
    "section": "Kriging Ordinario",
    "text": "Kriging Ordinario\nDado un conjunto de observaciones en diferentes localizaciones \\(s_1, s_2, ...,s_n\\) busca predecir el valor de la variable de interés en una nueva ubicación \\(s_0\\) como una combinación ponderada de las observaciones:\n\\[\n\\hat{Z}(s_0) = \\sum_{i=1}^{n} \\lambda_i Z(s_i)\n\\]\nDonde \\(\\lambda_i\\) son los pesos asignados a cada observación, determinados en función de la covarianza espacial entre \\(s_0\\) y \\(s_i\\) determinado por un variograma.",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Kriging</span>",
      "Teoría de Kriging"
    ]
  },
  {
    "objectID": "12.html#kriging-funcional",
    "href": "12.html#kriging-funcional",
    "title": "Definición",
    "section": "Kriging Funcional",
    "text": "Kriging Funcional\nEn el contexto funcional, las observaciones en cada ubicación espacial no son valores discretos sino funciones completas. Supongamos que tenemos un conjunto de funciones \\(X(s_1, t), X(s_2, t), \\cdots, X(s_n, t)\\) donde cada \\(X(s_i, t)\\) es una función que describe el comportamiento de la variable de interés a lo largo de un dominio continuo \\(t\\) (como el tiempo).\nEl kriging funcional extiende la idea del kriging clásico al predecir una función en una nueva ubicación \\(s_0\\) utilizando una combinación ponderada de las funciones observadas en las localizaciones \\(s_1, \\cdots, s_n\\). En ese orden de ideas, podemos formular el kriging funcional de la siguiente manera:\n\\[\\hat{X}(s_0, t) = \\sum_{i=1}^{n} \\lambda_i(t) X(s_i, t)\\] Donde \\(\\lambda_i\\) son las funciones de peso que dependen de la localización y del dominio funcional \\(t\\). Estas funciones de peso se determinan resolviendo un sistema de ecuaciones basado en la covariancia entre las funciones observadas y la función a predecir.\nCon el paquete SpatFD podemos crear un objeto SpatFD y definir los modelos de semivariogramas que vamos a emplear en el kriging. En este caso usaremos los datos AirQualityBogota y ajustaremos tres semivariogramas, uno wave, uno Mattern y por último un exponencial, la ubicación que queremos predecir se define en la variable newcoorden.\n\nlibrary(SpatFD)\nlibrary(gstat)\n\ndata(AirQualityBogota)\n\n#s_0 nonsampled location. It could be data.frame or matrix and one or more locations of interest\nnewcoorden &lt;- data.frame(\n              X = seq(93000, 105000, length.out = 100),\n              Y = seq(97000, 112000, length.out = 100))\n\n# Building the SpatFD object\n\ncoords_muestras &lt;- coord[, -1]  \n\nSFD_PM10 &lt;- SpatFD(\n  PM10,                     \n  coords = coords_muestras, \n  basis = \"Bsplines\",\n  nbasis = 17,\n  norder = 5,\n  lambda = 0.00002,\n  nharm = 3\n)\n\n# Semivariogram models for each spatial random field of scores\nmodelos &lt;- list(  vgm(psill = 2199288.58, model = \"Sph\", range = 1484.57, nugget = 0),\n                  vgm(psill = 62640.74, model = \"Mat\", range = 1979.43, nugget = 0, kappa = 0.68),\n                  vgm(psill = 37098.25, model = \"Exp\", range = 6433.16, nugget = 0))\n\nExisten dos enfoques diferentes para realizar el kriging funcional, el método de scores y el método lambda.",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Kriging</span>",
      "Teoría de Kriging"
    ]
  },
  {
    "objectID": "12.html#método-de-scores",
    "href": "12.html#método-de-scores",
    "title": "Definición",
    "section": "Método de Scores",
    "text": "Método de Scores\nEn el método de scores, el análisis funcional se basa en una descomposición de las funciones observadas en un conjunto de componentes principales, generalmente a través de una descomposición en funciones base (como la descomposición en funciones ortogonales o en series de Fourier). Este método se descompone en dos etapas:\n\nDescomposición funcional: Se aplica una descomposición funcional de las observaciones para representar cada función como una combinación de componentes principales (bases funcionales) y sus correspondientes coeficientes o “scores”. Si las funciones \\(X(s_i,t)\\) observadas se pueden representar como:\n\\[\nX(s_{i}, t) = \\sum_{k=1}^{K} \\alpha_{ik}\\phi_{k}(t)\n\\]\ndonde \\(\\phi_{k}(t)\\) son las bases funcionales y \\(\\alpha_{ik}\\) son los scores de las componentes principales para cada localización \\(s_{i}\\). En lugar de predecir la función completa, este método se centra en predecir los scores en la ubicación no observada \\(s_{0}\\).\nPredicción de una nueva ubicación: El kriging se aplica sobre los scores obtenidos. Se predicen los scores de la nueva ubicación \\(s_{0}\\) para construir la función predicha \\(\\hat{X}(s_{0}, t)\\) como una combinación de las bases funcionales ponderadas por los scores predichos:\n\\[\\hat{X}(s_{0}, t) = \\sum_{k=1}^{K} \\alpha_{0k}\\phi_{k}(t)\\]\nLa función KS_scores_lambdas permite realizar el kriging usando este método al usar ``scores’’ en la opción method.\n\nKS_SFD_PM10_sc &lt;- KS_scores_lambdas(SFD_PM10, newcoorden, method = \"scores\", model = modelos)\n\nUsing first variable by default\n\n\nUsing fill.all = TRUE by default\n\n\n[using simple kriging]\n[using simple kriging]\n[using simple kriging]",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Kriging</span>",
      "Teoría de Kriging"
    ]
  },
  {
    "objectID": "12.html#método-lambda",
    "href": "12.html#método-lambda",
    "title": "Definición",
    "section": "Método Lambda",
    "text": "Método Lambda\nEste método utiliza una combinación de las funciones observadas, ponderadas por ciertos coeficientes o pesos, para estimar la función en la nueva ubicación, es decir, el kriging se lleva a cabo directamente sobre las funciones. El predictor \\(\\check{\\chi}_{s_{0}}(t)\\) está dado por:\n\\[\\check{\\chi}_{s_{0}}(t) = \\sum_{i=1}^{n} \\lambda_{i}\\chi_{s_{i}}(t)\\]\nDeben encontrarse los pesos \\(\\lambda_{i}\\) que minimicen la diferencia entre la verdadera función en la ubicación no observada \\(s_{0}\\) y el predictor. Eso se expresa matemáticamente como:\n\\[min\\|\\chi_{s_{0}}(t) - \\check{\\chi}_{s_{0}}(t)\\|^2\\]\ndonde \\(\\chi_{s_{0}}(t)\\) es la verdadera función en la ubicación \\(s_{0}\\). La minimización de esta expresión se realiza en el sentido de la norma \\(L^{2}\\).\nLa función KS_scores_lambdas permite realizar el kriging usando este método al usar ‘’lambda’’ en la opción method.\n\nKS_SFD_PM10_both &lt;- KS_scores_lambdas(SFD_PM10, newcoorden, method = \"both\", model = modelos)\n\nUsing first variable by default\n\n\nUsing fill.all = TRUE by default\n\n\n[using simple kriging]\n[using simple kriging]\n[using simple kriging]",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Kriging</span>",
      "Teoría de Kriging"
    ]
  },
  {
    "objectID": "12.html#gráficamente",
    "href": "12.html#gráficamente",
    "title": "Definición",
    "section": "Gráficamente",
    "text": "Gráficamente\nPodemos graficar las predicciones usando la función ggplot_KS\n\nggplot_KS(KS_SFD_PM10_both,show.varpred = FALSE,\n         main = \"Plot 1 - Using Scores\",\n          main2 = \"Plot 2 - Using Lambda\",\n           ylab = \"PM10\")\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\nAsí mismo, podemos graficar las predicciones suavizadas en tiempos específicos.\n\np&lt;-ggmap_KS(KS_SFD_PM10_both,\n         map_path = map,\n         window_time = c(2108),\n         method = \"lambda\",\n         zmin = 50)\n\nUsing fill.all = TRUE by default\n\nprint(p)\n\n[[1]]",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Kriging</span>",
      "Teoría de Kriging"
    ]
  },
  {
    "objectID": "10-Ilustración del kriging simple espacio tiempo.html",
    "href": "10-Ilustración del kriging simple espacio tiempo.html",
    "title": "Ilustración del Kriging",
    "section": "",
    "text": "Simulación no condicional de una realización de un campo aleatorio espacio temporal no separable usando el modelo de covarianza cressie1\nEn primer lugar, se generar la grilla espacio temporal. Aquí suponemos n=6 ubicaciones espaciales y T=4 momentos en el tiempo, así en total son 24 ubicaciones espacio-tiempo. Se llevará a cabo la simulación y posteriormente se usará el predictor kriging con su respectiva estimación de varianza del error de predicción, en un punto no “observado”. Se asume conocida la función de covarianza. En la práctica esta matriz se puede estimar por métodos como maxima veorsimilitud, pseudoverosimilitud y métodos basados en mínimos cuadrados.\nlibrary(mvtnorm)\nx1 &lt;- seq(0,3,len = 3)\nx2 &lt;- seq(1,6,len = 2)\nt &lt;- 1:4\ngrillaSpT=expand.grid(x1,x2,t)\n\n#matriz de distancias (rezagos) espaciales\nmatDistSp=as.matrix(dist(grillaSpT[,1:2]))\n\n#matriz de distancias (rezagos) temporales\nmatDistT=as.matrix(dist(grillaSpT[,3:3]))\ncressie1=function(h,u,p){(p[1]^2/((p[2]^2*u^2+1)))*exp(-(p[3]^2*h^2)/(p[2]^2*u^2+1))}\n\n##parámetros p, mu, que en este caso son p=c(0.4,1.7,1.9) y mu=0\nsigma=cressie1(matDistSp,matDistT,p=c(0.15,1.7,1.9))\nsim1=rmvnorm(1,mean=rep(0,nrow(grillaSpT)), sigma=sigma)\n\ndatos1=cbind(grillaSpT,t(sim1))\n\nnames(datos1)=c(\"x\",\"y\",\"t\",\"z((x,y),t)\")\n\n\nmatDistSp\n\n          1        2        3        4        5        6        7        8\n1  0.000000 1.500000 3.000000 5.000000 5.220153 5.830952 0.000000 1.500000\n2  1.500000 0.000000 1.500000 5.220153 5.000000 5.220153 1.500000 0.000000\n3  3.000000 1.500000 0.000000 5.830952 5.220153 5.000000 3.000000 1.500000\n4  5.000000 5.220153 5.830952 0.000000 1.500000 3.000000 5.000000 5.220153\n5  5.220153 5.000000 5.220153 1.500000 0.000000 1.500000 5.220153 5.000000\n6  5.830952 5.220153 5.000000 3.000000 1.500000 0.000000 5.830952 5.220153\n7  0.000000 1.500000 3.000000 5.000000 5.220153 5.830952 0.000000 1.500000\n8  1.500000 0.000000 1.500000 5.220153 5.000000 5.220153 1.500000 0.000000\n9  3.000000 1.500000 0.000000 5.830952 5.220153 5.000000 3.000000 1.500000\n10 5.000000 5.220153 5.830952 0.000000 1.500000 3.000000 5.000000 5.220153\n11 5.220153 5.000000 5.220153 1.500000 0.000000 1.500000 5.220153 5.000000\n12 5.830952 5.220153 5.000000 3.000000 1.500000 0.000000 5.830952 5.220153\n13 0.000000 1.500000 3.000000 5.000000 5.220153 5.830952 0.000000 1.500000\n14 1.500000 0.000000 1.500000 5.220153 5.000000 5.220153 1.500000 0.000000\n15 3.000000 1.500000 0.000000 5.830952 5.220153 5.000000 3.000000 1.500000\n16 5.000000 5.220153 5.830952 0.000000 1.500000 3.000000 5.000000 5.220153\n17 5.220153 5.000000 5.220153 1.500000 0.000000 1.500000 5.220153 5.000000\n18 5.830952 5.220153 5.000000 3.000000 1.500000 0.000000 5.830952 5.220153\n19 0.000000 1.500000 3.000000 5.000000 5.220153 5.830952 0.000000 1.500000\n20 1.500000 0.000000 1.500000 5.220153 5.000000 5.220153 1.500000 0.000000\n21 3.000000 1.500000 0.000000 5.830952 5.220153 5.000000 3.000000 1.500000\n22 5.000000 5.220153 5.830952 0.000000 1.500000 3.000000 5.000000 5.220153\n23 5.220153 5.000000 5.220153 1.500000 0.000000 1.500000 5.220153 5.000000\n24 5.830952 5.220153 5.000000 3.000000 1.500000 0.000000 5.830952 5.220153\n          9       10       11       12       13       14       15       16\n1  3.000000 5.000000 5.220153 5.830952 0.000000 1.500000 3.000000 5.000000\n2  1.500000 5.220153 5.000000 5.220153 1.500000 0.000000 1.500000 5.220153\n3  0.000000 5.830952 5.220153 5.000000 3.000000 1.500000 0.000000 5.830952\n4  5.830952 0.000000 1.500000 3.000000 5.000000 5.220153 5.830952 0.000000\n5  5.220153 1.500000 0.000000 1.500000 5.220153 5.000000 5.220153 1.500000\n6  5.000000 3.000000 1.500000 0.000000 5.830952 5.220153 5.000000 3.000000\n7  3.000000 5.000000 5.220153 5.830952 0.000000 1.500000 3.000000 5.000000\n8  1.500000 5.220153 5.000000 5.220153 1.500000 0.000000 1.500000 5.220153\n9  0.000000 5.830952 5.220153 5.000000 3.000000 1.500000 0.000000 5.830952\n10 5.830952 0.000000 1.500000 3.000000 5.000000 5.220153 5.830952 0.000000\n11 5.220153 1.500000 0.000000 1.500000 5.220153 5.000000 5.220153 1.500000\n12 5.000000 3.000000 1.500000 0.000000 5.830952 5.220153 5.000000 3.000000\n13 3.000000 5.000000 5.220153 5.830952 0.000000 1.500000 3.000000 5.000000\n14 1.500000 5.220153 5.000000 5.220153 1.500000 0.000000 1.500000 5.220153\n15 0.000000 5.830952 5.220153 5.000000 3.000000 1.500000 0.000000 5.830952\n16 5.830952 0.000000 1.500000 3.000000 5.000000 5.220153 5.830952 0.000000\n17 5.220153 1.500000 0.000000 1.500000 5.220153 5.000000 5.220153 1.500000\n18 5.000000 3.000000 1.500000 0.000000 5.830952 5.220153 5.000000 3.000000\n19 3.000000 5.000000 5.220153 5.830952 0.000000 1.500000 3.000000 5.000000\n20 1.500000 5.220153 5.000000 5.220153 1.500000 0.000000 1.500000 5.220153\n21 0.000000 5.830952 5.220153 5.000000 3.000000 1.500000 0.000000 5.830952\n22 5.830952 0.000000 1.500000 3.000000 5.000000 5.220153 5.830952 0.000000\n23 5.220153 1.500000 0.000000 1.500000 5.220153 5.000000 5.220153 1.500000\n24 5.000000 3.000000 1.500000 0.000000 5.830952 5.220153 5.000000 3.000000\n         17       18       19       20       21       22       23       24\n1  5.220153 5.830952 0.000000 1.500000 3.000000 5.000000 5.220153 5.830952\n2  5.000000 5.220153 1.500000 0.000000 1.500000 5.220153 5.000000 5.220153\n3  5.220153 5.000000 3.000000 1.500000 0.000000 5.830952 5.220153 5.000000\n4  1.500000 3.000000 5.000000 5.220153 5.830952 0.000000 1.500000 3.000000\n5  0.000000 1.500000 5.220153 5.000000 5.220153 1.500000 0.000000 1.500000\n6  1.500000 0.000000 5.830952 5.220153 5.000000 3.000000 1.500000 0.000000\n7  5.220153 5.830952 0.000000 1.500000 3.000000 5.000000 5.220153 5.830952\n8  5.000000 5.220153 1.500000 0.000000 1.500000 5.220153 5.000000 5.220153\n9  5.220153 5.000000 3.000000 1.500000 0.000000 5.830952 5.220153 5.000000\n10 1.500000 3.000000 5.000000 5.220153 5.830952 0.000000 1.500000 3.000000\n11 0.000000 1.500000 5.220153 5.000000 5.220153 1.500000 0.000000 1.500000\n12 1.500000 0.000000 5.830952 5.220153 5.000000 3.000000 1.500000 0.000000\n13 5.220153 5.830952 0.000000 1.500000 3.000000 5.000000 5.220153 5.830952\n14 5.000000 5.220153 1.500000 0.000000 1.500000 5.220153 5.000000 5.220153\n15 5.220153 5.000000 3.000000 1.500000 0.000000 5.830952 5.220153 5.000000\n16 1.500000 3.000000 5.000000 5.220153 5.830952 0.000000 1.500000 3.000000\n17 0.000000 1.500000 5.220153 5.000000 5.220153 1.500000 0.000000 1.500000\n18 1.500000 0.000000 5.830952 5.220153 5.000000 3.000000 1.500000 0.000000\n19 5.220153 5.830952 0.000000 1.500000 3.000000 5.000000 5.220153 5.830952\n20 5.000000 5.220153 1.500000 0.000000 1.500000 5.220153 5.000000 5.220153\n21 5.220153 5.000000 3.000000 1.500000 0.000000 5.830952 5.220153 5.000000\n22 1.500000 3.000000 5.000000 5.220153 5.830952 0.000000 1.500000 3.000000\n23 0.000000 1.500000 5.220153 5.000000 5.220153 1.500000 0.000000 1.500000\n24 1.500000 0.000000 5.830952 5.220153 5.000000 3.000000 1.500000 0.000000\nmatDistT\n\n   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n1  0 0 0 0 0 0 1 1 1  1  1  1  2  2  2  2  2  2  3  3  3  3  3  3\n2  0 0 0 0 0 0 1 1 1  1  1  1  2  2  2  2  2  2  3  3  3  3  3  3\n3  0 0 0 0 0 0 1 1 1  1  1  1  2  2  2  2  2  2  3  3  3  3  3  3\n4  0 0 0 0 0 0 1 1 1  1  1  1  2  2  2  2  2  2  3  3  3  3  3  3\n5  0 0 0 0 0 0 1 1 1  1  1  1  2  2  2  2  2  2  3  3  3  3  3  3\n6  0 0 0 0 0 0 1 1 1  1  1  1  2  2  2  2  2  2  3  3  3  3  3  3\n7  1 1 1 1 1 1 0 0 0  0  0  0  1  1  1  1  1  1  2  2  2  2  2  2\n8  1 1 1 1 1 1 0 0 0  0  0  0  1  1  1  1  1  1  2  2  2  2  2  2\n9  1 1 1 1 1 1 0 0 0  0  0  0  1  1  1  1  1  1  2  2  2  2  2  2\n10 1 1 1 1 1 1 0 0 0  0  0  0  1  1  1  1  1  1  2  2  2  2  2  2\n11 1 1 1 1 1 1 0 0 0  0  0  0  1  1  1  1  1  1  2  2  2  2  2  2\n12 1 1 1 1 1 1 0 0 0  0  0  0  1  1  1  1  1  1  2  2  2  2  2  2\n13 2 2 2 2 2 2 1 1 1  1  1  1  0  0  0  0  0  0  1  1  1  1  1  1\n14 2 2 2 2 2 2 1 1 1  1  1  1  0  0  0  0  0  0  1  1  1  1  1  1\n15 2 2 2 2 2 2 1 1 1  1  1  1  0  0  0  0  0  0  1  1  1  1  1  1\n16 2 2 2 2 2 2 1 1 1  1  1  1  0  0  0  0  0  0  1  1  1  1  1  1\n17 2 2 2 2 2 2 1 1 1  1  1  1  0  0  0  0  0  0  1  1  1  1  1  1\n18 2 2 2 2 2 2 1 1 1  1  1  1  0  0  0  0  0  0  1  1  1  1  1  1\n19 3 3 3 3 3 3 2 2 2  2  2  2  1  1  1  1  1  1  0  0  0  0  0  0\n20 3 3 3 3 3 3 2 2 2  2  2  2  1  1  1  1  1  1  0  0  0  0  0  0\n21 3 3 3 3 3 3 2 2 2  2  2  2  1  1  1  1  1  1  0  0  0  0  0  0\n22 3 3 3 3 3 3 2 2 2  2  2  2  1  1  1  1  1  1  0  0  0  0  0  0\n23 3 3 3 3 3 3 2 2 2  2  2  2  1  1  1  1  1  1  0  0  0  0  0  0\n24 3 3 3 3 3 3 2 2 2  2  2  2  1  1  1  1  1  1  0  0  0  0  0  0\ndatos1\n\n     x y t  z((x,y),t)\n1  0.0 1 1  0.04571672\n2  1.5 1 1 -0.24335367\n3  3.0 1 1  0.11736114\n4  0.0 6 1  0.18814913\n5  1.5 6 1 -0.18338928\n6  3.0 6 1 -0.03459498\n7  0.0 1 2  0.19128162\n8  1.5 1 2 -0.18487095\n9  3.0 1 2 -0.01257342\n10 0.0 6 2 -0.16756013\n11 1.5 6 2 -0.18685937\n12 3.0 6 2 -0.11323965\n13 0.0 1 3  0.32233615\n14 1.5 1 3  0.08587613\n15 3.0 1 3 -0.01704276\n16 0.0 6 3  0.05721675\n17 1.5 6 3 -0.12612673\n18 3.0 6 3  0.06707751\n19 0.0 1 4  0.10034843\n20 1.5 1 4 -0.23829452\n21 3.0 1 4  0.18275276\n22 0.0 6 4  0.22618653\n23 1.5 6 4 -0.02474165\n24 3.0 6 4 -0.02296545\nSe requiere predecir predecir en el tiempo t=2.3 y en el lugar s0=(1.5,2.7).Nótese que tanto el dominio espacial como el dominio temporal con continuos y fijos. A continuación se presenta el procedimiento para llevar a cabo Kriging simple con su respectiva varianza de error de predicción estimada\ngrillaSpT0=rbind(expand.grid(x1,x2,t),c(1.5,2.7,2.3))\nmatDistSp0=as.matrix(dist(grillaSpT0[,1:2]))\nmatDistT0=as.matrix(dist(grillaSpT0[,3:3]))\nsigma0=cressie1(matDistSp0,matDistT0,p=c(0.15,1.7,1.9))\n#vector de covarianzas entre la coordenada a predecir y las observadas\nsigma0\n\n              1            2            3            4            5\n1  2.250000e-02 6.677680e-06 1.745640e-16 1.435838e-41 4.261364e-45\n2  6.677680e-06 2.250000e-02 6.677680e-06 4.261364e-45 1.435838e-41\n3  1.745640e-16 6.677680e-06 2.250000e-02 1.113981e-55 4.261364e-45\n4  1.435838e-41 4.261364e-45 1.113981e-55 2.250000e-02 6.677680e-06\n5  4.261364e-45 1.435838e-41 4.261364e-45 6.677680e-06 2.250000e-02\n6  1.113981e-55 4.261364e-45 1.435838e-41 1.745640e-16 6.677680e-06\n7  5.784062e-03 7.168131e-04 1.364348e-06 4.857107e-13 6.019365e-14\n8  7.168131e-04 5.784062e-03 7.168131e-04 6.019365e-14 4.857107e-13\n9  1.364348e-06 7.168131e-04 5.784062e-03 1.145697e-16 6.019365e-14\n10 4.857107e-13 6.019365e-14 1.145697e-16 5.784062e-03 7.168131e-04\n11 6.019365e-14 4.857107e-13 6.019365e-14 7.168131e-04 5.784062e-03\n12 1.145697e-16 6.019365e-14 4.857107e-13 1.364348e-06 7.168131e-04\n13 1.791401e-03 9.382886e-04 1.348240e-04 1.356956e-06 7.107376e-07\n14 9.382886e-04 1.791401e-03 9.382886e-04 7.107376e-07 1.356956e-06\n15 1.348240e-04 9.382886e-04 1.791401e-03 1.021269e-07 7.107376e-07\n16 1.356956e-06 7.107376e-07 1.021269e-07 1.791401e-03 9.382886e-04\n17 7.107376e-07 1.356956e-06 7.107376e-07 9.382886e-04 1.791401e-03\n18 1.021269e-07 7.107376e-07 1.356956e-06 1.348240e-04 9.382886e-04\n19 8.330248e-04 6.166746e-04 2.501787e-04 2.947989e-05 2.182348e-05\n20 6.166746e-04 8.330248e-04 6.166746e-04 2.182348e-05 2.947989e-05\n21 2.501787e-04 6.166746e-04 8.330248e-04 8.853568e-06 2.182348e-05\n22 2.947989e-05 2.182348e-05 8.853568e-06 8.330248e-04 6.166746e-04\n23 2.182348e-05 2.947989e-05 2.182348e-05 6.166746e-04 8.330248e-04\n24 8.853568e-06 2.182348e-05 2.947989e-05 2.501787e-04 6.166746e-04\n25 1.632912e-04 6.493361e-04 1.632912e-04 1.206101e-06 4.796124e-06\n              6            7            8            9           10\n1  1.113981e-55 5.784062e-03 7.168131e-04 1.364348e-06 4.857107e-13\n2  4.261364e-45 7.168131e-04 5.784062e-03 7.168131e-04 6.019365e-14\n3  1.435838e-41 1.364348e-06 7.168131e-04 5.784062e-03 1.145697e-16\n4  1.745640e-16 4.857107e-13 6.019365e-14 1.145697e-16 5.784062e-03\n5  6.677680e-06 6.019365e-14 4.857107e-13 6.019365e-14 7.168131e-04\n6  2.250000e-02 1.145697e-16 6.019365e-14 4.857107e-13 1.364348e-06\n7  1.145697e-16 2.250000e-02 6.677680e-06 1.745640e-16 1.435838e-41\n8  6.019365e-14 6.677680e-06 2.250000e-02 6.677680e-06 4.261364e-45\n9  4.857107e-13 1.745640e-16 6.677680e-06 2.250000e-02 1.113981e-55\n10 1.364348e-06 1.435838e-41 4.261364e-45 1.113981e-55 2.250000e-02\n11 7.168131e-04 4.261364e-45 1.435838e-41 4.261364e-45 6.677680e-06\n12 5.784062e-03 1.113981e-55 4.261364e-45 1.435838e-41 1.745640e-16\n13 1.021269e-07 5.784062e-03 7.168131e-04 1.364348e-06 4.857107e-13\n14 7.107376e-07 7.168131e-04 5.784062e-03 7.168131e-04 6.019365e-14\n15 1.356956e-06 1.364348e-06 7.168131e-04 5.784062e-03 1.145697e-16\n16 1.348240e-04 4.857107e-13 6.019365e-14 1.145697e-16 5.784062e-03\n17 9.382886e-04 6.019365e-14 4.857107e-13 6.019365e-14 7.168131e-04\n18 1.791401e-03 1.145697e-16 6.019365e-14 4.857107e-13 1.364348e-06\n19 8.853568e-06 1.791401e-03 9.382886e-04 1.348240e-04 1.356956e-06\n20 2.182348e-05 9.382886e-04 1.791401e-03 9.382886e-04 7.107376e-07\n21 2.947989e-05 1.348240e-04 9.382886e-04 1.791401e-03 1.021269e-07\n22 2.501787e-04 1.356956e-06 7.107376e-07 1.021269e-07 1.791401e-03\n23 6.166746e-04 7.107376e-07 1.356956e-06 7.107376e-07 9.382886e-04\n24 8.330248e-04 1.021269e-07 7.107376e-07 1.356956e-06 1.348240e-04\n25 1.206101e-06 7.188593e-09 4.529707e-06 7.188593e-09 8.000712e-19\n             11           12           13           14           15\n1  6.019365e-14 1.145697e-16 1.791401e-03 9.382886e-04 1.348240e-04\n2  4.857107e-13 6.019365e-14 9.382886e-04 1.791401e-03 9.382886e-04\n3  6.019365e-14 4.857107e-13 1.348240e-04 9.382886e-04 1.791401e-03\n4  7.168131e-04 1.364348e-06 1.356956e-06 7.107376e-07 1.021269e-07\n5  5.784062e-03 7.168131e-04 7.107376e-07 1.356956e-06 7.107376e-07\n6  7.168131e-04 5.784062e-03 1.021269e-07 7.107376e-07 1.356956e-06\n7  4.261364e-45 1.113981e-55 5.784062e-03 7.168131e-04 1.364348e-06\n8  1.435838e-41 4.261364e-45 7.168131e-04 5.784062e-03 7.168131e-04\n9  4.261364e-45 1.435838e-41 1.364348e-06 7.168131e-04 5.784062e-03\n10 6.677680e-06 1.745640e-16 4.857107e-13 6.019365e-14 1.145697e-16\n11 2.250000e-02 6.677680e-06 6.019365e-14 4.857107e-13 6.019365e-14\n12 6.677680e-06 2.250000e-02 1.145697e-16 6.019365e-14 4.857107e-13\n13 6.019365e-14 1.145697e-16 2.250000e-02 6.677680e-06 1.745640e-16\n14 4.857107e-13 6.019365e-14 6.677680e-06 2.250000e-02 6.677680e-06\n15 6.019365e-14 4.857107e-13 1.745640e-16 6.677680e-06 2.250000e-02\n16 7.168131e-04 1.364348e-06 1.435838e-41 4.261364e-45 1.113981e-55\n17 5.784062e-03 7.168131e-04 4.261364e-45 1.435838e-41 4.261364e-45\n18 7.168131e-04 5.784062e-03 1.113981e-55 4.261364e-45 1.435838e-41\n19 7.107376e-07 1.021269e-07 5.784062e-03 7.168131e-04 1.364348e-06\n20 1.356956e-06 7.107376e-07 7.168131e-04 5.784062e-03 7.168131e-04\n21 7.107376e-07 1.356956e-06 1.364348e-06 7.168131e-04 5.784062e-03\n22 9.382886e-04 1.348240e-04 4.857107e-13 6.019365e-14 1.145697e-16\n23 1.791401e-03 9.382886e-04 6.019365e-14 4.857107e-13 6.019365e-14\n24 9.382886e-04 1.791401e-03 1.145697e-16 6.019365e-14 4.857107e-13\n25 5.041442e-16 8.000712e-19 4.302596e-06 1.240942e-04 4.302596e-06\n             16           17           18           19           20\n1  1.356956e-06 7.107376e-07 1.021269e-07 8.330248e-04 6.166746e-04\n2  7.107376e-07 1.356956e-06 7.107376e-07 6.166746e-04 8.330248e-04\n3  1.021269e-07 7.107376e-07 1.356956e-06 2.501787e-04 6.166746e-04\n4  1.791401e-03 9.382886e-04 1.348240e-04 2.947989e-05 2.182348e-05\n5  9.382886e-04 1.791401e-03 9.382886e-04 2.182348e-05 2.947989e-05\n6  1.348240e-04 9.382886e-04 1.791401e-03 8.853568e-06 2.182348e-05\n7  4.857107e-13 6.019365e-14 1.145697e-16 1.791401e-03 9.382886e-04\n8  6.019365e-14 4.857107e-13 6.019365e-14 9.382886e-04 1.791401e-03\n9  1.145697e-16 6.019365e-14 4.857107e-13 1.348240e-04 9.382886e-04\n10 5.784062e-03 7.168131e-04 1.364348e-06 1.356956e-06 7.107376e-07\n11 7.168131e-04 5.784062e-03 7.168131e-04 7.107376e-07 1.356956e-06\n12 1.364348e-06 7.168131e-04 5.784062e-03 1.021269e-07 7.107376e-07\n13 1.435838e-41 4.261364e-45 1.113981e-55 5.784062e-03 7.168131e-04\n14 4.261364e-45 1.435838e-41 4.261364e-45 7.168131e-04 5.784062e-03\n15 1.113981e-55 4.261364e-45 1.435838e-41 1.364348e-06 7.168131e-04\n16 2.250000e-02 6.677680e-06 1.745640e-16 4.857107e-13 6.019365e-14\n17 6.677680e-06 2.250000e-02 6.677680e-06 6.019365e-14 4.857107e-13\n18 1.745640e-16 6.677680e-06 2.250000e-02 1.145697e-16 6.019365e-14\n19 4.857107e-13 6.019365e-14 1.145697e-16 2.250000e-02 6.677680e-06\n20 6.019365e-14 4.857107e-13 6.019365e-14 6.677680e-06 2.250000e-02\n21 1.145697e-16 6.019365e-14 4.857107e-13 1.745640e-16 6.677680e-06\n22 5.784062e-03 7.168131e-04 1.364348e-06 1.435838e-41 4.261364e-45\n23 7.168131e-04 5.784062e-03 7.168131e-04 4.261364e-45 1.435838e-41\n24 1.364348e-06 7.168131e-04 5.784062e-03 1.113981e-55 4.261364e-45\n25 2.770413e-11 7.990346e-10 2.770413e-11 3.308220e-04 7.884761e-04\n             21           22           23           24           25\n1  2.501787e-04 2.947989e-05 2.182348e-05 8.853568e-06 1.632912e-04\n2  6.166746e-04 2.182348e-05 2.947989e-05 2.182348e-05 6.493361e-04\n3  8.330248e-04 8.853568e-06 2.182348e-05 2.947989e-05 1.632912e-04\n4  8.853568e-06 8.330248e-04 6.166746e-04 2.501787e-04 1.206101e-06\n5  2.182348e-05 6.166746e-04 8.330248e-04 6.166746e-04 4.796124e-06\n6  2.947989e-05 2.501787e-04 6.166746e-04 8.330248e-04 1.206101e-06\n7  1.348240e-04 1.356956e-06 7.107376e-07 1.021269e-07 7.188593e-09\n8  9.382886e-04 7.107376e-07 1.356956e-06 7.107376e-07 4.529707e-06\n9  1.791401e-03 1.021269e-07 7.107376e-07 1.356956e-06 7.188593e-09\n10 1.021269e-07 1.791401e-03 9.382886e-04 1.348240e-04 8.000712e-19\n11 7.107376e-07 9.382886e-04 1.791401e-03 9.382886e-04 5.041442e-16\n12 1.356956e-06 1.348240e-04 9.382886e-04 1.791401e-03 8.000712e-19\n13 1.364348e-06 4.857107e-13 6.019365e-14 1.145697e-16 4.302596e-06\n14 7.168131e-04 6.019365e-14 4.857107e-13 6.019365e-14 1.240942e-04\n15 5.784062e-03 1.145697e-16 6.019365e-14 4.857107e-13 4.302596e-06\n16 1.145697e-16 5.784062e-03 7.168131e-04 1.364348e-06 2.770413e-11\n17 6.019365e-14 7.168131e-04 5.784062e-03 7.168131e-04 7.990346e-10\n18 4.857107e-13 1.364348e-06 7.168131e-04 5.784062e-03 2.770413e-11\n19 1.745640e-16 1.435838e-41 4.261364e-45 1.113981e-55 3.308220e-04\n20 6.677680e-06 4.261364e-45 1.435838e-41 4.261364e-45 7.884761e-04\n21 2.250000e-02 1.113981e-55 4.261364e-45 1.435838e-41 3.308220e-04\n22 1.113981e-55 2.250000e-02 6.677680e-06 1.745640e-16 1.508203e-05\n23 4.261364e-45 6.677680e-06 2.250000e-02 6.677680e-06 3.594628e-05\n24 1.435838e-41 1.745640e-16 6.677680e-06 2.250000e-02 1.508203e-05\n25 3.308220e-04 1.508203e-05 3.594628e-05 1.508203e-05 2.250000e-02\nlambda=solve(sigma)%*%sigma0[25,-25]\nlambda\n\n            [,1]\n1   7.588729e-03\n2   3.051466e-02\n3   7.588729e-03\n4  -3.276782e-05\n5   1.166265e-04\n6  -3.276782e-05\n7  -4.212887e-03\n8  -1.073644e-02\n9  -4.212887e-03\n10 -5.666790e-05\n11 -9.187561e-05\n12 -5.666790e-05\n13 -5.543596e-03\n14 -4.857869e-03\n15 -5.543596e-03\n16 -2.212264e-04\n17 -4.597041e-04\n18 -2.212264e-04\n19  1.587928e-02\n20  3.629635e-02\n21  1.587928e-02\n22  7.064917e-04\n23  1.685196e-03\n24  7.064917e-04\nz_pred0=t(lambda)%*%datos1[,4]\nz_pred0\n\n            [,1]\n[1,] -0.01108068\nVarErropred0=sigma[1,1]-t(sigma0[25,-25])%*%solve(sigma)%*%sigma0[25,-25]\nVarErropred0\n\n          [,1]\n[1,] 0.0224392",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Kriging</span>",
      "Ilustración del Kriging Simple"
    ]
  },
  {
    "objectID": "10-Ilustración del kriging simple espacio tiempo.html#algunas-funciones-de-covarianza-espacio-temporal-no-separables",
    "href": "10-Ilustración del kriging simple espacio tiempo.html#algunas-funciones-de-covarianza-espacio-temporal-no-separables",
    "title": "Ilustración del Kriging",
    "section": "Algunas funciones de covarianza espacio temporal no separables",
    "text": "Algunas funciones de covarianza espacio temporal no separables\n\n##Funciones de covarianza espacio temporal p vector de parámetros para cada modelo\nexp_esp_temp=function(h,u,p){((p[1])^2)*exp(-h/p[2]-u/p[3])}\ngauss_esp_temp=function(h,u,p){(p[1]^2)*exp(-(h/p[2])^2-(u/p[3])^2)}\ncressie1=function(h,u,p){(p[1]^2/((p[2]^2*u^2+1)))*exp(-(p[3]^2*h^2)/(p[2]^2*u^2+1))}\nGneiting1=function(h,u,p){p[1]^2/((p[2]*u^(2*p[3])+1)^(p[4]))*exp(-(p[6]*h^(2*p[5]))/((p[2]*u^(2*p[3])+1)^(p[4]*p[5])))}\nGneiting2=function(h,u,sigma,p)\n{p[1]^2/((2^(p[3]-1))*p[7](p[3])*(p[2]*u^(2*p[3])+1)^(p[4]+p[5]))*\n(((p[6]*h)/((p[2]*u^(2*p[3])+1)^(p[5]/2)))^p[3])*\nbesselK(((p[6]*h)/((p[2]*u^(2*p[3])+1)^(p[5]/2))),p[3])}\nIaco_Cesare=function(h,u,a,b,c){(1+h^p[1]+u^p[2])^(-p[3])}",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Kriging</span>",
      "Ilustración del Kriging Simple"
    ]
  },
  {
    "objectID": "10-Ilustración del kriging simple espacio tiempo.html#c-r-e-s-s-i-e---h-u-a-n-g-1999",
    "href": "10-Ilustración del kriging simple espacio tiempo.html#c-r-e-s-s-i-e---h-u-a-n-g-1999",
    "title": "Ilustración del Kriging",
    "section": "C R E S S I E - H U A N G (1999)",
    "text": "C R E S S I E - H U A N G (1999)\n\n#sigma:desviacion estandar, a es el parámetros de escala del tiempo, b es el parámetros de escala del espacio, d es la dimensión espacial; a,b positivos\nCH_1=function(h,u,p,d){(p[1]^2/((p[2]^2*u^2+1)^(d/2)))*exp(-(p[3]^2*h^2)/(p[2]^2*u^2+1))}\nCH_2=function(h,u,p,d){(p[1]^2/((p[2]*abs(u)+1)^(d/2)))*exp(-(p[3]^2*h^2)/(p[2]*abs(u)+1))}\nCH_3=function(h,u,p,d){p[1]^2*((p[2]^2)*(u^2)+1)/(((p[2]^2)*(u^2)+1)^2+(p[3]^2)*h^2)^((d+1)/2)}\nCH_4=function(h,u,p,d){p[1]^2*(p[2]*abs(u)+1)/((p[2]*abs(u)+1)^2+(p[3]^2)*h^2)^((d+1)/2)}\n\n#el caso mas general de C R E S S I E - H U A N G (1999) es cuando d=2, entonces queda\nCH_1=function(h,u,p){(p[1]^2/((p[2]^2*u^2+1)))*exp(-(p[3]^2*h^2)/(p[2]^2*u^2+1))}\nCH_2=function(h,u,p){(p[1]^2/((p[2]*abs(u)+1)))*exp(-(p[3]^2*h^2)/(p[2]*abs(u)+1))}\nCH_3=function(h,u,p){p[1]^2*((p[2]^2)*(u^2)+1)/(((p[2]^2)*(u^2)+1)^2+(p[3]^2)*h^2)^((3)/2)}\nCH_4=function(h,u,p){p[1]^2*(p[2]*abs(u)+1)/((p[2]*abs(u)+1)^2+(p[3]^2)*h^2)^((3)/2)}",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Kriging</span>",
      "Ilustración del Kriging Simple"
    ]
  },
  {
    "objectID": "10-Ilustración del kriging simple espacio tiempo.html#gneiting-2002-combina-fun1-fun2-y-psi-en-gneiting",
    "href": "10-Ilustración del kriging simple espacio tiempo.html#gneiting-2002-combina-fun1-fun2-y-psi-en-gneiting",
    "title": "Ilustración del Kriging",
    "section": "Gneiting (2002), combina fun1, fun2 y psi en Gneiting",
    "text": "Gneiting (2002), combina fun1, fun2 y psi en Gneiting\n\n#fun1\nphi1=function(r,c,gama,v){v*exp(-c*r^gama)}                                            #c&gt;0, 0&lt;gama&lt;=1, siempre v=1\nphi2=function(r,c,gama,v){((2^(v-1))*gamma(v))^(-1)*(c*r^0.5)^v*besselK(c*r^0.5,v)}    #c&gt;0, v&gt;0\nphi3=function(r,c,gama,v){(1+c*r^gama)^(-v)}                                           #c&gt;0, 0&lt;gama&lt;=1, v&gt;0\nphi4=function(r,c,gama,v){gama*(2^v)*(exp(c*r^0.5)+exp(-c*r^0.5))^(-v)}                #c&gt;0, v&gt;0, siempre gama=1\n\n#fun2\npsi1=function(r,a,alpha,beta){(a*r^alpha+1)^beta}                                      #a&gt;0, 0&lt;alpha&lt;=1, 0&lt;=beta&lt;=1\npsi2=function(r,a,alpha,beta){log(a*r^alpha+beta)/log(beta)}                           #a&gt;0, beta&gt;1,  0&lt;alpha&lt;=1\npsi3=function(r,a,alpha,beta){(a*r^alpha+beta)/(beta*(a*r^alpha+1))}                   #a&gt;0, 0&lt;beta&lt;=1   0&lt;alpha&lt;=1  \n\n#Cualquier combinación genera una función de covarianza válida\nGneiting=function(h,u,sigma,d,a,alpha,beta,c,gama,v,psi,phi){(sigma^2/(psi((abs(u)^2),a,alpha,beta))^(d/2))*phi(h^2/(psi(abs(u)^2,a,alpha,beta)),c,gama,v)}\n\n#el caso mas general de Gneiting (2002) es cuando d=2, entonces queda\nGneiting=function(h,u,sigma,a,alpha,beta,c,gama,v,psi,phi){(sigma^2/(psi((abs(u)^2),a,alpha,beta)))*phi(h^2/(psi(abs(u)^2,a,alpha,beta)),c,gama,v)}\n\n\n####IACO_CESSARE\nC_IACO_CESSARE=function(h,u,sigma,a,b,alpha,beta,gama){(1 + (h/a)^alpha + (u/b)^beta)^(-gama)}\n\n\n#(Porcu, 2007) Basado en la función de supervivencia de Dagum \n#función de Dagum\nDagum=function(r,lambda,theta,epsilon){1-1/(1+lambda*r^(-theta))^epsilon}                                                                                     #lamdba, theta in (0,7), epsilon in (0,7)\nDagumm=function(r,lambda,theta,epsilon){ifelse(r==0,1,Dagum(r,lambda,theta,epsilon))}\n\nPorcu_sep=function(h,u,lambda_h,theta_h,epsilon_h,lambda_u,theta_u,epsilon_u){Dagumm(h,lambda_h,theta_h,epsilon_h)*Dagumm(u,lambda_u,theta_u,epsilon_u)}      \nPorcu_Nsep=function(h,u,lambda_h,theta_h,epsilon_h,lambda_u,theta_u,epsilon_u,vartheta){vartheta*Dagumm(h,lambda_h,theta_h,epsilon_h)+(1-vartheta)*Dagumm(u,lambda_u,theta_u,epsilon_u)}",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Kriging</span>",
      "Ilustración del Kriging Simple"
    ]
  },
  {
    "objectID": "13.html",
    "href": "13.html",
    "title": "Definición",
    "section": "",
    "text": "Cokriging",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Cokriging</span>",
      "Modelo de Cokriging"
    ]
  },
  {
    "objectID": "13.html#definición",
    "href": "13.html#definición",
    "title": "Definición",
    "section": "Definición",
    "text": "Definición\nEl cokriging es una extensión del kriging que permite predecir una variable en una ubicación no muestreada utilizando no solo datos de esa misma variable, sino también información de otras variables relacionadas o covariables. Este método aprovecha la correlación espacial entre varias variables para mejorar la precisión de las predicciones.\n\nEjemplo\nSupongamos que queremos hacer la predicción tomando en cuenta \\(p\\) variables de forma simultánea. Considerando \\(Z(s_i) = (Z_1(s_i), Z_2(s_i), \\dots, Z_p(s_i))'\\), el predictor para \\(Z_l(s_0), 1 \\le l \\le p\\) basado en \\(p\\), basado en las \\(p\\) variables tiene la forma:\n\\[Z_l^*(s_0) = \\sum_{i=1}^{n} \\sum_{q=1}^{p} \\lambda_{qi} Z_q(s_i)\\]\nEl mejor predictor lineal insesgado de una variable en la ubicación \\(s_0\\) está dado por la minimización de\n\\[max_{1 \\le l \\le n} \\{Var[Z_l(s_0) - Z_l^*(s_0)]\\}\\]\nPor eficiencia computacional, puede decidirse minimizar\n\\[\\sum_{i=1}^{n} Var[Z_l(s_0) - Z_l^*(s_0)]\\]\nEn el paquete SpatFD se realiza cokriging sobre los scores elegidos para todas las variables funcionales involucradas. Las predicciones de scores se utilizan para construir el predictor funcional del cokriging.\n\nlibrary(SpatFD)\n\ndata(COKMexico)\n# Definimos nuestro objeto SpatFD\nSFD_PM10_NO2 &lt;- SpatFD(Mex_PM10, coords = coord_PM10, basis = \"Fourier\", \nnbasis = 21, lambda = 0.000001, nharm = 2)\n# Agregamos las observaciones de NO2 al objeto que creamos antes por medio del argumento add\nSFD_PM10_NO2 &lt;- SpatFD(NO2, coords = coord_NO2, basis = \"Fourier\", \nnbasis = 27, lambda = 0.000001, nharm = 2,\n                      add = SFD_PM10_NO2)\n# Definimos los modelos de varianza de cada una de las variables\nmodel1 &lt;- gstat::vgm(647677.1,\"Gau\",23317.05)\nmodel1 &lt;- gstat::vgm(127633,\"Wav\",9408.63, add.to = model1)\n\n# Especificamos la ubicación no muestreada\nnewcoords &lt;- data.frame(x = 509926, y = 2179149)\n\nLa función COKS_scores_lambdas nos permite hacer el cokriging funcional\n\ncokrig = COKS_scores_lambdas(SFD_PM10_NO2, newcoords, model1)\n\nUsing fill.all = TRUE by default\n\n\nUsing method = 'lambda' by default\n\n\n\n\n\n\n\n\n\nLinear Model of Coregionalization found. Good.\n[using ordinary cokriging]\n\n\n\ncokrig$modelfit\n\ndata:\nPC1.1 : formula = puntajes[[1]][[1]]`~`1 ; data dim = 13 x 2\nPC2.1 : formula = puntajes[[1]][[2]]`~`1 ; data dim = 13 x 2\nPC1.2 : formula = puntajes[[2]][[1]]`~`1 ; data dim = 18 x 2\nPC2.2 : formula = puntajes[[2]][[2]]`~`1 ; data dim = 18 x 2\nvariograms:\n               model      psill    range\nPC1.1[1]         Gau 356886.232 23317.05\nPC1.1[2]         Wav 251618.187  9408.63\nPC2.1[1]         Gau 157275.294 23317.05\nPC2.1[2]         Wav  66770.748  9408.63\nPC1.2[1]         Gau 509628.594 23317.05\nPC1.2[2]         Wav  86045.557  9408.63\nPC2.2[1]         Gau   9178.223 23317.05\nPC2.2[2]         Wav  77729.767  9408.63\nPC1.1.PC2.1[1]   Gau  96771.742 23317.05\nPC1.1.PC2.1[2]   Wav -11290.879  9408.63\nPC1.1.PC1.2[1]   Gau 358697.498 23317.05\nPC1.1.PC1.2[2]   Wav  84592.302  9408.63\nPC2.1.PC1.2[1]   Gau -36478.239 23317.05\nPC2.1.PC1.2[2]   Wav  57029.144  9408.63\nPC1.1.PC2.2[1]   Gau  11668.546 23317.05\nPC1.1.PC2.2[2]   Wav 137897.759  9408.63\nPC2.1.PC2.2[1]   Gau  -1677.278 23317.05\nPC2.1.PC2.2[2]   Wav -12680.551  9408.63\nPC1.2.PC2.2[1]   Gau  16583.870 23317.05\nPC1.2.PC2.2[2]   Wav  40857.282  9408.63",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Cokriging</span>",
      "Modelo de Cokriging"
    ]
  },
  {
    "objectID": "11-Cokriging.html",
    "href": "11-Cokriging.html",
    "title": "Cokriging",
    "section": "",
    "text": "[Cokriging]",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Cokriging</span>",
      "Ilustración del Cokriging"
    ]
  },
  {
    "objectID": "11-Cokriging.html#matrices-definida-positiva-para-el-modelo-esférico.",
    "href": "11-Cokriging.html#matrices-definida-positiva-para-el-modelo-esférico.",
    "title": "Cokriging",
    "section": "Matrices definida positiva para el modelo Esférico.",
    "text": "Matrices definida positiva para el modelo Esférico.\n\nmat1 &lt;- cbind(c(30, 30, 30),\n              c(30, 50, 30),\n              c(30, 30, 35))\n#matriz definida positiva \"cercana\"\nmat1 &lt;- data.frame(as.matrix(nearPD(mat1)$mat))\nnames(mat1) &lt;- c(\"NO2\", \"O3\", \"NOX\")\nrow.names(mat1) &lt;- c(\"NO2\", \"O3\", \"NOX\")\npander::pander(mat1)\n\n\nMatriz definida positiva para el modelo efecto Hueco.\n\nmat2 &lt;- cbind(c(13.02, 24.5, 18.739),\n              c(24.58, 46.4, 35.36),\n              c(18.73, 35.36, 26.95))\nmat2 &lt;- data.frame(as.matrix(nearPD(mat2)$mat))\nnames(mat2) &lt;- c(\"NO2\", \"O3\", \"NOX\")\nrow.names(mat2) &lt;- c(\"NO2\", \"O3\", \"NOX\")\npander::pander(mat2)",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Cokriging</span>",
      "Ilustración del Cokriging"
    ]
  },
  {
    "objectID": "11-Cokriging.html#semivariogramas-univariados",
    "href": "11-Cokriging.html#semivariogramas-univariados",
    "title": "Cokriging",
    "section": "Semivariogramas univariados",
    "text": "Semivariogramas univariados\n\nvgmno2 &lt;- vgm(psill = mat1[1, 1],\n            model = \"Sph\",\n            range = 6096,\n            add.to = vgm(psill = mat2[1, 1],\n                         model = \"Hol\",\n                         range = 2294))\n\nvgmo3 &lt;- vgm(psill = mat1[2, 2],\n            model = \"Sph\",\n            range = 6096,\n            add.to = vgm(psill = mat2[2, 2],\n                         model = \"Hol\",\n                         range = 2294))\n\nvgmnox &lt;- vgm(psill = mat1[3, 3],\n            model = \"Sph\",\n            range = 6096,\n            add.to = vgm(psill = mat2[3, 3],\n                         model = \"Hol\",\n                         range = 2294)",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Cokriging</span>",
      "Ilustración del Cokriging"
    ]
  },
  {
    "objectID": "11-Cokriging.html#semivarogramas-cruzados-bivariados",
    "href": "11-Cokriging.html#semivarogramas-cruzados-bivariados",
    "title": "Cokriging",
    "section": "Semivarogramas cruzados (Bivariados)",
    "text": "Semivarogramas cruzados (Bivariados)\n\nvgmno2_o3 &lt;- vgm(psill = mat1[1, 2], model = \"Sph\",\n            range = 6096,\n            add.to = vgm(psill = mat2[1, 2],\n                         model = \"Hol\",\n                         range = 2294))\n\nvgmno2_nox &lt;- vgm(psill = mat1[1, 3],\n            model = \"Sph\",\n            range = 6096,\n            add.to = vgm(psill = mat2[1, 3],\n                         model = \"Hol\",\n                         range = 2294))\n\nvgmno3_nox &lt;- vgm(psill = mat1[2, 3],\n                  model = \"Sph\",\n                  range = 6096,\n                  add.to = vgm(psill = mat2[2, 3],\n                               model = \"Hol\",\n                               range = 2294))",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Cokriging</span>",
      "Ilustración del Cokriging"
    ]
  },
  {
    "objectID": "11-Cokriging.html#gstat",
    "href": "11-Cokriging.html#gstat",
    "title": "Cokriging",
    "section": "gstat",
    "text": "gstat\n\nremove_na &lt;- function(frame, vari_) {\n\n    # Remove na from sp object\n\n    datos1 &lt;- frame\n\n    bool &lt;- !is.na(datos1@data[vari_])\n    datos1@data &lt;- datos1@data[bool, ]\n    datos1@coords &lt;- datos1@coords[bool, ]\n\n    return(datos1)\n\n}\n\ncoordinates(datos) &lt;- ~ X + Y\n\ng_st &lt;- gstat(NULL,\n              id = \"NO2\",\n              formula = NO2 ~ X + Y,\n              model = vgmno2,\n              data = remove_na(datos, \"NO2\"))\n\ng_st &lt;- gstat(g_st,\n              id = \"O3\",\n              formula = O3 ~ Y,\n              model = vgmo3,\n              data = remove_na(datos, \"O3\"))\n\ng_st &lt;- gstat(g_st,\n              id = \"NOX\",\n              formula = NOX ~ Y,\n              model = vgmnox,\n              data = remove_na(datos, \"NOX\"))\n#Cruzados\n\n\ng_st &lt;- gstat(g_st,\n              id = c(\"NO2\", \"O3\"),\n              model = vgmno2_o3)\n\ng_st &lt;- gstat(g_st,\n              id = c(\"NO2\", \"NOX\"),\n              model = vgmno2_nox)\n\ng_st &lt;- gstat(g_st,\n              id = c(\"O3\", \"NOX\"),\n              model = vgmno3_nox)\n\n\npander::pander(do.call(rbind, g_st$model)[, 1:3])",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Cokriging</span>",
      "Ilustración del Cokriging"
    ]
  },
  {
    "objectID": "11-Cokriging.html#estimación-del-semivariograma",
    "href": "11-Cokriging.html#estimación-del-semivariograma",
    "title": "Cokriging",
    "section": "Estimación del semivariograma",
    "text": "Estimación del semivariograma\n\nplot(variogram(g_st),\n     model = g_st$model,\n     pl = T,\n     xlab = \"Distancias\",\n     ylab = \"Semivarianza\")",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Cokriging</span>",
      "Ilustración del Cokriging"
    ]
  },
  {
    "objectID": "11-Cokriging.html#mapas-de-predicción-de-o3-con-las-covariables-espaciales-no2-y-nox",
    "href": "11-Cokriging.html#mapas-de-predicción-de-o3-con-las-covariables-espaciales-no2-y-nox",
    "title": "Cokriging",
    "section": "Mapas de predicción de O3 con las covariables espaciales NO2 y NOX",
    "text": "Mapas de predicción de O3 con las covariables espaciales NO2 y NOX\n\nprediction_plot &lt;- function(g_object, variable, map_path) {\n\n    map &lt;- readOGR(map_path)\n    new &lt;- sp::spsample(map, n = 100000, type = \"regular\")\n    coordinates(new) ~ x1 + x2\n    colnames(new@coords) &lt;- c(\"X\", \"Y\")\n\n    predic &lt;- predict(g_object, newdata = new)\n\n    prediction &lt;- data.frame(predic)\n\n    pred &lt;- paste(variable, \".pred\", sep = \"\")\n\n    plot &lt;- ggplot(prediction, aes_string(\"X\", \"Y\", fill = pred)) +\n            geom_tile() +\n            scale_fill_viridis_c() +\n            theme_void()\n\n    return(plot)\n\n}\n\n\nvariance_plot &lt;- function(g_object, variable, map_path) {\n\n    map &lt;- readOGR(map_path)\n    new &lt;- sp::spsample(map, n = 10000, type = \"regular\")\n    coordinates(new) ~ x1 + x2\n    colnames(new@coords) &lt;- c(\"X\", \"Y\")\n\n    predic &lt;- predict(g_object, newdata = new)\n\n    prediction &lt;- data.frame(predic)\n\n    var &lt;- paste(variable, \".var\", sep = \"\")\n\n    plot &lt;- ggplot(prediction, aes_string(\"X\", \"Y\", fill = var)) +\n            geom_tile() +\n            scale_fill_viridis_c(option = \"inferno\",\n                                 direction = -1) +\n            theme_void()\n\n    return(plot)\n\n}\n\ncv_plot &lt;- function(g_object, variable, map_path) {\n\n    map &lt;- readOGR(map_path)\n    new &lt;- sp::spsample(map, n = 10000, type = \"regular\")\n    coordinates(new) ~ x1 + x2\n    colnames(new@coords) &lt;- c(\"X\", \"Y\")\n\n    predic &lt;- predict(g_object, newdata = new)\n\n    prediction &lt;- data.frame(predic)\n    pred &lt;- paste(variable, \".pred\", sep = \"\")\n    var &lt;- paste(variable, \".var\", sep = \"\")\n    aux &lt;- abs(sqrt(prediction[var]) / abs(prediction[pred]))\n    aux[aux &gt; 1] &lt;- 1\n    prediction[\"cv\"] &lt;- aux\n\n    plot &lt;- ggplot(prediction, aes_string(\"X\", \"Y\", fill = \"cv\")) +\n            geom_tile() +\n            scale_fill_viridis_c(option = \"magma\",\n                                 direction = -1) +\n            theme_void()\n\n    return(plot)\n}\n\n\npl1 &lt;- prediction_plot(g_st, \"O3\",\n                       \"SP/mpiosutm.shp\")\n\n\npl2 &lt;- variance_plot(g_st, \"O3\",\n                     \"SP/mpiosutm.shp\")\n\n\npl3 &lt;- cv_plot(g_st, \"O3\",\n               \"SP/mpiosutm.shp\")\n\n\nggplotly(pl1)\n\n\nggplotly(pl2)\n\n\nggplotly(pl3)",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Cokriging</span>",
      "Ilustración del Cokriging"
    ]
  },
  {
    "objectID": "14.html",
    "href": "14.html",
    "title": "Diseño Óptimo",
    "section": "",
    "text": "Diseño Óptimo",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Diseño Óptimo</span>",
      "Diseño Óptimo"
    ]
  },
  {
    "objectID": "14.html#introducción",
    "href": "14.html#introducción",
    "title": "Diseño Óptimo",
    "section": "Introducción",
    "text": "Introducción\nLa función FD_optimal_design permite determinar el diseño espacial óptimo para la recolección de datos funcionales o escalares, basado en un modelo de variograma y un conjunto de puntos donde se desea realizar predicciones. Este diseño es crucial para optimizar la información obtenida en estudios espaciales.",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Diseño Óptimo</span>",
      "Diseño Óptimo"
    ]
  },
  {
    "objectID": "14.html#uso",
    "href": "14.html#uso",
    "title": "Diseño Óptimo",
    "section": "Uso",
    "text": "Uso\n\nFD_optimal_design(k, s0, model, fixed_stations = NULL,\n                   scalar = FALSE, nharm = NULL,",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Diseño Óptimo</span>",
      "Diseño Óptimo"
    ]
  },
  {
    "objectID": "14.html#argumentos",
    "href": "14.html#argumentos",
    "title": "Diseño Óptimo",
    "section": "Argumentos",
    "text": "Argumentos\n\nk: Número de nuevas estaciones a ubicar.\ns0: Un objeto de tipo matrix, array, data.frame o SpatialPoints que contiene las coordenadas de los puntos donde se desea realizar la predicción óptima.\nmodel: Un objeto VariogramModel del paquete gstat o una lista de modelos si se utilizarán diferentes modelos para cada armónico.\nfixed_stations: Coordenadas de estaciones ya existentes que no se eliminarán. Puede ser de clase matrix, array, data.frame, SpatialPoints o NULL si no hay estaciones fijas. scalar: Booleano que indica si la optimización es para datos funcionales (FALSE) o escalares (TRUE). Si es TRUE, nharm se establece en 1.\nnharm: Número de armónicos de los componentes principales funcionales a utilizar en la predicción.\nmethod: Método de kriging funcional que se utilizará, disponible “lambda” y “scores”.\ngrid: Coordenadas donde se pueden ubicar las nuevas estaciones, debe ser de tipo matrix, array, data.frame, SpatialPoints.\nmap: Objeto espacial del paquete sp donde se ubicarán las nuevas estaciones. También se usará para crear la gráfica.\n\n-plt: Booleano que indica si se debe generar una gráfica con ggplot2.",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Diseño Óptimo</span>",
      "Diseño Óptimo"
    ]
  },
  {
    "objectID": "14.html#detalles",
    "href": "14.html#detalles",
    "title": "Diseño Óptimo",
    "section": "Detalles",
    "text": "Detalles\nLa función utiliza métodos presentados por Bohorquez et al. (2016) para encontrar la mejor combinación de diseño según la varianza del error de predicción de kriging funcional. Se implementan dos métodos de kriging funcional:\n\nMétodo “lambda”: Utiliza FPCA y kriging simple.\nMétodo “scores”: Aplica kriging simple a cada armónico y minimiza la varianza total de las predicciones.",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Diseño Óptimo</span>",
      "Diseño Óptimo"
    ]
  },
  {
    "objectID": "14.html#valor-de-retorno",
    "href": "14.html#valor-de-retorno",
    "title": "Diseño Óptimo",
    "section": "Valor de Retorno",
    "text": "Valor de Retorno\nLa función devuelve un objeto de clase OptimalSpatialDesign que incluye:\n\nnew_stations: Coordenadas de las nuevas estaciones.\nfixed_stations: Coordenadas de las estaciones fijas.\nplot: Gráfica generada con ggplot2.",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Diseño Óptimo</span>",
      "Diseño Óptimo"
    ]
  },
  {
    "objectID": "14.html#ejemplo",
    "href": "14.html#ejemplo",
    "title": "Diseño Óptimo",
    "section": "Ejemplo",
    "text": "Ejemplo\n\nlibrary(gstat)\n\nWarning: package 'gstat' was built under R version 4.4.3\n\nlibrary(SpatFD)\n\ns0 &lt;- cbind(2 * runif(100), runif(100))  # coordenadas aleatorias\nfixed_stations &lt;- cbind(2 * runif(4), runif(4))\nx_grid &lt;- seq(0, 2, length = 30)\ny_grid &lt;- seq(0, 1, length = 30)\ngrid &lt;- cbind(rep(x_grid, each = 30), rep(y_grid, 30))\nmodel &lt;- vgm(psill = 5.665312,\n              model = \"Exc\",\n              range = 8000,\n              kappa = 1.62,\n              add.to = vgm(psill = 0.893,\n                           model = \"Nug\",\n                           range = 0,\n                           kappa = 0))\n\nOSD &lt;- FD_optimal_design(k = 10, s0 = s0, model = model,\n                         grid = grid, nharm = 2, plt = TRUE,\n                         fixed_stations = fixed_stations)\n\nAs 'model' is a single variogramModel it will be used for all the harmonics.\n\n\ninitial  value -1120.446780 \nfinal  value -1120.446780 \nconverged\n\n# Resultados\nOSD$new_stations\n\n         x         y\n 1.9310345 0.4482759\n 0.5517241 0.5517241\n 0.1379310 0.4137931\n 1.8620690 0.6896552\n 0.4827586 0.6551724\n 2.0000000 0.5172414\n 1.9310345 0.1724138\n 0.8965517 0.7241379\n 1.8620690 0.3448276\n 1.7931034 1.0000000\n\nOSD$fixed_stations\n\n            V1        V2\n[1,] 0.1229227 0.1343118\n[2,] 1.7473316 0.5840676\n[3,] 0.4329912 0.7178589\n[4,] 1.8780185 0.8448753\n\nOSD$plot\n\n\n\n\n\n\n\nclass(OSD)\n\n[1] \"OptimalSpatialDesign\"\n\n\n\n\n\n\n\n\nNote\n\n\n\nEl método ‘lambda’ tiende a ser más rápido que el método ‘scores’.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nCuando el método es ‘lambda’, el valor minimizado no es la varianza, sino el negativo de una expresión específica en la referencia mencionada.",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Diseño Óptimo</span>",
      "Diseño Óptimo"
    ]
  },
  {
    "objectID": "12-Pulimiento de medianas.html",
    "href": "12-Pulimiento de medianas.html",
    "title": "Pulimiento de Medianas",
    "section": "",
    "text": "Simulación de un campo aleatorio.",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Diseño Óptimo</span>",
      "Pulimiento de Medianas"
    ]
  },
  {
    "objectID": "12-Pulimiento de medianas.html#cargar-librerias",
    "href": "12-Pulimiento de medianas.html#cargar-librerias",
    "title": "Pulimiento de Medianas",
    "section": "Cargar librerias",
    "text": "Cargar librerias\nLista de librerías con link a la documentación.\n\ngstat\nsp\n\nLista de librerías con link a la documentación. Lista de librerías con link a la documentación.",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Diseño Óptimo</span>",
      "Pulimiento de Medianas"
    ]
  },
  {
    "objectID": "12-Pulimiento de medianas.html#grilla-de-las-ubicaciones-espaciales.",
    "href": "12-Pulimiento de medianas.html#grilla-de-las-ubicaciones-espaciales.",
    "title": "Pulimiento de Medianas",
    "section": "Grilla de las ubicaciones espaciales.",
    "text": "Grilla de las ubicaciones espaciales.\n\nn_x &lt;- 4\nn_y &lt;- 6\nx &lt;- seq(0, 1, len = n_x)\ny &lt;- seq(0, 1, len = n_y)\ncoordenadas &lt;- as.data.frame(expand.grid(x, y))\nnames(coordenadas) &lt;- c(\"X\", \"Y\")\n\nEncabezado coordenadas",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Diseño Óptimo</span>",
      "Pulimiento de Medianas"
    ]
  },
  {
    "objectID": "12-Pulimiento de medianas.html#definición-de-objeto-vgm",
    "href": "12-Pulimiento de medianas.html#definición-de-objeto-vgm",
    "title": "Pulimiento de Medianas",
    "section": "Definición de objeto VGM",
    "text": "Definición de objeto VGM\nEsto define un objeto vgm que es el tipo de objeto que usa el paquete gstat para los modelos teóricos de variograma. Con este objeto se pueden definir modelos anidados.\n\nvgm\n\n\nlibrary(sp)\nlibrary(mvtnorm)\n\nlibrary(gstat)\nvario &lt;- vgm(10, # Punto de silla\n             \"Exp\", # Modelo, ver documentación\n             0.5)  # Rango\nprint(vario)",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Diseño Óptimo</span>",
      "Pulimiento de Medianas"
    ]
  },
  {
    "objectID": "12-Pulimiento de medianas.html#matriz-de-varianza-dadas-coordenadas.",
    "href": "12-Pulimiento de medianas.html#matriz-de-varianza-dadas-coordenadas.",
    "title": "Pulimiento de Medianas",
    "section": "Matriz de varianza dadas coordenadas.",
    "text": "Matriz de varianza dadas coordenadas.\n\nvgmArea\ncoordinates\n\n\n coordinates(coordenadas) &lt;- ~X + Y\n    class(coordenadas) # Cambio de objedto dataframe a sp\n\n\ncov_mat &lt;- vgmArea(coordenadas, # Matriz de ubiaciones SP\n        vgm = vario) # VGM object\n\nprint(dim(cov_mat))",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Diseño Óptimo</span>",
      "Pulimiento de Medianas"
    ]
  },
  {
    "objectID": "12-Pulimiento de medianas.html#simulación.",
    "href": "12-Pulimiento de medianas.html#simulación.",
    "title": "Pulimiento de Medianas",
    "section": "Simulación.",
    "text": "Simulación.\nSimulación dada la media y la matriz de varianza\n\nmu  &lt;- rep(0, n_x * n_y) # Media del proceso\nsimu &lt;- rmvnorm(1,\n                mean = mu,\n                sigma = cov_mat)\nprint(simu[1:5])",
    "crumbs": [
      "<span style='color: #FF8000 !important;'>Diseño Óptimo</span>",
      "Pulimiento de Medianas"
    ]
  }
]